{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobiFace(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bottleneck_block1): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block1): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block1_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block2): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2_3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block3): BottleneckBlock(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_4): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_5): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_6): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (relu): PReLU(num_parameters=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "\n",
    "#import models\n",
    "from mobiface_like_v2 import MobiFace\n",
    "from backbone import get_model\n",
    "import model\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, also set the seed for GPU\n",
    "torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = MobiFace()\n",
    "#student = student.to(dtype=torch.float16,device=torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobiFace                                      [1, 512]                  --\n",
       "├─Conv2d: 1-1                                 [1, 64, 56, 56]           1,728\n",
       "├─BatchNorm2d: 1-2                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-3                                  [1, 64, 56, 56]           1\n",
       "├─DepthwiseSeparableConv2d: 1-4               [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 56, 56]           576\n",
       "│    └─Conv2d: 2-2                            [1, 64, 56, 56]           4,096\n",
       "│    └─BatchNorm2d: 2-3                       [1, 64, 56, 56]           128\n",
       "│    └─PReLU: 2-4                             [1, 64, 56, 56]           1\n",
       "├─BatchNorm2d: 1-5                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-6                                  [1, 64, 56, 56]           (recursive)\n",
       "├─BottleneckBlock: 1-7                        [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-5                            [1, 32, 56, 56]           2,048\n",
       "│    └─BatchNorm2d: 2-6                       [1, 32, 56, 56]           64\n",
       "│    └─PReLU: 2-7                             [1, 32, 56, 56]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-8          [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                       [1, 32, 28, 28]           288\n",
       "│    │    └─Conv2d: 3-2                       [1, 32, 28, 28]           1,024\n",
       "│    │    └─BatchNorm2d: 3-3                  [1, 32, 28, 28]           64\n",
       "│    │    └─PReLU: 3-4                        [1, 32, 28, 28]           1\n",
       "│    └─BatchNorm2d: 2-9                       [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-10                            [1, 32, 28, 28]           (recursive)\n",
       "│    └─Conv2d: 2-11                           [1, 64, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-12                      [1, 64, 28, 28]           128\n",
       "├─InvertedResidualBlock: 1-8                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-13                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-14                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-15                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-16         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-5                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-6                       [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-8                        [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-17                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-18                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-19                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-20                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-21                       [1, 64, 28, 28]           --\n",
       "├─InvertedResidualBlock: 1-9                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-22                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-23                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-24                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-25         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-9                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-10                      [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-11                 [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-12                       [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-26                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-27                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-28                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-29                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-30                       [1, 64, 28, 28]           --\n",
       "├─BottleneckBlock: 1-10                       [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-31                           [1, 32, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-32                      [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-33                            [1, 32, 28, 28]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-34         [1, 32, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-13                      [1, 32, 14, 14]           288\n",
       "│    │    └─Conv2d: 3-14                      [1, 32, 14, 14]           1,024\n",
       "│    │    └─BatchNorm2d: 3-15                 [1, 32, 14, 14]           64\n",
       "│    │    └─PReLU: 3-16                       [1, 32, 14, 14]           1\n",
       "│    └─BatchNorm2d: 2-35                      [1, 32, 14, 14]           64\n",
       "│    └─PReLU: 2-36                            [1, 32, 14, 14]           (recursive)\n",
       "│    └─Conv2d: 2-37                           [1, 128, 14, 14]          4,096\n",
       "│    └─BatchNorm2d: 2-38                      [1, 128, 14, 14]          256\n",
       "├─InvertedResidualBlock: 1-11                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-39                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-40                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-41                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-42         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-17                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-18                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-19                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-20                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-43                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-44                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-45                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-46                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-47                       [1, 128, 14, 14]          --\n",
       "├─InvertedResidualBlock: 1-12                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-48                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-49                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-50                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-51         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-21                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-22                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-23                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-24                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-52                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-53                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-54                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-55                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-56                       [1, 128, 14, 14]          --\n",
       "├─InvertedResidualBlock: 1-13                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-57                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-58                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-59                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-60         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-25                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-26                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-27                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-28                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-61                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-62                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-63                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-64                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-65                       [1, 128, 14, 14]          --\n",
       "├─BottleneckBlock: 1-14                       [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-66                           [1, 64, 14, 14]           8,192\n",
       "│    └─BatchNorm2d: 2-67                      [1, 64, 14, 14]           128\n",
       "│    └─PReLU: 2-68                            [1, 64, 14, 14]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-69         [1, 64, 7, 7]             --\n",
       "│    │    └─Conv2d: 3-29                      [1, 64, 7, 7]             576\n",
       "│    │    └─Conv2d: 3-30                      [1, 64, 7, 7]             4,096\n",
       "│    │    └─BatchNorm2d: 3-31                 [1, 64, 7, 7]             128\n",
       "│    │    └─PReLU: 3-32                       [1, 64, 7, 7]             1\n",
       "│    └─BatchNorm2d: 2-70                      [1, 64, 7, 7]             128\n",
       "│    └─PReLU: 2-71                            [1, 64, 7, 7]             (recursive)\n",
       "│    └─Conv2d: 2-72                           [1, 256, 7, 7]            16,384\n",
       "│    └─BatchNorm2d: 2-73                      [1, 256, 7, 7]            512\n",
       "├─InvertedResidualBlock: 1-15                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-74                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-75                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-76                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-77         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-33                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-34                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-35                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-36                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-78                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-79                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-80                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-81                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-82                       [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-16                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-83                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-84                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-85                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-86         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-37                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-38                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-39                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-40                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-87                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-88                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-89                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-90                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-91                       [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-17                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-92                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-93                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-94                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-95         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-41                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-42                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-43                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-44                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-96                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-97                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-98                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-99                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-100                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-18                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-101                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-102                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-103                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-104        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-45                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-46                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-47                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-48                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-105                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-106                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-107                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-108                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-109                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-19                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-110                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-111                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-112                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-113        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-49                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-50                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-51                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-52                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-114                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-115                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-116                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-117                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-118                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-20                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-119                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-120                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-121                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-122        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-53                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-54                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-55                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-56                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-123                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-124                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-125                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-126                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-127                      [1, 256, 7, 7]            --\n",
       "├─Conv2d: 1-21                                [1, 512, 7, 7]            131,072\n",
       "├─BatchNorm2d: 1-22                           [1, 512, 7, 7]            1,024\n",
       "├─Linear: 1-23                                [1, 512]                  262,656\n",
       "===============================================================================================\n",
       "Total params: 4,115,358\n",
       "Trainable params: 4,115,358\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 328.25\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 61.37\n",
       "Params size (MB): 16.46\n",
       "Estimated Total Size (MB): 77.98\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(student, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher =  torch.load(\"full_webcassia_finetuned_v2.pth\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionResnetV1(\n",
       "  (conv2d_1a): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2a): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2b): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_3b): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4a): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4b): BasicConv2d(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (repeat_1): Sequential(\n",
       "    (0): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_6a): Mixed_6a(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_2): Sequential(\n",
       "    (0): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_7a): Mixed_7a(\n",
       "    (branch0): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_3): Sequential(\n",
       "    (0): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (block8): Block8(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "InceptionResnetV1                             [1, 10575]                --\n",
       "├─BasicConv2d: 1-1                            [1, 32, 55, 55]           --\n",
       "│    └─Conv2d: 2-1                            [1, 32, 55, 55]           (864)\n",
       "│    └─BatchNorm2d: 2-2                       [1, 32, 55, 55]           (64)\n",
       "│    └─ReLU: 2-3                              [1, 32, 55, 55]           --\n",
       "├─BasicConv2d: 1-2                            [1, 32, 53, 53]           --\n",
       "│    └─Conv2d: 2-4                            [1, 32, 53, 53]           (9,216)\n",
       "│    └─BatchNorm2d: 2-5                       [1, 32, 53, 53]           (64)\n",
       "│    └─ReLU: 2-6                              [1, 32, 53, 53]           --\n",
       "├─BasicConv2d: 1-3                            [1, 64, 53, 53]           --\n",
       "│    └─Conv2d: 2-7                            [1, 64, 53, 53]           (18,432)\n",
       "│    └─BatchNorm2d: 2-8                       [1, 64, 53, 53]           (128)\n",
       "│    └─ReLU: 2-9                              [1, 64, 53, 53]           --\n",
       "├─MaxPool2d: 1-4                              [1, 64, 26, 26]           --\n",
       "├─BasicConv2d: 1-5                            [1, 80, 26, 26]           --\n",
       "│    └─Conv2d: 2-10                           [1, 80, 26, 26]           (5,120)\n",
       "│    └─BatchNorm2d: 2-11                      [1, 80, 26, 26]           (160)\n",
       "│    └─ReLU: 2-12                             [1, 80, 26, 26]           --\n",
       "├─BasicConv2d: 1-6                            [1, 192, 24, 24]          --\n",
       "│    └─Conv2d: 2-13                           [1, 192, 24, 24]          (138,240)\n",
       "│    └─BatchNorm2d: 2-14                      [1, 192, 24, 24]          (384)\n",
       "│    └─ReLU: 2-15                             [1, 192, 24, 24]          --\n",
       "├─BasicConv2d: 1-7                            [1, 256, 11, 11]          --\n",
       "│    └─Conv2d: 2-16                           [1, 256, 11, 11]          (442,368)\n",
       "│    └─BatchNorm2d: 2-17                      [1, 256, 11, 11]          (512)\n",
       "│    └─ReLU: 2-18                             [1, 256, 11, 11]          --\n",
       "├─Sequential: 1-8                             [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-19                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-1                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-2                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-3                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-4                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-5                         [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-20                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-6                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-7                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-8                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-9                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-10                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-21                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-11                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-12                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-13                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-14                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-15                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-22                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-16                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-17                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-18                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-19                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-20                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-23                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-21                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-22                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-23                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-24                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-25                        [1, 256, 11, 11]          --\n",
       "├─Mixed_6a: 1-9                               [1, 896, 5, 5]            --\n",
       "│    └─BasicConv2d: 2-24                      [1, 384, 5, 5]            --\n",
       "│    │    └─Conv2d: 3-26                      [1, 384, 5, 5]            (884,736)\n",
       "│    │    └─BatchNorm2d: 3-27                 [1, 384, 5, 5]            (768)\n",
       "│    │    └─ReLU: 3-28                        [1, 384, 5, 5]            --\n",
       "│    └─Sequential: 2-25                       [1, 256, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-29                 [1, 192, 11, 11]          (49,536)\n",
       "│    │    └─BasicConv2d: 3-30                 [1, 192, 11, 11]          (332,160)\n",
       "│    │    └─BasicConv2d: 3-31                 [1, 256, 5, 5]            (442,880)\n",
       "│    └─MaxPool2d: 2-26                        [1, 256, 5, 5]            --\n",
       "├─Sequential: 1-10                            [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-27                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-32                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-33                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-34                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-35                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-28                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-36                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-37                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-38                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-39                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-29                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-40                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-41                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-42                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-43                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-30                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-44                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-45                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-46                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-47                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-31                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-48                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-49                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-50                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-51                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-32                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-52                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-53                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-54                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-55                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-33                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-56                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-57                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-58                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-59                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-34                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-60                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-61                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-62                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-63                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-35                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-64                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-65                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-66                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-67                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-36                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-68                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-69                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-70                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-71                        [1, 896, 5, 5]            --\n",
       "├─Mixed_7a: 1-11                              [1, 1792, 2, 2]           --\n",
       "│    └─Sequential: 2-37                       [1, 384, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-72                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-73                 [1, 384, 2, 2]            (885,504)\n",
       "│    └─Sequential: 2-38                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-74                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-75                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─Sequential: 2-39                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-76                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-77                 [1, 256, 5, 5]            (590,336)\n",
       "│    │    └─BasicConv2d: 3-78                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─MaxPool2d: 2-40                        [1, 896, 2, 2]            --\n",
       "├─Sequential: 1-12                            [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-41                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-79                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-80                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-81                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-82                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-42                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-83                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-84                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-85                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-86                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-43                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-87                 [1, 192, 2, 2]            344,448\n",
       "│    │    └─Sequential: 3-88                  [1, 192, 2, 2]            566,400\n",
       "│    │    └─Conv2d: 3-89                      [1, 1792, 2, 2]           689,920\n",
       "│    │    └─ReLU: 3-90                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-44                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-91                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-92                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-93                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-94                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-45                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-95                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-96                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-97                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-98                        [1, 1792, 2, 2]           --\n",
       "├─Block8: 1-13                                [1, 1792, 2, 2]           --\n",
       "│    └─BasicConv2d: 2-46                      [1, 192, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-99                      [1, 192, 2, 2]            344,064\n",
       "│    │    └─BatchNorm2d: 3-100                [1, 192, 2, 2]            384\n",
       "│    │    └─ReLU: 3-101                       [1, 192, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       [1, 192, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-102                [1, 192, 2, 2]            344,448\n",
       "│    │    └─BasicConv2d: 3-103                [1, 192, 2, 2]            110,976\n",
       "│    │    └─BasicConv2d: 3-104                [1, 192, 2, 2]            110,976\n",
       "│    └─Conv2d: 2-48                           [1, 1792, 2, 2]           689,920\n",
       "├─AdaptiveAvgPool2d: 1-14                     [1, 1792, 1, 1]           --\n",
       "├─Dropout: 1-15                               [1, 1792, 1, 1]           --\n",
       "├─Linear: 1-16                                [1, 512]                  917,504\n",
       "├─BatchNorm1d: 1-17                           [1, 512]                  1,024\n",
       "├─Linear: 1-18                                [1, 10575]                5,424,975\n",
       "===============================================================================================\n",
       "Total params: 28,907,599\n",
       "Trainable params: 9,545,039\n",
       "Non-trainable params: 19,362,560\n",
       "Total mult-adds (M): 600.00\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 18.13\n",
       "Params size (MB): 115.63\n",
       "Estimated Total Size (MB): 133.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(teacher, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionResnetV1(\n",
       "  (conv2d_1a): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2a): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2b): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_3b): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4a): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4b): BasicConv2d(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (repeat_1): Sequential(\n",
       "    (0): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_6a): Mixed_6a(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_2): Sequential(\n",
       "    (0): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_7a): Mixed_7a(\n",
       "    (branch0): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_3): Sequential(\n",
       "    (0): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (block8): Block8(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiFace(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bottleneck_block1): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block2): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block3): BottleneckBlock(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_4): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_5): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_6): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (relu): PReLU(num_parameters=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10575\n",
    "student.fc = nn.Linear(in_features=512, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KD Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for test\n",
    "#root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\small_sample\"\n",
    "root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\images\"\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# Create DataLoader for training\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiFace(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bottleneck_block1): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block2): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block3): BottleneckBlock(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_4): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_5): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_6): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=512, out_features=10575, bias=True)\n",
       "  (relu): PReLU(num_parameters=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = student\n",
    "teacher_model = teacher\n",
    "\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.687118649482727, Accuracy: 0.9198032448297415\n"
     ]
    }
   ],
   "source": [
    "# Criterion, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test accuracy\n",
    "teacher.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = teacher(inputs)\n",
    "        test_loss = criterion(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "print(f'Test Loss: {test_loss.item()}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/5367], Loss: 10.1743, correct :0, total: 64, Batch Accuracy: 0.00%\n",
      "Epoch [1/10], Batch [101/5367], Loss: 10.1203, correct :9, total: 6464, Batch Accuracy: 0.14%\n",
      "Epoch [1/10], Batch [201/5367], Loss: 10.0228, correct :19, total: 12864, Batch Accuracy: 0.15%\n",
      "Epoch [1/10], Batch [301/5367], Loss: 9.9555, correct :39, total: 19264, Batch Accuracy: 0.20%\n",
      "Epoch [1/10], Batch [401/5367], Loss: 9.8972, correct :63, total: 25664, Batch Accuracy: 0.25%\n",
      "Epoch [1/10], Batch [501/5367], Loss: 9.8459, correct :86, total: 32064, Batch Accuracy: 0.27%\n",
      "Epoch [1/10], Batch [601/5367], Loss: 9.7932, correct :118, total: 38464, Batch Accuracy: 0.31%\n",
      "Epoch [1/10], Batch [701/5367], Loss: 9.7374, correct :153, total: 44864, Batch Accuracy: 0.34%\n",
      "Epoch [1/10], Batch [801/5367], Loss: 9.6820, correct :194, total: 51264, Batch Accuracy: 0.38%\n",
      "Epoch [1/10], Batch [901/5367], Loss: 9.6289, correct :249, total: 57664, Batch Accuracy: 0.43%\n",
      "Epoch [1/10], Batch [1001/5367], Loss: 9.5810, correct :305, total: 64064, Batch Accuracy: 0.48%\n",
      "Epoch [1/10], Batch [1101/5367], Loss: 9.5324, correct :367, total: 70464, Batch Accuracy: 0.52%\n",
      "Epoch [1/10], Batch [1201/5367], Loss: 9.4861, correct :426, total: 76864, Batch Accuracy: 0.55%\n",
      "Epoch [1/10], Batch [1301/5367], Loss: 9.4392, correct :502, total: 83264, Batch Accuracy: 0.60%\n",
      "Epoch [1/10], Batch [1401/5367], Loss: 9.3941, correct :589, total: 89664, Batch Accuracy: 0.66%\n",
      "Epoch [1/10], Batch [1501/5367], Loss: 9.3491, correct :688, total: 96064, Batch Accuracy: 0.72%\n",
      "Epoch [1/10], Batch [1601/5367], Loss: 9.3065, correct :789, total: 102464, Batch Accuracy: 0.77%\n",
      "Epoch [1/10], Batch [1701/5367], Loss: 9.2633, correct :899, total: 108864, Batch Accuracy: 0.83%\n",
      "Epoch [1/10], Batch [1801/5367], Loss: 9.2214, correct :1008, total: 115264, Batch Accuracy: 0.87%\n",
      "Epoch [1/10], Batch [1901/5367], Loss: 9.1807, correct :1141, total: 121664, Batch Accuracy: 0.94%\n",
      "Epoch [1/10], Batch [2001/5367], Loss: 9.1430, correct :1278, total: 128064, Batch Accuracy: 1.00%\n",
      "Epoch [1/10], Batch [2101/5367], Loss: 9.1031, correct :1432, total: 134464, Batch Accuracy: 1.06%\n",
      "Epoch [1/10], Batch [2201/5367], Loss: 9.0659, correct :1581, total: 140864, Batch Accuracy: 1.12%\n",
      "Epoch [1/10], Batch [2301/5367], Loss: 9.0286, correct :1766, total: 147264, Batch Accuracy: 1.20%\n",
      "Epoch [1/10], Batch [2401/5367], Loss: 8.9910, correct :1993, total: 153664, Batch Accuracy: 1.30%\n",
      "Epoch [1/10], Batch [2501/5367], Loss: 8.9547, correct :2191, total: 160064, Batch Accuracy: 1.37%\n",
      "Epoch [1/10], Batch [2601/5367], Loss: 8.9189, correct :2436, total: 166464, Batch Accuracy: 1.46%\n",
      "Epoch [1/10], Batch [2701/5367], Loss: 8.8833, correct :2697, total: 172864, Batch Accuracy: 1.56%\n",
      "Epoch [1/10], Batch [2801/5367], Loss: 8.8486, correct :2961, total: 179264, Batch Accuracy: 1.65%\n",
      "Epoch [1/10], Batch [2901/5367], Loss: 8.8135, correct :3236, total: 185664, Batch Accuracy: 1.74%\n",
      "Epoch [1/10], Batch [3001/5367], Loss: 8.7805, correct :3510, total: 192064, Batch Accuracy: 1.83%\n",
      "Epoch [1/10], Batch [3101/5367], Loss: 8.7472, correct :3795, total: 198464, Batch Accuracy: 1.91%\n",
      "Epoch [1/10], Batch [3201/5367], Loss: 8.7136, correct :4138, total: 204864, Batch Accuracy: 2.02%\n",
      "Epoch [1/10], Batch [3301/5367], Loss: 8.6805, correct :4478, total: 211264, Batch Accuracy: 2.12%\n",
      "Epoch [1/10], Batch [3401/5367], Loss: 8.6498, correct :4838, total: 217664, Batch Accuracy: 2.22%\n",
      "Epoch [1/10], Batch [3501/5367], Loss: 8.6187, correct :5208, total: 224064, Batch Accuracy: 2.32%\n",
      "Epoch [1/10], Batch [3601/5367], Loss: 8.5863, correct :5593, total: 230464, Batch Accuracy: 2.43%\n",
      "Epoch [1/10], Batch [3701/5367], Loss: 8.5553, correct :5970, total: 236864, Batch Accuracy: 2.52%\n",
      "Epoch [1/10], Batch [3801/5367], Loss: 8.5248, correct :6362, total: 243264, Batch Accuracy: 2.62%\n",
      "Epoch [1/10], Batch [3901/5367], Loss: 8.4937, correct :6837, total: 249664, Batch Accuracy: 2.74%\n",
      "Epoch [1/10], Batch [4001/5367], Loss: 8.4625, correct :7298, total: 256064, Batch Accuracy: 2.85%\n",
      "Epoch [1/10], Batch [4101/5367], Loss: 8.4318, correct :7807, total: 262464, Batch Accuracy: 2.97%\n",
      "Epoch [1/10], Batch [4201/5367], Loss: 8.4013, correct :8340, total: 268864, Batch Accuracy: 3.10%\n",
      "Epoch [1/10], Batch [4301/5367], Loss: 8.3703, correct :8876, total: 275264, Batch Accuracy: 3.22%\n",
      "Epoch [1/10], Batch [4401/5367], Loss: 8.3396, correct :9469, total: 281664, Batch Accuracy: 3.36%\n",
      "Epoch [1/10], Batch [4501/5367], Loss: 8.3088, correct :10030, total: 288064, Batch Accuracy: 3.48%\n",
      "Epoch [1/10], Batch [4601/5367], Loss: 8.2794, correct :10639, total: 294464, Batch Accuracy: 3.61%\n",
      "Epoch [1/10], Batch [4701/5367], Loss: 8.2492, correct :11304, total: 300864, Batch Accuracy: 3.76%\n",
      "Epoch [1/10], Batch [4801/5367], Loss: 8.2188, correct :11949, total: 307264, Batch Accuracy: 3.89%\n",
      "Epoch [1/10], Batch [4901/5367], Loss: 8.1893, correct :12631, total: 313664, Batch Accuracy: 4.03%\n",
      "Epoch [1/10], Batch [5001/5367], Loss: 8.1600, correct :13289, total: 320064, Batch Accuracy: 4.15%\n",
      "Epoch [1/10], Batch [5101/5367], Loss: 8.1319, correct :13986, total: 326464, Batch Accuracy: 4.28%\n",
      "Epoch [1/10], Batch [5201/5367], Loss: 8.1031, correct :14747, total: 332864, Batch Accuracy: 4.43%\n",
      "Epoch [1/10], Batch [5301/5367], Loss: 8.0750, correct :15498, total: 339264, Batch Accuracy: 4.57%\n",
      "Epoch [1/10], Validation Loss: 6.8163, Validation Accuracy: 9.98%\n",
      "Epoch [1/10], Loss: 8.0561, Accuracy: 4.67%\n",
      "Epoch [2/10], Batch [1/5367], Loss: 6.3918, correct :9, total: 64, Batch Accuracy: 14.06%\n",
      "Epoch [2/10], Batch [101/5367], Loss: 6.3263, correct :828, total: 6464, Batch Accuracy: 12.81%\n",
      "Epoch [2/10], Batch [201/5367], Loss: 6.3209, correct :1680, total: 12864, Batch Accuracy: 13.06%\n",
      "Epoch [2/10], Batch [301/5367], Loss: 6.3235, correct :2560, total: 19264, Batch Accuracy: 13.29%\n",
      "Epoch [2/10], Batch [401/5367], Loss: 6.3128, correct :3427, total: 25664, Batch Accuracy: 13.35%\n",
      "Epoch [2/10], Batch [501/5367], Loss: 6.3025, correct :4305, total: 32064, Batch Accuracy: 13.43%\n",
      "Epoch [2/10], Batch [601/5367], Loss: 6.2927, correct :5231, total: 38464, Batch Accuracy: 13.60%\n",
      "Epoch [2/10], Batch [701/5367], Loss: 6.2725, correct :6218, total: 44864, Batch Accuracy: 13.86%\n",
      "Epoch [2/10], Batch [801/5367], Loss: 6.2527, correct :7229, total: 51264, Batch Accuracy: 14.10%\n",
      "Epoch [2/10], Batch [901/5367], Loss: 6.2419, correct :8257, total: 57664, Batch Accuracy: 14.32%\n",
      "Epoch [2/10], Batch [1001/5367], Loss: 6.2296, correct :9262, total: 64064, Batch Accuracy: 14.46%\n",
      "Epoch [2/10], Batch [1101/5367], Loss: 6.2111, correct :10322, total: 70464, Batch Accuracy: 14.65%\n",
      "Epoch [2/10], Batch [1201/5367], Loss: 6.1933, correct :11401, total: 76864, Batch Accuracy: 14.83%\n",
      "Epoch [2/10], Batch [1301/5367], Loss: 6.1759, correct :12545, total: 83264, Batch Accuracy: 15.07%\n",
      "Epoch [2/10], Batch [1401/5367], Loss: 6.1607, correct :13626, total: 89664, Batch Accuracy: 15.20%\n",
      "Epoch [2/10], Batch [1501/5367], Loss: 6.1447, correct :14781, total: 96064, Batch Accuracy: 15.39%\n",
      "Epoch [2/10], Batch [1601/5367], Loss: 6.1320, correct :15931, total: 102464, Batch Accuracy: 15.55%\n",
      "Epoch [2/10], Batch [1701/5367], Loss: 6.1163, correct :17106, total: 108864, Batch Accuracy: 15.71%\n",
      "Epoch [2/10], Batch [1801/5367], Loss: 6.1004, correct :18332, total: 115264, Batch Accuracy: 15.90%\n",
      "Epoch [2/10], Batch [1901/5367], Loss: 6.0883, correct :19497, total: 121664, Batch Accuracy: 16.03%\n",
      "Epoch [2/10], Batch [2001/5367], Loss: 6.0705, correct :20786, total: 128064, Batch Accuracy: 16.23%\n",
      "Epoch [2/10], Batch [2101/5367], Loss: 6.0537, correct :22048, total: 134464, Batch Accuracy: 16.40%\n",
      "Epoch [2/10], Batch [2201/5367], Loss: 6.0362, correct :23353, total: 140864, Batch Accuracy: 16.58%\n",
      "Epoch [2/10], Batch [2301/5367], Loss: 6.0204, correct :24607, total: 147264, Batch Accuracy: 16.71%\n",
      "Epoch [2/10], Batch [2401/5367], Loss: 6.0069, correct :25916, total: 153664, Batch Accuracy: 16.87%\n",
      "Epoch [2/10], Batch [2501/5367], Loss: 5.9913, correct :27293, total: 160064, Batch Accuracy: 17.05%\n",
      "Epoch [2/10], Batch [2601/5367], Loss: 5.9748, correct :28702, total: 166464, Batch Accuracy: 17.24%\n",
      "Epoch [2/10], Batch [2701/5367], Loss: 5.9605, correct :30033, total: 172864, Batch Accuracy: 17.37%\n",
      "Epoch [2/10], Batch [2801/5367], Loss: 5.9460, correct :31393, total: 179264, Batch Accuracy: 17.51%\n",
      "Epoch [2/10], Batch [2901/5367], Loss: 5.9309, correct :32834, total: 185664, Batch Accuracy: 17.68%\n",
      "Epoch [2/10], Batch [3001/5367], Loss: 5.9141, correct :34292, total: 192064, Batch Accuracy: 17.85%\n",
      "Epoch [2/10], Batch [3101/5367], Loss: 5.8979, correct :35804, total: 198464, Batch Accuracy: 18.04%\n",
      "Epoch [2/10], Batch [3201/5367], Loss: 5.8808, correct :37358, total: 204864, Batch Accuracy: 18.24%\n",
      "Epoch [2/10], Batch [3301/5367], Loss: 5.8673, correct :38842, total: 211264, Batch Accuracy: 18.39%\n",
      "Epoch [2/10], Batch [3401/5367], Loss: 5.8509, correct :40461, total: 217664, Batch Accuracy: 18.59%\n",
      "Epoch [2/10], Batch [3501/5367], Loss: 5.8350, correct :42010, total: 224064, Batch Accuracy: 18.75%\n",
      "Epoch [2/10], Batch [3601/5367], Loss: 5.8206, correct :43607, total: 230464, Batch Accuracy: 18.92%\n",
      "Epoch [2/10], Batch [3701/5367], Loss: 5.8060, correct :45228, total: 236864, Batch Accuracy: 19.09%\n",
      "Epoch [2/10], Batch [3801/5367], Loss: 5.7905, correct :46878, total: 243264, Batch Accuracy: 19.27%\n",
      "Epoch [2/10], Batch [3901/5367], Loss: 5.7767, correct :48465, total: 249664, Batch Accuracy: 19.41%\n",
      "Epoch [2/10], Batch [4001/5367], Loss: 5.7604, correct :50155, total: 256064, Batch Accuracy: 19.59%\n",
      "Epoch [2/10], Batch [4101/5367], Loss: 5.7442, correct :51894, total: 262464, Batch Accuracy: 19.77%\n",
      "Epoch [2/10], Batch [4201/5367], Loss: 5.7304, correct :53617, total: 268864, Batch Accuracy: 19.94%\n",
      "Epoch [2/10], Batch [4301/5367], Loss: 5.7146, correct :55411, total: 275264, Batch Accuracy: 20.13%\n",
      "Epoch [2/10], Batch [4401/5367], Loss: 5.6978, correct :57234, total: 281664, Batch Accuracy: 20.32%\n",
      "Epoch [2/10], Batch [4501/5367], Loss: 5.6831, correct :59016, total: 288064, Batch Accuracy: 20.49%\n",
      "Epoch [2/10], Batch [4601/5367], Loss: 5.6671, correct :60916, total: 294464, Batch Accuracy: 20.69%\n",
      "Epoch [2/10], Batch [4701/5367], Loss: 5.6522, correct :62742, total: 300864, Batch Accuracy: 20.85%\n",
      "Epoch [2/10], Batch [4801/5367], Loss: 5.6357, correct :64713, total: 307264, Batch Accuracy: 21.06%\n",
      "Epoch [2/10], Batch [4901/5367], Loss: 5.6210, correct :66583, total: 313664, Batch Accuracy: 21.23%\n",
      "Epoch [2/10], Batch [5001/5367], Loss: 5.6057, correct :68548, total: 320064, Batch Accuracy: 21.42%\n",
      "Epoch [2/10], Batch [5101/5367], Loss: 5.5898, correct :70531, total: 326464, Batch Accuracy: 21.60%\n",
      "Epoch [2/10], Batch [5201/5367], Loss: 5.5744, correct :72530, total: 332864, Batch Accuracy: 21.79%\n",
      "Epoch [2/10], Batch [5301/5367], Loss: 5.5609, correct :74493, total: 339264, Batch Accuracy: 21.96%\n",
      "Epoch [2/10], Validation Loss: 5.0341, Validation Accuracy: 28.10%\n",
      "Epoch [2/10], Loss: 5.5520, Accuracy: 22.06%\n",
      "Epoch [3/10], Batch [1/5367], Loss: 4.1360, correct :27, total: 64, Batch Accuracy: 42.19%\n",
      "Epoch [3/10], Batch [101/5367], Loss: 4.4343, correct :2266, total: 6464, Batch Accuracy: 35.06%\n",
      "Epoch [3/10], Batch [201/5367], Loss: 4.4694, correct :4404, total: 12864, Batch Accuracy: 34.24%\n",
      "Epoch [3/10], Batch [301/5367], Loss: 4.4673, correct :6583, total: 19264, Batch Accuracy: 34.17%\n",
      "Epoch [3/10], Batch [401/5367], Loss: 4.4601, correct :8803, total: 25664, Batch Accuracy: 34.30%\n",
      "Epoch [3/10], Batch [501/5367], Loss: 4.4595, correct :11073, total: 32064, Batch Accuracy: 34.53%\n",
      "Epoch [3/10], Batch [601/5367], Loss: 4.4677, correct :13310, total: 38464, Batch Accuracy: 34.60%\n",
      "Epoch [3/10], Batch [701/5367], Loss: 4.4608, correct :15535, total: 44864, Batch Accuracy: 34.63%\n",
      "Epoch [3/10], Batch [801/5367], Loss: 4.4479, correct :17840, total: 51264, Batch Accuracy: 34.80%\n",
      "Epoch [3/10], Batch [901/5367], Loss: 4.4486, correct :20185, total: 57664, Batch Accuracy: 35.00%\n",
      "Epoch [3/10], Batch [1001/5367], Loss: 4.4462, correct :22423, total: 64064, Batch Accuracy: 35.00%\n",
      "Epoch [3/10], Batch [1101/5367], Loss: 4.4387, correct :24773, total: 70464, Batch Accuracy: 35.16%\n",
      "Epoch [3/10], Batch [1201/5367], Loss: 4.4311, correct :27098, total: 76864, Batch Accuracy: 35.25%\n",
      "Epoch [3/10], Batch [1301/5367], Loss: 4.4246, correct :29487, total: 83264, Batch Accuracy: 35.41%\n",
      "Epoch [3/10], Batch [1401/5367], Loss: 4.4194, correct :31878, total: 89664, Batch Accuracy: 35.55%\n",
      "Epoch [3/10], Batch [1501/5367], Loss: 4.4161, correct :34223, total: 96064, Batch Accuracy: 35.63%\n",
      "Epoch [3/10], Batch [1601/5367], Loss: 4.4124, correct :36609, total: 102464, Batch Accuracy: 35.73%\n",
      "Epoch [3/10], Batch [1701/5367], Loss: 4.4055, correct :38988, total: 108864, Batch Accuracy: 35.81%\n",
      "Epoch [3/10], Batch [1801/5367], Loss: 4.4003, correct :41382, total: 115264, Batch Accuracy: 35.90%\n",
      "Epoch [3/10], Batch [1901/5367], Loss: 4.3983, correct :43740, total: 121664, Batch Accuracy: 35.95%\n",
      "Epoch [3/10], Batch [2001/5367], Loss: 4.3887, correct :46230, total: 128064, Batch Accuracy: 36.10%\n",
      "Epoch [3/10], Batch [2101/5367], Loss: 4.3813, correct :48752, total: 134464, Batch Accuracy: 36.26%\n",
      "Epoch [3/10], Batch [2201/5367], Loss: 4.3729, correct :51266, total: 140864, Batch Accuracy: 36.39%\n",
      "Epoch [3/10], Batch [2301/5367], Loss: 4.3676, correct :53704, total: 147264, Batch Accuracy: 36.47%\n",
      "Epoch [3/10], Batch [2401/5367], Loss: 4.3593, correct :56282, total: 153664, Batch Accuracy: 36.63%\n",
      "Epoch [3/10], Batch [2501/5367], Loss: 4.3513, correct :58809, total: 160064, Batch Accuracy: 36.74%\n",
      "Epoch [3/10], Batch [2601/5367], Loss: 4.3455, correct :61321, total: 166464, Batch Accuracy: 36.84%\n",
      "Epoch [3/10], Batch [2701/5367], Loss: 4.3372, correct :63945, total: 172864, Batch Accuracy: 36.99%\n",
      "Epoch [3/10], Batch [2801/5367], Loss: 4.3296, correct :66515, total: 179264, Batch Accuracy: 37.10%\n",
      "Epoch [3/10], Batch [2901/5367], Loss: 4.3218, correct :69124, total: 185664, Batch Accuracy: 37.23%\n",
      "Epoch [3/10], Batch [3001/5367], Loss: 4.3142, correct :71750, total: 192064, Batch Accuracy: 37.36%\n",
      "Epoch [3/10], Batch [3101/5367], Loss: 4.3053, correct :74425, total: 198464, Batch Accuracy: 37.50%\n",
      "Epoch [3/10], Batch [3201/5367], Loss: 4.2981, correct :77106, total: 204864, Batch Accuracy: 37.64%\n",
      "Epoch [3/10], Batch [3301/5367], Loss: 4.2915, correct :79743, total: 211264, Batch Accuracy: 37.75%\n",
      "Epoch [3/10], Batch [3401/5367], Loss: 4.2837, correct :82432, total: 217664, Batch Accuracy: 37.87%\n",
      "Epoch [3/10], Batch [3501/5367], Loss: 4.2774, correct :85064, total: 224064, Batch Accuracy: 37.96%\n",
      "Epoch [3/10], Batch [3601/5367], Loss: 4.2700, correct :87776, total: 230464, Batch Accuracy: 38.09%\n",
      "Epoch [3/10], Batch [3701/5367], Loss: 4.2632, correct :90511, total: 236864, Batch Accuracy: 38.21%\n",
      "Epoch [3/10], Batch [3801/5367], Loss: 4.2543, correct :93309, total: 243264, Batch Accuracy: 38.36%\n",
      "Epoch [3/10], Batch [3901/5367], Loss: 4.2467, correct :96072, total: 249664, Batch Accuracy: 38.48%\n",
      "Epoch [3/10], Batch [4001/5367], Loss: 4.2390, correct :98913, total: 256064, Batch Accuracy: 38.63%\n",
      "Epoch [3/10], Batch [4101/5367], Loss: 4.2309, correct :101746, total: 262464, Batch Accuracy: 38.77%\n",
      "Epoch [3/10], Batch [4201/5367], Loss: 4.2221, correct :104614, total: 268864, Batch Accuracy: 38.91%\n",
      "Epoch [3/10], Batch [4301/5367], Loss: 4.2161, correct :107387, total: 275264, Batch Accuracy: 39.01%\n",
      "Epoch [3/10], Batch [4401/5367], Loss: 4.2074, correct :110252, total: 281664, Batch Accuracy: 39.14%\n",
      "Epoch [3/10], Batch [4501/5367], Loss: 4.1995, correct :113127, total: 288064, Batch Accuracy: 39.27%\n",
      "Epoch [3/10], Batch [4601/5367], Loss: 4.1918, correct :116002, total: 294464, Batch Accuracy: 39.39%\n",
      "Epoch [3/10], Batch [4701/5367], Loss: 4.1840, correct :118880, total: 300864, Batch Accuracy: 39.51%\n",
      "Epoch [3/10], Batch [4801/5367], Loss: 4.1768, correct :121795, total: 307264, Batch Accuracy: 39.64%\n",
      "Epoch [3/10], Batch [4901/5367], Loss: 4.1676, correct :124762, total: 313664, Batch Accuracy: 39.78%\n",
      "Epoch [3/10], Batch [5001/5367], Loss: 4.1606, correct :127687, total: 320064, Batch Accuracy: 39.89%\n",
      "Epoch [3/10], Batch [5101/5367], Loss: 4.1522, correct :130654, total: 326464, Batch Accuracy: 40.02%\n",
      "Epoch [3/10], Batch [5201/5367], Loss: 4.1453, correct :133597, total: 332864, Batch Accuracy: 40.14%\n",
      "Epoch [3/10], Batch [5301/5367], Loss: 4.1364, correct :136656, total: 339264, Batch Accuracy: 40.28%\n",
      "Epoch [3/10], Validation Loss: 3.8316, Validation Accuracy: 45.28%\n",
      "Epoch [3/10], Loss: 4.1305, Accuracy: 40.36%\n",
      "Epoch [4/10], Batch [1/5367], Loss: 2.5591, correct :44, total: 64, Batch Accuracy: 68.75%\n",
      "Epoch [4/10], Batch [101/5367], Loss: 3.2954, correct :3359, total: 6464, Batch Accuracy: 51.96%\n",
      "Epoch [4/10], Batch [201/5367], Loss: 3.3077, correct :6681, total: 12864, Batch Accuracy: 51.94%\n",
      "Epoch [4/10], Batch [301/5367], Loss: 3.3095, correct :10038, total: 19264, Batch Accuracy: 52.11%\n",
      "Epoch [4/10], Batch [401/5367], Loss: 3.3267, correct :13347, total: 25664, Batch Accuracy: 52.01%\n",
      "Epoch [4/10], Batch [501/5367], Loss: 3.3385, correct :16603, total: 32064, Batch Accuracy: 51.78%\n",
      "Epoch [4/10], Batch [601/5367], Loss: 3.3446, correct :19862, total: 38464, Batch Accuracy: 51.64%\n",
      "Epoch [4/10], Batch [701/5367], Loss: 3.3450, correct :23144, total: 44864, Batch Accuracy: 51.59%\n",
      "Epoch [4/10], Batch [801/5367], Loss: 3.3468, correct :26439, total: 51264, Batch Accuracy: 51.57%\n",
      "Epoch [4/10], Batch [901/5367], Loss: 3.3483, correct :29734, total: 57664, Batch Accuracy: 51.56%\n",
      "Epoch [4/10], Batch [1001/5367], Loss: 3.3540, correct :32995, total: 64064, Batch Accuracy: 51.50%\n",
      "Epoch [4/10], Batch [1101/5367], Loss: 3.3545, correct :36323, total: 70464, Batch Accuracy: 51.55%\n",
      "Epoch [4/10], Batch [1201/5367], Loss: 3.3562, correct :39651, total: 76864, Batch Accuracy: 51.59%\n",
      "Epoch [4/10], Batch [1301/5367], Loss: 3.3551, correct :42975, total: 83264, Batch Accuracy: 51.61%\n",
      "Epoch [4/10], Batch [1401/5367], Loss: 3.3586, correct :46273, total: 89664, Batch Accuracy: 51.61%\n",
      "Epoch [4/10], Batch [1501/5367], Loss: 3.3576, correct :49581, total: 96064, Batch Accuracy: 51.61%\n",
      "Epoch [4/10], Batch [1601/5367], Loss: 3.3555, correct :52927, total: 102464, Batch Accuracy: 51.65%\n",
      "Epoch [4/10], Batch [1701/5367], Loss: 3.3545, correct :56277, total: 108864, Batch Accuracy: 51.69%\n",
      "Epoch [4/10], Batch [1801/5367], Loss: 3.3531, correct :59621, total: 115264, Batch Accuracy: 51.73%\n",
      "Epoch [4/10], Batch [1901/5367], Loss: 3.3528, correct :62973, total: 121664, Batch Accuracy: 51.76%\n",
      "Epoch [4/10], Batch [2001/5367], Loss: 3.3523, correct :66345, total: 128064, Batch Accuracy: 51.81%\n",
      "Epoch [4/10], Batch [2101/5367], Loss: 3.3499, correct :69698, total: 134464, Batch Accuracy: 51.83%\n",
      "Epoch [4/10], Batch [2201/5367], Loss: 3.3490, correct :73076, total: 140864, Batch Accuracy: 51.88%\n",
      "Epoch [4/10], Batch [2301/5367], Loss: 3.3489, correct :76419, total: 147264, Batch Accuracy: 51.89%\n",
      "Epoch [4/10], Batch [2401/5367], Loss: 3.3484, correct :79797, total: 153664, Batch Accuracy: 51.93%\n",
      "Epoch [4/10], Batch [2501/5367], Loss: 3.3464, correct :83149, total: 160064, Batch Accuracy: 51.95%\n",
      "Epoch [4/10], Batch [2601/5367], Loss: 3.3438, correct :86556, total: 166464, Batch Accuracy: 52.00%\n",
      "Epoch [4/10], Batch [2701/5367], Loss: 3.3454, correct :89860, total: 172864, Batch Accuracy: 51.98%\n",
      "Epoch [4/10], Batch [2801/5367], Loss: 3.3417, correct :93343, total: 179264, Batch Accuracy: 52.07%\n",
      "Epoch [4/10], Batch [2901/5367], Loss: 3.3423, correct :96713, total: 185664, Batch Accuracy: 52.09%\n",
      "Epoch [4/10], Batch [3001/5367], Loss: 3.3422, correct :100082, total: 192064, Batch Accuracy: 52.11%\n",
      "Epoch [4/10], Batch [3101/5367], Loss: 3.3421, correct :103477, total: 198464, Batch Accuracy: 52.14%\n",
      "Epoch [4/10], Batch [3201/5367], Loss: 3.3409, correct :106900, total: 204864, Batch Accuracy: 52.18%\n",
      "Epoch [4/10], Batch [3301/5367], Loss: 3.3389, correct :110325, total: 211264, Batch Accuracy: 52.22%\n",
      "Epoch [4/10], Batch [3401/5367], Loss: 3.3351, correct :113799, total: 217664, Batch Accuracy: 52.28%\n",
      "Epoch [4/10], Batch [3501/5367], Loss: 3.3335, correct :117177, total: 224064, Batch Accuracy: 52.30%\n",
      "Epoch [4/10], Batch [3601/5367], Loss: 3.3300, correct :120689, total: 230464, Batch Accuracy: 52.37%\n",
      "Epoch [4/10], Batch [3701/5367], Loss: 3.3297, correct :124060, total: 236864, Batch Accuracy: 52.38%\n",
      "Epoch [4/10], Batch [3801/5367], Loss: 3.3274, correct :127550, total: 243264, Batch Accuracy: 52.43%\n",
      "Epoch [4/10], Batch [3901/5367], Loss: 3.3236, correct :131066, total: 249664, Batch Accuracy: 52.50%\n",
      "Epoch [4/10], Batch [4001/5367], Loss: 3.3201, correct :134560, total: 256064, Batch Accuracy: 52.55%\n",
      "Epoch [4/10], Batch [4101/5367], Loss: 3.3176, correct :138033, total: 262464, Batch Accuracy: 52.59%\n",
      "Epoch [4/10], Batch [4201/5367], Loss: 3.3151, correct :141521, total: 268864, Batch Accuracy: 52.64%\n",
      "Epoch [4/10], Batch [4301/5367], Loss: 3.3122, correct :145034, total: 275264, Batch Accuracy: 52.69%\n",
      "Epoch [4/10], Batch [4401/5367], Loss: 3.3099, correct :148546, total: 281664, Batch Accuracy: 52.74%\n",
      "Epoch [4/10], Batch [4501/5367], Loss: 3.3081, correct :152062, total: 288064, Batch Accuracy: 52.79%\n",
      "Epoch [4/10], Batch [4601/5367], Loss: 3.3055, correct :155527, total: 294464, Batch Accuracy: 52.82%\n",
      "Epoch [4/10], Batch [4701/5367], Loss: 3.3031, correct :159056, total: 300864, Batch Accuracy: 52.87%\n",
      "Epoch [4/10], Batch [4801/5367], Loss: 3.2994, correct :162649, total: 307264, Batch Accuracy: 52.93%\n",
      "Epoch [4/10], Batch [4901/5367], Loss: 3.2973, correct :166140, total: 313664, Batch Accuracy: 52.97%\n",
      "Epoch [4/10], Batch [5001/5367], Loss: 3.2944, correct :169723, total: 320064, Batch Accuracy: 53.03%\n",
      "Epoch [4/10], Batch [5101/5367], Loss: 3.2923, correct :173235, total: 326464, Batch Accuracy: 53.06%\n",
      "Epoch [4/10], Batch [5201/5367], Loss: 3.2888, correct :176822, total: 332864, Batch Accuracy: 53.12%\n",
      "Epoch [4/10], Batch [5301/5367], Loss: 3.2852, correct :180424, total: 339264, Batch Accuracy: 53.18%\n",
      "Epoch [4/10], Validation Loss: 3.5432, Validation Accuracy: 49.79%\n",
      "Epoch [4/10], Loss: 3.2830, Accuracy: 53.22%\n",
      "Epoch [5/10], Batch [1/5367], Loss: 2.8194, correct :39, total: 64, Batch Accuracy: 60.94%\n",
      "Epoch [5/10], Batch [101/5367], Loss: 2.6737, correct :4059, total: 6464, Batch Accuracy: 62.79%\n",
      "Epoch [5/10], Batch [201/5367], Loss: 2.7264, correct :7978, total: 12864, Batch Accuracy: 62.02%\n",
      "Epoch [5/10], Batch [301/5367], Loss: 2.7505, correct :11845, total: 19264, Batch Accuracy: 61.49%\n",
      "Epoch [5/10], Batch [401/5367], Loss: 2.7592, correct :15759, total: 25664, Batch Accuracy: 61.41%\n",
      "Epoch [5/10], Batch [501/5367], Loss: 2.7629, correct :19663, total: 32064, Batch Accuracy: 61.32%\n",
      "Epoch [5/10], Batch [601/5367], Loss: 2.7615, correct :23561, total: 38464, Batch Accuracy: 61.25%\n",
      "Epoch [5/10], Batch [701/5367], Loss: 2.7705, correct :27462, total: 44864, Batch Accuracy: 61.21%\n",
      "Epoch [5/10], Batch [801/5367], Loss: 2.7726, correct :31331, total: 51264, Batch Accuracy: 61.12%\n",
      "Epoch [5/10], Batch [901/5367], Loss: 2.7736, correct :35223, total: 57664, Batch Accuracy: 61.08%\n",
      "Epoch [5/10], Batch [1001/5367], Loss: 2.7851, correct :38997, total: 64064, Batch Accuracy: 60.87%\n",
      "Epoch [5/10], Batch [1101/5367], Loss: 2.7934, correct :42795, total: 70464, Batch Accuracy: 60.73%\n",
      "Epoch [5/10], Batch [1201/5367], Loss: 2.7953, correct :46659, total: 76864, Batch Accuracy: 60.70%\n",
      "Epoch [5/10], Batch [1301/5367], Loss: 2.7959, correct :50543, total: 83264, Batch Accuracy: 60.70%\n",
      "Epoch [5/10], Batch [1401/5367], Loss: 2.7983, correct :54417, total: 89664, Batch Accuracy: 60.69%\n",
      "Epoch [5/10], Batch [1501/5367], Loss: 2.8021, correct :58271, total: 96064, Batch Accuracy: 60.66%\n",
      "Epoch [5/10], Batch [1601/5367], Loss: 2.8045, correct :62115, total: 102464, Batch Accuracy: 60.62%\n",
      "Epoch [5/10], Batch [1701/5367], Loss: 2.8100, correct :65890, total: 108864, Batch Accuracy: 60.53%\n",
      "Epoch [5/10], Batch [1801/5367], Loss: 2.8097, correct :69774, total: 115264, Batch Accuracy: 60.53%\n",
      "Epoch [5/10], Batch [1901/5367], Loss: 2.8083, correct :73676, total: 121664, Batch Accuracy: 60.56%\n",
      "Epoch [5/10], Batch [2001/5367], Loss: 2.8119, correct :77459, total: 128064, Batch Accuracy: 60.48%\n",
      "Epoch [5/10], Batch [2101/5367], Loss: 2.8125, correct :81337, total: 134464, Batch Accuracy: 60.49%\n",
      "Epoch [5/10], Batch [2201/5367], Loss: 2.8132, correct :85222, total: 140864, Batch Accuracy: 60.50%\n",
      "Epoch [5/10], Batch [2301/5367], Loss: 2.8143, correct :89051, total: 147264, Batch Accuracy: 60.47%\n",
      "Epoch [5/10], Batch [2401/5367], Loss: 2.8171, correct :92901, total: 153664, Batch Accuracy: 60.46%\n",
      "Epoch [5/10], Batch [2501/5367], Loss: 2.8190, correct :96712, total: 160064, Batch Accuracy: 60.42%\n",
      "Epoch [5/10], Batch [2601/5367], Loss: 2.8175, correct :100578, total: 166464, Batch Accuracy: 60.42%\n",
      "Epoch [5/10], Batch [2701/5367], Loss: 2.8191, correct :104434, total: 172864, Batch Accuracy: 60.41%\n",
      "Epoch [5/10], Batch [2801/5367], Loss: 2.8179, correct :108360, total: 179264, Batch Accuracy: 60.45%\n",
      "Epoch [5/10], Batch [2901/5367], Loss: 2.8172, correct :112238, total: 185664, Batch Accuracy: 60.45%\n",
      "Epoch [5/10], Batch [3001/5367], Loss: 2.8175, correct :116126, total: 192064, Batch Accuracy: 60.46%\n",
      "Epoch [5/10], Batch [3101/5367], Loss: 2.8191, correct :119981, total: 198464, Batch Accuracy: 60.45%\n",
      "Epoch [5/10], Batch [3201/5367], Loss: 2.8218, correct :123754, total: 204864, Batch Accuracy: 60.41%\n",
      "Epoch [5/10], Batch [3301/5367], Loss: 2.8233, correct :127606, total: 211264, Batch Accuracy: 60.40%\n",
      "Epoch [5/10], Batch [3401/5367], Loss: 2.8246, correct :131439, total: 217664, Batch Accuracy: 60.39%\n",
      "Epoch [5/10], Batch [3501/5367], Loss: 2.8251, correct :135275, total: 224064, Batch Accuracy: 60.37%\n",
      "Epoch [5/10], Batch [3601/5367], Loss: 2.8261, correct :139133, total: 230464, Batch Accuracy: 60.37%\n",
      "Epoch [5/10], Batch [3701/5367], Loss: 2.8248, correct :143037, total: 236864, Batch Accuracy: 60.39%\n",
      "Epoch [5/10], Batch [3801/5367], Loss: 2.8232, correct :146975, total: 243264, Batch Accuracy: 60.42%\n",
      "Epoch [5/10], Batch [3901/5367], Loss: 2.8228, correct :150867, total: 249664, Batch Accuracy: 60.43%\n",
      "Epoch [5/10], Batch [4001/5367], Loss: 2.8228, correct :154747, total: 256064, Batch Accuracy: 60.43%\n",
      "Epoch [5/10], Batch [4101/5367], Loss: 2.8222, correct :158673, total: 262464, Batch Accuracy: 60.46%\n",
      "Epoch [5/10], Batch [4201/5367], Loss: 2.8221, correct :162573, total: 268864, Batch Accuracy: 60.47%\n",
      "Epoch [5/10], Batch [4301/5367], Loss: 2.8208, correct :166462, total: 275264, Batch Accuracy: 60.47%\n",
      "Epoch [5/10], Batch [4401/5367], Loss: 2.8200, correct :170436, total: 281664, Batch Accuracy: 60.51%\n",
      "Epoch [5/10], Batch [4501/5367], Loss: 2.8193, correct :174349, total: 288064, Batch Accuracy: 60.52%\n",
      "Epoch [5/10], Batch [4601/5367], Loss: 2.8187, correct :178265, total: 294464, Batch Accuracy: 60.54%\n",
      "Epoch [5/10], Batch [4701/5367], Loss: 2.8176, correct :182207, total: 300864, Batch Accuracy: 60.56%\n",
      "Epoch [5/10], Batch [4801/5367], Loss: 2.8162, correct :186155, total: 307264, Batch Accuracy: 60.58%\n",
      "Epoch [5/10], Batch [4901/5367], Loss: 2.8159, correct :190082, total: 313664, Batch Accuracy: 60.60%\n",
      "Epoch [5/10], Batch [5001/5367], Loss: 2.8149, correct :194046, total: 320064, Batch Accuracy: 60.63%\n",
      "Epoch [5/10], Batch [5101/5367], Loss: 2.8146, correct :197932, total: 326464, Batch Accuracy: 60.63%\n",
      "Epoch [5/10], Batch [5201/5367], Loss: 2.8139, correct :201833, total: 332864, Batch Accuracy: 60.64%\n",
      "Epoch [5/10], Batch [5301/5367], Loss: 2.8117, correct :205866, total: 339264, Batch Accuracy: 60.68%\n",
      "Epoch [5/10], Validation Loss: 3.2270, Validation Accuracy: 55.12%\n",
      "Epoch [5/10], Loss: 2.8116, Accuracy: 60.67%\n",
      "Epoch [6/10], Batch [1/5367], Loss: 2.0998, correct :45, total: 64, Batch Accuracy: 70.31%\n",
      "Epoch [6/10], Batch [101/5367], Loss: 2.3336, correct :4403, total: 6464, Batch Accuracy: 68.12%\n",
      "Epoch [6/10], Batch [201/5367], Loss: 2.3197, correct :8805, total: 12864, Batch Accuracy: 68.45%\n",
      "Epoch [6/10], Batch [301/5367], Loss: 2.3298, correct :13115, total: 19264, Batch Accuracy: 68.08%\n",
      "Epoch [6/10], Batch [401/5367], Loss: 2.3278, correct :17509, total: 25664, Batch Accuracy: 68.22%\n",
      "Epoch [6/10], Batch [501/5367], Loss: 2.3431, correct :21810, total: 32064, Batch Accuracy: 68.02%\n",
      "Epoch [6/10], Batch [601/5367], Loss: 2.3492, correct :26129, total: 38464, Batch Accuracy: 67.93%\n",
      "Epoch [6/10], Batch [701/5367], Loss: 2.3626, correct :30365, total: 44864, Batch Accuracy: 67.68%\n",
      "Epoch [6/10], Batch [801/5367], Loss: 2.3758, correct :34585, total: 51264, Batch Accuracy: 67.46%\n",
      "Epoch [6/10], Batch [901/5367], Loss: 2.3783, correct :38855, total: 57664, Batch Accuracy: 67.38%\n",
      "Epoch [6/10], Batch [1001/5367], Loss: 2.3902, correct :43071, total: 64064, Batch Accuracy: 67.23%\n",
      "Epoch [6/10], Batch [1101/5367], Loss: 2.3927, correct :47351, total: 70464, Batch Accuracy: 67.20%\n",
      "Epoch [6/10], Batch [1201/5367], Loss: 2.3985, correct :51597, total: 76864, Batch Accuracy: 67.13%\n",
      "Epoch [6/10], Batch [1301/5367], Loss: 2.4044, correct :55840, total: 83264, Batch Accuracy: 67.06%\n",
      "Epoch [6/10], Batch [1401/5367], Loss: 2.4141, correct :59986, total: 89664, Batch Accuracy: 66.90%\n",
      "Epoch [6/10], Batch [1501/5367], Loss: 2.4163, correct :64237, total: 96064, Batch Accuracy: 66.87%\n",
      "Epoch [6/10], Batch [1601/5367], Loss: 2.4182, correct :68493, total: 102464, Batch Accuracy: 66.85%\n",
      "Epoch [6/10], Batch [1701/5367], Loss: 2.4212, correct :72698, total: 108864, Batch Accuracy: 66.78%\n",
      "Epoch [6/10], Batch [1801/5367], Loss: 2.4283, correct :76885, total: 115264, Batch Accuracy: 66.70%\n",
      "Epoch [6/10], Batch [1901/5367], Loss: 2.4358, correct :80984, total: 121664, Batch Accuracy: 66.56%\n",
      "Epoch [6/10], Batch [2001/5367], Loss: 2.4409, correct :85112, total: 128064, Batch Accuracy: 66.46%\n",
      "Epoch [6/10], Batch [2101/5367], Loss: 2.4452, correct :89317, total: 134464, Batch Accuracy: 66.42%\n",
      "Epoch [6/10], Batch [2201/5367], Loss: 2.4459, correct :93531, total: 140864, Batch Accuracy: 66.40%\n",
      "Epoch [6/10], Batch [2301/5367], Loss: 2.4497, correct :97652, total: 147264, Batch Accuracy: 66.31%\n",
      "Epoch [6/10], Batch [2401/5367], Loss: 2.4524, correct :101786, total: 153664, Batch Accuracy: 66.24%\n",
      "Epoch [6/10], Batch [2501/5367], Loss: 2.4526, correct :106038, total: 160064, Batch Accuracy: 66.25%\n",
      "Epoch [6/10], Batch [2601/5367], Loss: 2.4531, correct :110275, total: 166464, Batch Accuracy: 66.25%\n",
      "Epoch [6/10], Batch [2701/5367], Loss: 2.4543, correct :114453, total: 172864, Batch Accuracy: 66.21%\n",
      "Epoch [6/10], Batch [2801/5367], Loss: 2.4564, correct :118658, total: 179264, Batch Accuracy: 66.19%\n",
      "Epoch [6/10], Batch [2901/5367], Loss: 2.4580, correct :122898, total: 185664, Batch Accuracy: 66.19%\n",
      "Epoch [6/10], Batch [3001/5367], Loss: 2.4591, correct :127085, total: 192064, Batch Accuracy: 66.17%\n",
      "Epoch [6/10], Batch [3101/5367], Loss: 2.4616, correct :131269, total: 198464, Batch Accuracy: 66.14%\n",
      "Epoch [6/10], Batch [3201/5367], Loss: 2.4597, correct :135553, total: 204864, Batch Accuracy: 66.17%\n",
      "Epoch [6/10], Batch [3301/5367], Loss: 2.4598, correct :139750, total: 211264, Batch Accuracy: 66.15%\n",
      "Epoch [6/10], Batch [3401/5367], Loss: 2.4593, correct :143989, total: 217664, Batch Accuracy: 66.15%\n",
      "Epoch [6/10], Batch [3501/5367], Loss: 2.4599, correct :148237, total: 224064, Batch Accuracy: 66.16%\n",
      "Epoch [6/10], Batch [3601/5367], Loss: 2.4629, correct :152425, total: 230464, Batch Accuracy: 66.14%\n",
      "Epoch [6/10], Batch [3701/5367], Loss: 2.4638, correct :156650, total: 236864, Batch Accuracy: 66.13%\n",
      "Epoch [6/10], Batch [3801/5367], Loss: 2.4660, correct :160849, total: 243264, Batch Accuracy: 66.12%\n",
      "Epoch [6/10], Batch [3901/5367], Loss: 2.4684, correct :165026, total: 249664, Batch Accuracy: 66.10%\n",
      "Epoch [6/10], Batch [4001/5367], Loss: 2.4695, correct :169239, total: 256064, Batch Accuracy: 66.09%\n",
      "Epoch [6/10], Batch [4101/5367], Loss: 2.4705, correct :173411, total: 262464, Batch Accuracy: 66.07%\n",
      "Epoch [6/10], Batch [4201/5367], Loss: 2.4709, correct :177657, total: 268864, Batch Accuracy: 66.08%\n",
      "Epoch [6/10], Batch [4301/5367], Loss: 2.4720, correct :181799, total: 275264, Batch Accuracy: 66.05%\n",
      "Epoch [6/10], Batch [4401/5367], Loss: 2.4724, correct :186019, total: 281664, Batch Accuracy: 66.04%\n",
      "Epoch [6/10], Batch [4501/5367], Loss: 2.4720, correct :190310, total: 288064, Batch Accuracy: 66.07%\n",
      "Epoch [6/10], Batch [4601/5367], Loss: 2.4713, correct :194574, total: 294464, Batch Accuracy: 66.08%\n",
      "Epoch [6/10], Batch [4701/5367], Loss: 2.4716, correct :198841, total: 300864, Batch Accuracy: 66.09%\n",
      "Epoch [6/10], Batch [4801/5367], Loss: 2.4714, correct :203117, total: 307264, Batch Accuracy: 66.11%\n",
      "Epoch [6/10], Batch [4901/5367], Loss: 2.4706, correct :207394, total: 313664, Batch Accuracy: 66.12%\n",
      "Epoch [6/10], Batch [5001/5367], Loss: 2.4711, correct :211591, total: 320064, Batch Accuracy: 66.11%\n",
      "Epoch [6/10], Batch [5101/5367], Loss: 2.4717, correct :215799, total: 326464, Batch Accuracy: 66.10%\n",
      "Epoch [6/10], Batch [5201/5367], Loss: 2.4708, correct :220049, total: 332864, Batch Accuracy: 66.11%\n",
      "Epoch [6/10], Batch [5301/5367], Loss: 2.4704, correct :224339, total: 339264, Batch Accuracy: 66.13%\n",
      "Epoch [6/10], Validation Loss: 2.8458, Validation Accuracy: 60.22%\n",
      "Epoch [6/10], Loss: 2.4707, Accuracy: 66.12%\n",
      "Epoch [7/10], Batch [1/5367], Loss: 2.4929, correct :40, total: 64, Batch Accuracy: 62.50%\n",
      "Epoch [7/10], Batch [101/5367], Loss: 2.0633, correct :4684, total: 6464, Batch Accuracy: 72.46%\n",
      "Epoch [7/10], Batch [201/5367], Loss: 2.0625, correct :9342, total: 12864, Batch Accuracy: 72.62%\n",
      "Epoch [7/10], Batch [301/5367], Loss: 2.0703, correct :13973, total: 19264, Batch Accuracy: 72.53%\n",
      "Epoch [7/10], Batch [401/5367], Loss: 2.0716, correct :18599, total: 25664, Batch Accuracy: 72.47%\n",
      "Epoch [7/10], Batch [501/5367], Loss: 2.0761, correct :23222, total: 32064, Batch Accuracy: 72.42%\n",
      "Epoch [7/10], Batch [601/5367], Loss: 2.0847, correct :27804, total: 38464, Batch Accuracy: 72.29%\n",
      "Epoch [7/10], Batch [701/5367], Loss: 2.0955, correct :32324, total: 44864, Batch Accuracy: 72.05%\n",
      "Epoch [7/10], Batch [801/5367], Loss: 2.1039, correct :36882, total: 51264, Batch Accuracy: 71.95%\n",
      "Epoch [7/10], Batch [901/5367], Loss: 2.1028, correct :41484, total: 57664, Batch Accuracy: 71.94%\n",
      "Epoch [7/10], Batch [1001/5367], Loss: 2.1077, correct :46025, total: 64064, Batch Accuracy: 71.84%\n",
      "Epoch [7/10], Batch [1101/5367], Loss: 2.1086, correct :50599, total: 70464, Batch Accuracy: 71.81%\n",
      "Epoch [7/10], Batch [1201/5367], Loss: 2.1110, correct :55153, total: 76864, Batch Accuracy: 71.75%\n",
      "Epoch [7/10], Batch [1301/5367], Loss: 2.1164, correct :59653, total: 83264, Batch Accuracy: 71.64%\n",
      "Epoch [7/10], Batch [1401/5367], Loss: 2.1217, correct :64162, total: 89664, Batch Accuracy: 71.56%\n",
      "Epoch [7/10], Batch [1501/5367], Loss: 2.1276, correct :68639, total: 96064, Batch Accuracy: 71.45%\n",
      "Epoch [7/10], Batch [1601/5367], Loss: 2.1344, correct :73128, total: 102464, Batch Accuracy: 71.37%\n",
      "Epoch [7/10], Batch [1701/5367], Loss: 2.1387, correct :77616, total: 108864, Batch Accuracy: 71.30%\n",
      "Epoch [7/10], Batch [1801/5367], Loss: 2.1431, correct :82100, total: 115264, Batch Accuracy: 71.23%\n",
      "Epoch [7/10], Batch [1901/5367], Loss: 2.1473, correct :86557, total: 121664, Batch Accuracy: 71.14%\n",
      "Epoch [7/10], Batch [2001/5367], Loss: 2.1481, correct :91089, total: 128064, Batch Accuracy: 71.13%\n",
      "Epoch [7/10], Batch [2101/5367], Loss: 2.1490, correct :95608, total: 134464, Batch Accuracy: 71.10%\n",
      "Epoch [7/10], Batch [2201/5367], Loss: 2.1515, correct :100095, total: 140864, Batch Accuracy: 71.06%\n",
      "Epoch [7/10], Batch [2301/5367], Loss: 2.1588, correct :104464, total: 147264, Batch Accuracy: 70.94%\n",
      "Epoch [7/10], Batch [2401/5367], Loss: 2.1611, correct :108903, total: 153664, Batch Accuracy: 70.87%\n",
      "Epoch [7/10], Batch [2501/5367], Loss: 2.1627, correct :113394, total: 160064, Batch Accuracy: 70.84%\n",
      "Epoch [7/10], Batch [2601/5367], Loss: 2.1669, correct :117806, total: 166464, Batch Accuracy: 70.77%\n",
      "Epoch [7/10], Batch [2701/5367], Loss: 2.1668, correct :122364, total: 172864, Batch Accuracy: 70.79%\n",
      "Epoch [7/10], Batch [2801/5367], Loss: 2.1673, correct :126879, total: 179264, Batch Accuracy: 70.78%\n",
      "Epoch [7/10], Batch [2901/5367], Loss: 2.1688, correct :131369, total: 185664, Batch Accuracy: 70.76%\n",
      "Epoch [7/10], Batch [3001/5367], Loss: 2.1709, correct :135861, total: 192064, Batch Accuracy: 70.74%\n",
      "Epoch [7/10], Batch [3101/5367], Loss: 2.1736, correct :140318, total: 198464, Batch Accuracy: 70.70%\n",
      "Epoch [7/10], Batch [3201/5367], Loss: 2.1763, correct :144784, total: 204864, Batch Accuracy: 70.67%\n",
      "Epoch [7/10], Batch [3301/5367], Loss: 2.1778, correct :149244, total: 211264, Batch Accuracy: 70.64%\n",
      "Epoch [7/10], Batch [3401/5367], Loss: 2.1805, correct :153681, total: 217664, Batch Accuracy: 70.60%\n",
      "Epoch [7/10], Batch [3501/5367], Loss: 2.1826, correct :158121, total: 224064, Batch Accuracy: 70.57%\n",
      "Epoch [7/10], Batch [3601/5367], Loss: 2.1851, correct :162563, total: 230464, Batch Accuracy: 70.54%\n",
      "Epoch [7/10], Batch [3701/5367], Loss: 2.1861, correct :167060, total: 236864, Batch Accuracy: 70.53%\n",
      "Epoch [7/10], Batch [3801/5367], Loss: 2.1872, correct :171509, total: 243264, Batch Accuracy: 70.50%\n",
      "Epoch [7/10], Batch [3901/5367], Loss: 2.1887, correct :175996, total: 249664, Batch Accuracy: 70.49%\n",
      "Epoch [7/10], Batch [4001/5367], Loss: 2.1911, correct :180423, total: 256064, Batch Accuracy: 70.46%\n",
      "Epoch [7/10], Batch [4101/5367], Loss: 2.1923, correct :184874, total: 262464, Batch Accuracy: 70.44%\n",
      "Epoch [7/10], Batch [4201/5367], Loss: 2.1930, correct :189357, total: 268864, Batch Accuracy: 70.43%\n",
      "Epoch [7/10], Batch [4301/5367], Loss: 2.1947, correct :193789, total: 275264, Batch Accuracy: 70.40%\n",
      "Epoch [7/10], Batch [4401/5367], Loss: 2.1964, correct :198255, total: 281664, Batch Accuracy: 70.39%\n",
      "Epoch [7/10], Batch [4501/5367], Loss: 2.1955, correct :202779, total: 288064, Batch Accuracy: 70.39%\n",
      "Epoch [7/10], Batch [4601/5367], Loss: 2.1958, correct :207304, total: 294464, Batch Accuracy: 70.40%\n",
      "Epoch [7/10], Batch [4701/5367], Loss: 2.1968, correct :211778, total: 300864, Batch Accuracy: 70.39%\n",
      "Epoch [7/10], Batch [4801/5367], Loss: 2.1971, correct :216266, total: 307264, Batch Accuracy: 70.38%\n",
      "Epoch [7/10], Batch [4901/5367], Loss: 2.1992, correct :220692, total: 313664, Batch Accuracy: 70.36%\n",
      "Epoch [7/10], Batch [5001/5367], Loss: 2.2011, correct :225128, total: 320064, Batch Accuracy: 70.34%\n",
      "Epoch [7/10], Batch [5101/5367], Loss: 2.2018, correct :229578, total: 326464, Batch Accuracy: 70.32%\n",
      "Epoch [7/10], Batch [5201/5367], Loss: 2.2025, correct :234034, total: 332864, Batch Accuracy: 70.31%\n",
      "Epoch [7/10], Batch [5301/5367], Loss: 2.2024, correct :238523, total: 339264, Batch Accuracy: 70.31%\n",
      "Epoch [7/10], Validation Loss: 2.5725, Validation Accuracy: 64.97%\n",
      "Epoch [7/10], Loss: 2.2030, Accuracy: 70.30%\n",
      "Epoch [8/10], Batch [1/5367], Loss: 1.5287, correct :55, total: 64, Batch Accuracy: 85.94%\n",
      "Epoch [8/10], Batch [101/5367], Loss: 1.8260, correct :4964, total: 6464, Batch Accuracy: 76.79%\n",
      "Epoch [8/10], Batch [201/5367], Loss: 1.8053, correct :9911, total: 12864, Batch Accuracy: 77.04%\n",
      "Epoch [8/10], Batch [301/5367], Loss: 1.8149, correct :14768, total: 19264, Batch Accuracy: 76.66%\n",
      "Epoch [8/10], Batch [401/5367], Loss: 1.8269, correct :19586, total: 25664, Batch Accuracy: 76.32%\n",
      "Epoch [8/10], Batch [501/5367], Loss: 1.8319, correct :24477, total: 32064, Batch Accuracy: 76.34%\n",
      "Epoch [8/10], Batch [601/5367], Loss: 1.8424, correct :29280, total: 38464, Batch Accuracy: 76.12%\n",
      "Epoch [8/10], Batch [701/5367], Loss: 1.8523, correct :34083, total: 44864, Batch Accuracy: 75.97%\n",
      "Epoch [8/10], Batch [801/5367], Loss: 1.8597, correct :38885, total: 51264, Batch Accuracy: 75.85%\n",
      "Epoch [8/10], Batch [901/5367], Loss: 1.8687, correct :43686, total: 57664, Batch Accuracy: 75.76%\n",
      "Epoch [8/10], Batch [1001/5367], Loss: 1.8737, correct :48459, total: 64064, Batch Accuracy: 75.64%\n",
      "Epoch [8/10], Batch [1101/5367], Loss: 1.8771, correct :53204, total: 70464, Batch Accuracy: 75.51%\n",
      "Epoch [8/10], Batch [1201/5367], Loss: 1.8853, correct :57904, total: 76864, Batch Accuracy: 75.33%\n",
      "Epoch [8/10], Batch [1301/5367], Loss: 1.8928, correct :62626, total: 83264, Batch Accuracy: 75.21%\n",
      "Epoch [8/10], Batch [1401/5367], Loss: 1.8960, correct :67400, total: 89664, Batch Accuracy: 75.17%\n",
      "Epoch [8/10], Batch [1501/5367], Loss: 1.9055, correct :72080, total: 96064, Batch Accuracy: 75.03%\n",
      "Epoch [8/10], Batch [1601/5367], Loss: 1.9104, correct :76792, total: 102464, Batch Accuracy: 74.95%\n",
      "Epoch [8/10], Batch [1701/5367], Loss: 1.9147, correct :81466, total: 108864, Batch Accuracy: 74.83%\n",
      "Epoch [8/10], Batch [1801/5367], Loss: 1.9196, correct :86158, total: 115264, Batch Accuracy: 74.75%\n",
      "Epoch [8/10], Batch [1901/5367], Loss: 1.9228, correct :90874, total: 121664, Batch Accuracy: 74.69%\n",
      "Epoch [8/10], Batch [2001/5367], Loss: 1.9255, correct :95585, total: 128064, Batch Accuracy: 74.64%\n",
      "Epoch [8/10], Batch [2101/5367], Loss: 1.9304, correct :100253, total: 134464, Batch Accuracy: 74.56%\n",
      "Epoch [8/10], Batch [2201/5367], Loss: 1.9343, correct :104966, total: 140864, Batch Accuracy: 74.52%\n",
      "Epoch [8/10], Batch [2301/5367], Loss: 1.9369, correct :109655, total: 147264, Batch Accuracy: 74.46%\n",
      "Epoch [8/10], Batch [2401/5367], Loss: 1.9439, correct :114232, total: 153664, Batch Accuracy: 74.34%\n",
      "Epoch [8/10], Batch [2501/5367], Loss: 1.9485, correct :118863, total: 160064, Batch Accuracy: 74.26%\n",
      "Epoch [8/10], Batch [2601/5367], Loss: 1.9511, correct :123552, total: 166464, Batch Accuracy: 74.22%\n",
      "Epoch [8/10], Batch [2701/5367], Loss: 1.9553, correct :128167, total: 172864, Batch Accuracy: 74.14%\n",
      "Epoch [8/10], Batch [2801/5367], Loss: 1.9585, correct :132802, total: 179264, Batch Accuracy: 74.08%\n",
      "Epoch [8/10], Batch [2901/5367], Loss: 1.9609, correct :137476, total: 185664, Batch Accuracy: 74.05%\n",
      "Epoch [8/10], Batch [3001/5367], Loss: 1.9633, correct :142158, total: 192064, Batch Accuracy: 74.02%\n",
      "Epoch [8/10], Batch [3101/5367], Loss: 1.9661, correct :146805, total: 198464, Batch Accuracy: 73.97%\n",
      "Epoch [8/10], Batch [3201/5367], Loss: 1.9701, correct :151402, total: 204864, Batch Accuracy: 73.90%\n",
      "Epoch [8/10], Batch [3301/5367], Loss: 1.9735, correct :155995, total: 211264, Batch Accuracy: 73.84%\n",
      "Epoch [8/10], Batch [3401/5367], Loss: 1.9744, correct :160671, total: 217664, Batch Accuracy: 73.82%\n",
      "Epoch [8/10], Batch [3501/5367], Loss: 1.9766, correct :165277, total: 224064, Batch Accuracy: 73.76%\n",
      "Epoch [8/10], Batch [3601/5367], Loss: 1.9775, correct :169953, total: 230464, Batch Accuracy: 73.74%\n",
      "Epoch [8/10], Batch [3701/5367], Loss: 1.9789, correct :174590, total: 236864, Batch Accuracy: 73.71%\n",
      "Epoch [8/10], Batch [3801/5367], Loss: 1.9810, correct :179222, total: 243264, Batch Accuracy: 73.67%\n",
      "Epoch [8/10], Batch [3901/5367], Loss: 1.9826, correct :183869, total: 249664, Batch Accuracy: 73.65%\n",
      "Epoch [8/10], Batch [4001/5367], Loss: 1.9838, correct :188517, total: 256064, Batch Accuracy: 73.62%\n",
      "Epoch [8/10], Batch [4101/5367], Loss: 1.9866, correct :193090, total: 262464, Batch Accuracy: 73.57%\n",
      "Epoch [8/10], Batch [4201/5367], Loss: 1.9880, correct :197723, total: 268864, Batch Accuracy: 73.54%\n",
      "Epoch [8/10], Batch [4301/5367], Loss: 1.9892, correct :202363, total: 275264, Batch Accuracy: 73.52%\n",
      "Epoch [8/10], Batch [4401/5367], Loss: 1.9917, correct :206947, total: 281664, Batch Accuracy: 73.47%\n",
      "Epoch [8/10], Batch [4501/5367], Loss: 1.9934, correct :211608, total: 288064, Batch Accuracy: 73.46%\n",
      "Epoch [8/10], Batch [4601/5367], Loss: 1.9937, correct :216280, total: 294464, Batch Accuracy: 73.45%\n",
      "Epoch [8/10], Batch [4701/5367], Loss: 1.9943, correct :220950, total: 300864, Batch Accuracy: 73.44%\n",
      "Epoch [8/10], Batch [4801/5367], Loss: 1.9954, correct :225583, total: 307264, Batch Accuracy: 73.42%\n",
      "Epoch [8/10], Batch [4901/5367], Loss: 1.9970, correct :230205, total: 313664, Batch Accuracy: 73.39%\n",
      "Epoch [8/10], Batch [5001/5367], Loss: 1.9977, correct :234843, total: 320064, Batch Accuracy: 73.37%\n",
      "Epoch [8/10], Batch [5101/5367], Loss: 1.9986, correct :239524, total: 326464, Batch Accuracy: 73.37%\n",
      "Epoch [8/10], Batch [5201/5367], Loss: 1.9993, correct :244218, total: 332864, Batch Accuracy: 73.37%\n",
      "Epoch [8/10], Batch [5301/5367], Loss: 2.0028, correct :248749, total: 339264, Batch Accuracy: 73.32%\n",
      "Epoch [8/10], Validation Loss: 2.3800, Validation Accuracy: 67.91%\n",
      "Epoch [8/10], Loss: 2.0032, Accuracy: 73.32%\n",
      "Epoch [9/10], Batch [1/5367], Loss: 1.4154, correct :53, total: 64, Batch Accuracy: 82.81%\n",
      "Epoch [9/10], Batch [101/5367], Loss: 1.5724, correct :5179, total: 6464, Batch Accuracy: 80.12%\n",
      "Epoch [9/10], Batch [201/5367], Loss: 1.6070, correct :10250, total: 12864, Batch Accuracy: 79.68%\n",
      "Epoch [9/10], Batch [301/5367], Loss: 1.6252, correct :15311, total: 19264, Batch Accuracy: 79.48%\n",
      "Epoch [9/10], Batch [401/5367], Loss: 1.6404, correct :20372, total: 25664, Batch Accuracy: 79.38%\n",
      "Epoch [9/10], Batch [501/5367], Loss: 1.6419, correct :25441, total: 32064, Batch Accuracy: 79.34%\n",
      "Epoch [9/10], Batch [601/5367], Loss: 1.6543, correct :30438, total: 38464, Batch Accuracy: 79.13%\n",
      "Epoch [9/10], Batch [701/5367], Loss: 1.6643, correct :35451, total: 44864, Batch Accuracy: 79.02%\n",
      "Epoch [9/10], Batch [801/5367], Loss: 1.6663, correct :40474, total: 51264, Batch Accuracy: 78.95%\n",
      "Epoch [9/10], Batch [901/5367], Loss: 1.6727, correct :45413, total: 57664, Batch Accuracy: 78.75%\n",
      "Epoch [9/10], Batch [1001/5367], Loss: 1.6784, correct :50339, total: 64064, Batch Accuracy: 78.58%\n",
      "Epoch [9/10], Batch [1101/5367], Loss: 1.6874, correct :55259, total: 70464, Batch Accuracy: 78.42%\n",
      "Epoch [9/10], Batch [1201/5367], Loss: 1.6961, correct :60172, total: 76864, Batch Accuracy: 78.28%\n",
      "Epoch [9/10], Batch [1301/5367], Loss: 1.7059, correct :65020, total: 83264, Batch Accuracy: 78.09%\n",
      "Epoch [9/10], Batch [1401/5367], Loss: 1.7108, correct :69939, total: 89664, Batch Accuracy: 78.00%\n",
      "Epoch [9/10], Batch [1501/5367], Loss: 1.7150, correct :74879, total: 96064, Batch Accuracy: 77.95%\n",
      "Epoch [9/10], Batch [1601/5367], Loss: 1.7214, correct :79803, total: 102464, Batch Accuracy: 77.88%\n",
      "Epoch [9/10], Batch [1701/5367], Loss: 1.7265, correct :84689, total: 108864, Batch Accuracy: 77.79%\n",
      "Epoch [9/10], Batch [1801/5367], Loss: 1.7308, correct :89584, total: 115264, Batch Accuracy: 77.72%\n",
      "Epoch [9/10], Batch [1901/5367], Loss: 1.7341, correct :94475, total: 121664, Batch Accuracy: 77.65%\n",
      "Epoch [9/10], Batch [2001/5367], Loss: 1.7392, correct :99325, total: 128064, Batch Accuracy: 77.56%\n",
      "Epoch [9/10], Batch [2101/5367], Loss: 1.7450, correct :104172, total: 134464, Batch Accuracy: 77.47%\n",
      "Epoch [9/10], Batch [2201/5367], Loss: 1.7507, correct :109014, total: 140864, Batch Accuracy: 77.39%\n",
      "Epoch [9/10], Batch [2301/5367], Loss: 1.7570, correct :113815, total: 147264, Batch Accuracy: 77.29%\n",
      "Epoch [9/10], Batch [2401/5367], Loss: 1.7618, correct :118615, total: 153664, Batch Accuracy: 77.19%\n",
      "Epoch [9/10], Batch [2501/5367], Loss: 1.7649, correct :123464, total: 160064, Batch Accuracy: 77.13%\n",
      "Epoch [9/10], Batch [2601/5367], Loss: 1.7697, correct :128303, total: 166464, Batch Accuracy: 77.08%\n",
      "Epoch [9/10], Batch [2701/5367], Loss: 1.7748, correct :133067, total: 172864, Batch Accuracy: 76.98%\n",
      "Epoch [9/10], Batch [2801/5367], Loss: 1.7789, correct :137855, total: 179264, Batch Accuracy: 76.90%\n",
      "Epoch [9/10], Batch [2901/5367], Loss: 1.7824, correct :142722, total: 185664, Batch Accuracy: 76.87%\n",
      "Epoch [9/10], Batch [3001/5367], Loss: 1.7873, correct :147472, total: 192064, Batch Accuracy: 76.78%\n",
      "Epoch [9/10], Batch [3101/5367], Loss: 1.7894, correct :152289, total: 198464, Batch Accuracy: 76.73%\n",
      "Epoch [9/10], Batch [3201/5367], Loss: 1.7929, correct :157072, total: 204864, Batch Accuracy: 76.67%\n",
      "Epoch [9/10], Batch [3301/5367], Loss: 1.7951, correct :161858, total: 211264, Batch Accuracy: 76.61%\n",
      "Epoch [9/10], Batch [3401/5367], Loss: 1.7985, correct :166613, total: 217664, Batch Accuracy: 76.55%\n",
      "Epoch [9/10], Batch [3501/5367], Loss: 1.8011, correct :171412, total: 224064, Batch Accuracy: 76.50%\n",
      "Epoch [9/10], Batch [3601/5367], Loss: 1.8051, correct :176155, total: 230464, Batch Accuracy: 76.43%\n",
      "Epoch [9/10], Batch [3701/5367], Loss: 1.8068, correct :180985, total: 236864, Batch Accuracy: 76.41%\n",
      "Epoch [9/10], Batch [3801/5367], Loss: 1.8089, correct :185794, total: 243264, Batch Accuracy: 76.38%\n",
      "Epoch [9/10], Batch [3901/5367], Loss: 1.8126, correct :190541, total: 249664, Batch Accuracy: 76.32%\n",
      "Epoch [9/10], Batch [4001/5367], Loss: 1.8142, correct :195323, total: 256064, Batch Accuracy: 76.28%\n",
      "Epoch [9/10], Batch [4101/5367], Loss: 1.8179, correct :200074, total: 262464, Batch Accuracy: 76.23%\n",
      "Epoch [9/10], Batch [4201/5367], Loss: 1.8201, correct :204862, total: 268864, Batch Accuracy: 76.20%\n",
      "Epoch [9/10], Batch [4301/5367], Loss: 1.8226, correct :209609, total: 275264, Batch Accuracy: 76.15%\n",
      "Epoch [9/10], Batch [4401/5367], Loss: 1.8246, correct :214408, total: 281664, Batch Accuracy: 76.12%\n",
      "Epoch [9/10], Batch [4501/5367], Loss: 1.8271, correct :219181, total: 288064, Batch Accuracy: 76.09%\n",
      "Epoch [9/10], Batch [4601/5367], Loss: 1.8287, correct :223959, total: 294464, Batch Accuracy: 76.06%\n",
      "Epoch [9/10], Batch [4701/5367], Loss: 1.8304, correct :228715, total: 300864, Batch Accuracy: 76.02%\n",
      "Epoch [9/10], Batch [4801/5367], Loss: 1.8311, correct :233529, total: 307264, Batch Accuracy: 76.00%\n",
      "Epoch [9/10], Batch [4901/5367], Loss: 1.8334, correct :238251, total: 313664, Batch Accuracy: 75.96%\n",
      "Epoch [9/10], Batch [5001/5367], Loss: 1.8353, correct :243006, total: 320064, Batch Accuracy: 75.92%\n",
      "Epoch [9/10], Batch [5101/5367], Loss: 1.8375, correct :247779, total: 326464, Batch Accuracy: 75.90%\n",
      "Epoch [9/10], Batch [5201/5367], Loss: 1.8391, correct :252567, total: 332864, Batch Accuracy: 75.88%\n",
      "Epoch [9/10], Batch [5301/5367], Loss: 1.8411, correct :257301, total: 339264, Batch Accuracy: 75.84%\n",
      "Epoch [9/10], Validation Loss: 2.3515, Validation Accuracy: 68.25%\n",
      "Epoch [9/10], Loss: 1.8425, Accuracy: 75.83%\n",
      "Epoch [10/10], Batch [1/5367], Loss: 1.6834, correct :56, total: 64, Batch Accuracy: 87.50%\n",
      "Epoch [10/10], Batch [101/5367], Loss: 1.5051, correct :5247, total: 6464, Batch Accuracy: 81.17%\n",
      "Epoch [10/10], Batch [201/5367], Loss: 1.5095, correct :10455, total: 12864, Batch Accuracy: 81.27%\n",
      "Epoch [10/10], Batch [301/5367], Loss: 1.5072, correct :15660, total: 19264, Batch Accuracy: 81.29%\n",
      "Epoch [10/10], Batch [401/5367], Loss: 1.5139, correct :20834, total: 25664, Batch Accuracy: 81.18%\n",
      "Epoch [10/10], Batch [501/5367], Loss: 1.5180, correct :26020, total: 32064, Batch Accuracy: 81.15%\n",
      "Epoch [10/10], Batch [601/5367], Loss: 1.5325, correct :31166, total: 38464, Batch Accuracy: 81.03%\n",
      "Epoch [10/10], Batch [701/5367], Loss: 1.5332, correct :36345, total: 44864, Batch Accuracy: 81.01%\n",
      "Epoch [10/10], Batch [801/5367], Loss: 1.5383, correct :41501, total: 51264, Batch Accuracy: 80.96%\n",
      "Epoch [10/10], Batch [901/5367], Loss: 1.5414, correct :46615, total: 57664, Batch Accuracy: 80.84%\n",
      "Epoch [10/10], Batch [1001/5367], Loss: 1.5528, correct :51649, total: 64064, Batch Accuracy: 80.62%\n",
      "Epoch [10/10], Batch [1101/5367], Loss: 1.5581, correct :56741, total: 70464, Batch Accuracy: 80.52%\n",
      "Epoch [10/10], Batch [1201/5367], Loss: 1.5652, correct :61772, total: 76864, Batch Accuracy: 80.37%\n",
      "Epoch [10/10], Batch [1301/5367], Loss: 1.5722, correct :66817, total: 83264, Batch Accuracy: 80.25%\n",
      "Epoch [10/10], Batch [1401/5367], Loss: 1.5754, correct :71912, total: 89664, Batch Accuracy: 80.20%\n",
      "Epoch [10/10], Batch [1501/5367], Loss: 1.5843, correct :76912, total: 96064, Batch Accuracy: 80.06%\n",
      "Epoch [10/10], Batch [1601/5367], Loss: 1.5929, correct :81902, total: 102464, Batch Accuracy: 79.93%\n",
      "Epoch [10/10], Batch [1701/5367], Loss: 1.6001, correct :86876, total: 108864, Batch Accuracy: 79.80%\n",
      "Epoch [10/10], Batch [1801/5367], Loss: 1.6061, correct :91878, total: 115264, Batch Accuracy: 79.71%\n",
      "Epoch [10/10], Batch [1901/5367], Loss: 1.6117, correct :96877, total: 121664, Batch Accuracy: 79.63%\n",
      "Epoch [10/10], Batch [2001/5367], Loss: 1.6158, correct :101858, total: 128064, Batch Accuracy: 79.54%\n",
      "Epoch [10/10], Batch [2101/5367], Loss: 1.6195, correct :106830, total: 134464, Batch Accuracy: 79.45%\n",
      "Epoch [10/10], Batch [2201/5367], Loss: 1.6267, correct :111792, total: 140864, Batch Accuracy: 79.36%\n",
      "Epoch [10/10], Batch [2301/5367], Loss: 1.6296, correct :116783, total: 147264, Batch Accuracy: 79.30%\n",
      "Epoch [10/10], Batch [2401/5367], Loss: 1.6321, correct :121788, total: 153664, Batch Accuracy: 79.26%\n",
      "Epoch [10/10], Batch [2501/5367], Loss: 1.6355, correct :126755, total: 160064, Batch Accuracy: 79.19%\n",
      "Epoch [10/10], Batch [2601/5367], Loss: 1.6391, correct :131716, total: 166464, Batch Accuracy: 79.13%\n",
      "Epoch [10/10], Batch [2701/5367], Loss: 1.6446, correct :136598, total: 172864, Batch Accuracy: 79.02%\n",
      "Epoch [10/10], Batch [2801/5367], Loss: 1.6489, correct :141539, total: 179264, Batch Accuracy: 78.96%\n",
      "Epoch [10/10], Batch [2901/5367], Loss: 1.6521, correct :146467, total: 185664, Batch Accuracy: 78.89%\n",
      "Epoch [10/10], Batch [3001/5367], Loss: 1.6552, correct :151389, total: 192064, Batch Accuracy: 78.82%\n",
      "Epoch [10/10], Batch [3101/5367], Loss: 1.6600, correct :156241, total: 198464, Batch Accuracy: 78.73%\n",
      "Epoch [10/10], Batch [3201/5367], Loss: 1.6631, correct :161190, total: 204864, Batch Accuracy: 78.68%\n",
      "Epoch [10/10], Batch [3301/5367], Loss: 1.6659, correct :166120, total: 211264, Batch Accuracy: 78.63%\n",
      "Epoch [10/10], Batch [3401/5367], Loss: 1.6697, correct :171014, total: 217664, Batch Accuracy: 78.57%\n",
      "Epoch [10/10], Batch [3501/5367], Loss: 1.6731, correct :175940, total: 224064, Batch Accuracy: 78.52%\n",
      "Epoch [10/10], Batch [3601/5367], Loss: 1.6747, correct :180908, total: 230464, Batch Accuracy: 78.50%\n",
      "Epoch [10/10], Batch [3701/5367], Loss: 1.6765, correct :185874, total: 236864, Batch Accuracy: 78.47%\n",
      "Epoch [10/10], Batch [3801/5367], Loss: 1.6778, correct :190838, total: 243264, Batch Accuracy: 78.45%\n",
      "Epoch [10/10], Batch [3901/5367], Loss: 1.6796, correct :195748, total: 249664, Batch Accuracy: 78.40%\n",
      "Epoch [10/10], Batch [4001/5367], Loss: 1.6820, correct :200679, total: 256064, Batch Accuracy: 78.37%\n",
      "Epoch [10/10], Batch [4101/5367], Loss: 1.6823, correct :205601, total: 262464, Batch Accuracy: 78.33%\n",
      "Epoch [10/10], Batch [4201/5367], Loss: 1.6846, correct :210525, total: 268864, Batch Accuracy: 78.30%\n",
      "Epoch [10/10], Batch [4301/5367], Loss: 1.6880, correct :215430, total: 275264, Batch Accuracy: 78.26%\n",
      "Epoch [10/10], Batch [4401/5367], Loss: 1.6906, correct :220328, total: 281664, Batch Accuracy: 78.22%\n",
      "Epoch [10/10], Batch [4501/5367], Loss: 1.6920, correct :225244, total: 288064, Batch Accuracy: 78.19%\n",
      "Epoch [10/10], Batch [4601/5367], Loss: 1.6942, correct :230150, total: 294464, Batch Accuracy: 78.16%\n",
      "Epoch [10/10], Batch [4701/5367], Loss: 1.6957, correct :235067, total: 300864, Batch Accuracy: 78.13%\n",
      "Epoch [10/10], Batch [4801/5367], Loss: 1.6977, correct :239950, total: 307264, Batch Accuracy: 78.09%\n",
      "Epoch [10/10], Batch [4901/5367], Loss: 1.7004, correct :244836, total: 313664, Batch Accuracy: 78.06%\n",
      "Epoch [10/10], Batch [5001/5367], Loss: 1.7031, correct :249687, total: 320064, Batch Accuracy: 78.01%\n",
      "Epoch [10/10], Batch [5101/5367], Loss: 1.7048, correct :254575, total: 326464, Batch Accuracy: 77.98%\n",
      "Epoch [10/10], Batch [5201/5367], Loss: 1.7061, correct :259475, total: 332864, Batch Accuracy: 77.95%\n",
      "Epoch [10/10], Batch [5301/5367], Loss: 1.7082, correct :264346, total: 339264, Batch Accuracy: 77.92%\n",
      "Epoch [10/10], Validation Loss: 2.2337, Validation Accuracy: 70.22%\n",
      "Epoch [10/10], Loss: 1.7090, Accuracy: 77.90%\n"
     ]
    }
   ],
   "source": [
    "# Define the temperature parameter for knowledge distillation\n",
    "temperature = 4.0  # You can adjust this value based on your needs\n",
    "# Define the loss function and optimizer for training the student model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "\n",
    "    #define running loss\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass for the teacher model (assuming it's already trained)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = teacher_model(inputs)\n",
    "\n",
    "        # Forward pass for the student model\n",
    "        optimizer_student.zero_grad()\n",
    "        outputs_student = student_model(inputs)\n",
    "\n",
    "        #Calculates the knowledge distillation loss using the Kullback-Leibler (KL) Divergence loss.It measures the difference between two probability distributions. In this case, it calculates the KL Divergence between the log-softmax predictions of the student model and the softmax predictions of the teacher model.\n",
    "\n",
    "        loss_distillation = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs_student / temperature, dim=1), #This part computes the logarithm of the softmax function applied to the output predictions of the student model divided by the temperature. The temperature is a hyperparameter that controls the smoothness of the probability distribution.\n",
    "                                           F.softmax(outputs_teacher / temperature, dim=1)) #Similarly, this part computes the softmax function applied to the output predictions of the teacher model divided by the temperature.\n",
    "\n",
    "        # Calculate the classification loss\n",
    "        loss_classification = criterion(outputs_student, labels)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_classification + loss_distillation\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs_student.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "        # Print batch statistics\n",
    "        if batch_idx % 100 == 0:  # Adjust the interval for printing\n",
    "            batch_accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / (batch_idx + 1):.4f}, correct :{correct}, total: {total}, Batch Accuracy: {batch_accuracy:.2f}%')\n",
    "\n",
    "    # Validation phase\n",
    "    student_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for val_batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "            # Forward pass for the teacher model\n",
    "            with torch.no_grad():\n",
    "                val_outputs_teacher = teacher_model(val_inputs)\n",
    "\n",
    "            # Forward pass for the student model\n",
    "            val_outputs_student = student_model(val_inputs)\n",
    "\n",
    "            # Calculate the classification loss for validation\n",
    "            val_loss_classification = criterion(val_outputs_student, val_labels)\n",
    "\n",
    "            # Calculate the knowledge distillation loss for validation\n",
    "            val_loss_distillation = nn.KLDivLoss(reduction='batchmean')(\n",
    "                F.log_softmax(val_outputs_student / temperature, dim=1),\n",
    "                F.softmax(val_outputs_teacher / temperature, dim=1)\n",
    "            )\n",
    "\n",
    "            # Total loss for validation\n",
    "            val_loss_batch = val_loss_classification + val_loss_distillation\n",
    "\n",
    "            val_loss += val_loss_batch.item()\n",
    "\n",
    "            _, val_predicted = val_outputs_student.max(1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += val_predicted.eq(val_labels).sum().item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Print validation statistics\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, '\n",
    "            f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "            \n",
    "    # Print training statistics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.95%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "student_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = student_model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model, 'KD_full_mobiFace_like_v2.pth') \n",
    "torch.save(student_model.state_dict(), 'KD_dict_mobiFace_live_v2.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
