{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "\n",
    "#import models\n",
    "from mobiface_like_v1 import MobiFace\n",
    "from backbone import get_model\n",
    "import model\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, also set the seed for GPU\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10575\n",
    "student = MobiFace()\n",
    "student.fc = nn.Linear(in_features=512, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobiFace                                      [1, 10575]                --\n",
       "├─Conv2d: 1-1                                 [1, 64, 56, 56]           1,728\n",
       "├─BatchNorm2d: 1-2                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-3                                  [1, 64, 56, 56]           1\n",
       "├─DepthwiseSeparableConv2d: 1-4               [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 56, 56]           576\n",
       "│    └─Conv2d: 2-2                            [1, 64, 56, 56]           4,096\n",
       "│    └─BatchNorm2d: 2-3                       [1, 64, 56, 56]           128\n",
       "│    └─PReLU: 2-4                             [1, 64, 56, 56]           1\n",
       "├─BatchNorm2d: 1-5                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-6                                  [1, 64, 56, 56]           (recursive)\n",
       "├─BottleneckBlock: 1-7                        [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-5                            [1, 32, 56, 56]           2,048\n",
       "│    └─BatchNorm2d: 2-6                       [1, 32, 56, 56]           64\n",
       "│    └─PReLU: 2-7                             [1, 32, 56, 56]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-8          [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                       [1, 32, 28, 28]           288\n",
       "│    │    └─Conv2d: 3-2                       [1, 32, 28, 28]           1,024\n",
       "│    │    └─BatchNorm2d: 3-3                  [1, 32, 28, 28]           64\n",
       "│    │    └─PReLU: 3-4                        [1, 32, 28, 28]           1\n",
       "│    └─BatchNorm2d: 2-9                       [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-10                            [1, 32, 28, 28]           (recursive)\n",
       "│    └─Conv2d: 2-11                           [1, 64, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-12                      [1, 64, 28, 28]           128\n",
       "├─InvertedResidualBlock: 1-8                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-13                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-14                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-15                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-16         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-5                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-6                       [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-8                        [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-17                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-18                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-19                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-20                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-21                       [1, 64, 28, 28]           --\n",
       "├─BottleneckBlock: 1-9                        [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-22                           [1, 32, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-23                      [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-24                            [1, 32, 28, 28]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-25         [1, 32, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-9                       [1, 32, 14, 14]           288\n",
       "│    │    └─Conv2d: 3-10                      [1, 32, 14, 14]           1,024\n",
       "│    │    └─BatchNorm2d: 3-11                 [1, 32, 14, 14]           64\n",
       "│    │    └─PReLU: 3-12                       [1, 32, 14, 14]           1\n",
       "│    └─BatchNorm2d: 2-26                      [1, 32, 14, 14]           64\n",
       "│    └─PReLU: 2-27                            [1, 32, 14, 14]           (recursive)\n",
       "│    └─Conv2d: 2-28                           [1, 128, 14, 14]          4,096\n",
       "│    └─BatchNorm2d: 2-29                      [1, 128, 14, 14]          256\n",
       "├─InvertedResidualBlock: 1-10                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-30                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-31                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-32                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-33         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-13                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-14                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-15                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-16                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-34                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-35                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-36                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-37                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-38                       [1, 128, 14, 14]          --\n",
       "├─BottleneckBlock: 1-11                       [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-39                           [1, 64, 14, 14]           8,192\n",
       "│    └─BatchNorm2d: 2-40                      [1, 64, 14, 14]           128\n",
       "│    └─PReLU: 2-41                            [1, 64, 14, 14]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-42         [1, 64, 7, 7]             --\n",
       "│    │    └─Conv2d: 3-17                      [1, 64, 7, 7]             576\n",
       "│    │    └─Conv2d: 3-18                      [1, 64, 7, 7]             4,096\n",
       "│    │    └─BatchNorm2d: 3-19                 [1, 64, 7, 7]             128\n",
       "│    │    └─PReLU: 3-20                       [1, 64, 7, 7]             1\n",
       "│    └─BatchNorm2d: 2-43                      [1, 64, 7, 7]             128\n",
       "│    └─PReLU: 2-44                            [1, 64, 7, 7]             (recursive)\n",
       "│    └─Conv2d: 2-45                           [1, 256, 7, 7]            16,384\n",
       "│    └─BatchNorm2d: 2-46                      [1, 256, 7, 7]            512\n",
       "├─InvertedResidualBlock: 1-12                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-47                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-48                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-49                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-50         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-21                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-22                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-23                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-24                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-51                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-52                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-53                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-54                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-55                       [1, 256, 7, 7]            --\n",
       "├─Conv2d: 1-13                                [1, 512, 7, 7]            131,072\n",
       "├─BatchNorm2d: 1-14                           [1, 512, 7, 7]            1,024\n",
       "├─Linear: 1-15                                [1, 10575]                5,424,975\n",
       "===============================================================================================\n",
       "Total params: 6,310,109\n",
       "Trainable params: 6,310,109\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 124.94\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 35.36\n",
       "Params size (MB): 25.24\n",
       "Estimated Total Size (MB): 60.75\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(student, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher =  torch.load(\"full_webcassia_finetuned_v2.pth\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionResnetV1(\n",
       "  (conv2d_1a): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2a): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2b): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_3b): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4a): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4b): BasicConv2d(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (repeat_1): Sequential(\n",
       "    (0): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_6a): Mixed_6a(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_2): Sequential(\n",
       "    (0): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_7a): Mixed_7a(\n",
       "    (branch0): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_3): Sequential(\n",
       "    (0): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (block8): Block8(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "InceptionResnetV1                             [1, 10575]                --\n",
       "├─BasicConv2d: 1-1                            [1, 32, 55, 55]           --\n",
       "│    └─Conv2d: 2-1                            [1, 32, 55, 55]           (864)\n",
       "│    └─BatchNorm2d: 2-2                       [1, 32, 55, 55]           (64)\n",
       "│    └─ReLU: 2-3                              [1, 32, 55, 55]           --\n",
       "├─BasicConv2d: 1-2                            [1, 32, 53, 53]           --\n",
       "│    └─Conv2d: 2-4                            [1, 32, 53, 53]           (9,216)\n",
       "│    └─BatchNorm2d: 2-5                       [1, 32, 53, 53]           (64)\n",
       "│    └─ReLU: 2-6                              [1, 32, 53, 53]           --\n",
       "├─BasicConv2d: 1-3                            [1, 64, 53, 53]           --\n",
       "│    └─Conv2d: 2-7                            [1, 64, 53, 53]           (18,432)\n",
       "│    └─BatchNorm2d: 2-8                       [1, 64, 53, 53]           (128)\n",
       "│    └─ReLU: 2-9                              [1, 64, 53, 53]           --\n",
       "├─MaxPool2d: 1-4                              [1, 64, 26, 26]           --\n",
       "├─BasicConv2d: 1-5                            [1, 80, 26, 26]           --\n",
       "│    └─Conv2d: 2-10                           [1, 80, 26, 26]           (5,120)\n",
       "│    └─BatchNorm2d: 2-11                      [1, 80, 26, 26]           (160)\n",
       "│    └─ReLU: 2-12                             [1, 80, 26, 26]           --\n",
       "├─BasicConv2d: 1-6                            [1, 192, 24, 24]          --\n",
       "│    └─Conv2d: 2-13                           [1, 192, 24, 24]          (138,240)\n",
       "│    └─BatchNorm2d: 2-14                      [1, 192, 24, 24]          (384)\n",
       "│    └─ReLU: 2-15                             [1, 192, 24, 24]          --\n",
       "├─BasicConv2d: 1-7                            [1, 256, 11, 11]          --\n",
       "│    └─Conv2d: 2-16                           [1, 256, 11, 11]          (442,368)\n",
       "│    └─BatchNorm2d: 2-17                      [1, 256, 11, 11]          (512)\n",
       "│    └─ReLU: 2-18                             [1, 256, 11, 11]          --\n",
       "├─Sequential: 1-8                             [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-19                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-1                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-2                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-3                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-4                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-5                         [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-20                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-6                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-7                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-8                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-9                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-10                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-21                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-11                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-12                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-13                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-14                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-15                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-22                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-16                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-17                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-18                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-19                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-20                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-23                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-21                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-22                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-23                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-24                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-25                        [1, 256, 11, 11]          --\n",
       "├─Mixed_6a: 1-9                               [1, 896, 5, 5]            --\n",
       "│    └─BasicConv2d: 2-24                      [1, 384, 5, 5]            --\n",
       "│    │    └─Conv2d: 3-26                      [1, 384, 5, 5]            (884,736)\n",
       "│    │    └─BatchNorm2d: 3-27                 [1, 384, 5, 5]            (768)\n",
       "│    │    └─ReLU: 3-28                        [1, 384, 5, 5]            --\n",
       "│    └─Sequential: 2-25                       [1, 256, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-29                 [1, 192, 11, 11]          (49,536)\n",
       "│    │    └─BasicConv2d: 3-30                 [1, 192, 11, 11]          (332,160)\n",
       "│    │    └─BasicConv2d: 3-31                 [1, 256, 5, 5]            (442,880)\n",
       "│    └─MaxPool2d: 2-26                        [1, 256, 5, 5]            --\n",
       "├─Sequential: 1-10                            [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-27                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-32                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-33                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-34                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-35                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-28                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-36                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-37                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-38                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-39                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-29                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-40                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-41                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-42                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-43                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-30                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-44                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-45                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-46                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-47                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-31                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-48                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-49                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-50                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-51                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-32                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-52                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-53                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-54                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-55                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-33                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-56                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-57                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-58                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-59                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-34                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-60                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-61                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-62                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-63                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-35                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-64                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-65                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-66                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-67                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-36                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-68                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-69                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-70                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-71                        [1, 896, 5, 5]            --\n",
       "├─Mixed_7a: 1-11                              [1, 1792, 2, 2]           --\n",
       "│    └─Sequential: 2-37                       [1, 384, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-72                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-73                 [1, 384, 2, 2]            (885,504)\n",
       "│    └─Sequential: 2-38                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-74                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-75                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─Sequential: 2-39                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-76                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-77                 [1, 256, 5, 5]            (590,336)\n",
       "│    │    └─BasicConv2d: 3-78                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─MaxPool2d: 2-40                        [1, 896, 2, 2]            --\n",
       "├─Sequential: 1-12                            [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-41                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-79                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-80                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-81                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-82                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-42                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-83                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-84                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-85                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-86                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-43                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-87                 [1, 192, 2, 2]            344,448\n",
       "│    │    └─Sequential: 3-88                  [1, 192, 2, 2]            566,400\n",
       "│    │    └─Conv2d: 3-89                      [1, 1792, 2, 2]           689,920\n",
       "│    │    └─ReLU: 3-90                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-44                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-91                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-92                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-93                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-94                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-45                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-95                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-96                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-97                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-98                        [1, 1792, 2, 2]           --\n",
       "├─Block8: 1-13                                [1, 1792, 2, 2]           --\n",
       "│    └─BasicConv2d: 2-46                      [1, 192, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-99                      [1, 192, 2, 2]            344,064\n",
       "│    │    └─BatchNorm2d: 3-100                [1, 192, 2, 2]            384\n",
       "│    │    └─ReLU: 3-101                       [1, 192, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       [1, 192, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-102                [1, 192, 2, 2]            344,448\n",
       "│    │    └─BasicConv2d: 3-103                [1, 192, 2, 2]            110,976\n",
       "│    │    └─BasicConv2d: 3-104                [1, 192, 2, 2]            110,976\n",
       "│    └─Conv2d: 2-48                           [1, 1792, 2, 2]           689,920\n",
       "├─AdaptiveAvgPool2d: 1-14                     [1, 1792, 1, 1]           --\n",
       "├─Dropout: 1-15                               [1, 1792, 1, 1]           --\n",
       "├─Linear: 1-16                                [1, 512]                  917,504\n",
       "├─BatchNorm1d: 1-17                           [1, 512]                  1,024\n",
       "├─Linear: 1-18                                [1, 10575]                5,424,975\n",
       "===============================================================================================\n",
       "Total params: 28,907,599\n",
       "Trainable params: 9,545,039\n",
       "Non-trainable params: 19,362,560\n",
       "Total mult-adds (M): 600.00\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 18.13\n",
       "Params size (MB): 115.63\n",
       "Estimated Total Size (MB): 133.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(teacher, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KD Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for test\n",
    "#root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\small_sample\"\n",
    "root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\images\"\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Create ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# Number of images for testing\n",
    "num_test_images = 2000\n",
    "\n",
    "# Total number of images\n",
    "total_images = len(dataset)\n",
    "\n",
    "# Indices of images for testing\n",
    "test_indices = random.sample(range(total_images), num_test_images)\n",
    "\n",
    "# Remaining indices for validation and training\n",
    "remaining_indices = set(range(total_images)) - set(test_indices)\n",
    "\n",
    "\n",
    "# Split remaining indices into validation and training sets\n",
    "remaining_indices = list(remaining_indices)\n",
    "random.shuffle(remaining_indices)\n",
    "\n",
    "\n",
    "# Define the sizes of validation and training sets\n",
    "val_size = int(0.30 * len(remaining_indices))\n",
    "train_size = len(remaining_indices) - val_size\n",
    "\n",
    "# Indices for validation and training sets\n",
    "val_indices = remaining_indices[:val_size]\n",
    "train_indices = remaining_indices[val_size:]\n",
    "\n",
    "\n",
    "# Create Subset datasets\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiFace(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bottleneck_block1): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block2): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block3): BottleneckBlock(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): PReLU(num_parameters=1)\n",
       "  (fc): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = student\n",
    "teacher_model = teacher\n",
    "\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [1/2673], Loss: 10.2849, correct :0, total: 128, Batch Accuracy: 0.00%\n",
      "Epoch [1/15], Batch [101/2673], Loss: 10.0633, correct :28, total: 12928, Batch Accuracy: 0.22%\n",
      "Epoch [1/15], Batch [201/2673], Loss: 9.8916, correct :73, total: 25728, Batch Accuracy: 0.28%\n",
      "Epoch [1/15], Batch [301/2673], Loss: 9.7467, correct :139, total: 38528, Batch Accuracy: 0.36%\n",
      "Epoch [1/15], Batch [401/2673], Loss: 9.6098, correct :270, total: 51328, Batch Accuracy: 0.53%\n",
      "Epoch [1/15], Batch [501/2673], Loss: 9.4818, correct :442, total: 64128, Batch Accuracy: 0.69%\n",
      "Epoch [1/15], Batch [601/2673], Loss: 9.3630, correct :670, total: 76928, Batch Accuracy: 0.87%\n",
      "Epoch [1/15], Batch [701/2673], Loss: 9.2532, correct :954, total: 89728, Batch Accuracy: 1.06%\n",
      "Epoch [1/15], Batch [801/2673], Loss: 9.1470, correct :1315, total: 102528, Batch Accuracy: 1.28%\n",
      "Epoch [1/15], Batch [901/2673], Loss: 9.0471, correct :1747, total: 115328, Batch Accuracy: 1.51%\n",
      "Epoch [1/15], Batch [1001/2673], Loss: 8.9513, correct :2234, total: 128128, Batch Accuracy: 1.74%\n",
      "Epoch [1/15], Batch [1101/2673], Loss: 8.8564, correct :2855, total: 140928, Batch Accuracy: 2.03%\n",
      "Epoch [1/15], Batch [1201/2673], Loss: 8.7675, correct :3555, total: 153728, Batch Accuracy: 2.31%\n",
      "Epoch [1/15], Batch [1301/2673], Loss: 8.6822, correct :4309, total: 166528, Batch Accuracy: 2.59%\n",
      "Epoch [1/15], Batch [1401/2673], Loss: 8.5985, correct :5120, total: 179328, Batch Accuracy: 2.86%\n",
      "Epoch [1/15], Batch [1501/2673], Loss: 8.5176, correct :6035, total: 192128, Batch Accuracy: 3.14%\n",
      "Epoch [1/15], Batch [1601/2673], Loss: 8.4386, correct :7131, total: 204928, Batch Accuracy: 3.48%\n",
      "Epoch [1/15], Batch [1701/2673], Loss: 8.3642, correct :8312, total: 217728, Batch Accuracy: 3.82%\n",
      "Epoch [1/15], Batch [1801/2673], Loss: 8.2912, correct :9582, total: 230528, Batch Accuracy: 4.16%\n",
      "Epoch [1/15], Batch [1901/2673], Loss: 8.2213, correct :10967, total: 243328, Batch Accuracy: 4.51%\n",
      "Epoch [1/15], Batch [2001/2673], Loss: 8.1520, correct :12362, total: 256128, Batch Accuracy: 4.83%\n",
      "Epoch [1/15], Batch [2101/2673], Loss: 8.0830, correct :13935, total: 268928, Batch Accuracy: 5.18%\n",
      "Epoch [1/15], Batch [2201/2673], Loss: 8.0171, correct :15542, total: 281728, Batch Accuracy: 5.52%\n",
      "Epoch [1/15], Batch [2301/2673], Loss: 7.9520, correct :17356, total: 294528, Batch Accuracy: 5.89%\n",
      "Epoch [1/15], Batch [2401/2673], Loss: 7.8883, correct :19196, total: 307328, Batch Accuracy: 6.25%\n",
      "Epoch [1/15], Batch [2501/2673], Loss: 7.8244, correct :21251, total: 320128, Batch Accuracy: 6.64%\n",
      "Epoch [1/15], Batch [2601/2673], Loss: 7.7621, correct :23412, total: 332928, Batch Accuracy: 7.03%\n",
      "Epoch [1/15], Validation Loss: 0.0000, Validation Accuracy: 14.72%\n",
      "Epoch [2/15], Batch [1/2673], Loss: 5.9766, correct :24, total: 128, Batch Accuracy: 18.75%\n",
      "Epoch [2/15], Batch [101/2673], Loss: 6.0193, correct :2199, total: 12928, Batch Accuracy: 17.01%\n",
      "Epoch [2/15], Batch [201/2673], Loss: 5.9978, correct :4590, total: 25728, Batch Accuracy: 17.84%\n",
      "Epoch [2/15], Batch [301/2673], Loss: 5.9585, correct :7028, total: 38528, Batch Accuracy: 18.24%\n",
      "Epoch [2/15], Batch [401/2673], Loss: 5.9130, correct :9673, total: 51328, Batch Accuracy: 18.85%\n",
      "Epoch [2/15], Batch [501/2673], Loss: 5.8633, correct :12443, total: 64128, Batch Accuracy: 19.40%\n",
      "Epoch [2/15], Batch [601/2673], Loss: 5.8164, correct :15386, total: 76928, Batch Accuracy: 20.00%\n",
      "Epoch [2/15], Batch [701/2673], Loss: 5.7782, correct :18311, total: 89728, Batch Accuracy: 20.41%\n",
      "Epoch [2/15], Batch [801/2673], Loss: 5.7416, correct :21363, total: 102528, Batch Accuracy: 20.84%\n",
      "Epoch [2/15], Batch [901/2673], Loss: 5.7010, correct :24527, total: 115328, Batch Accuracy: 21.27%\n",
      "Epoch [2/15], Batch [1001/2673], Loss: 5.6636, correct :27806, total: 128128, Batch Accuracy: 21.70%\n",
      "Epoch [2/15], Batch [1101/2673], Loss: 5.6290, correct :31183, total: 140928, Batch Accuracy: 22.13%\n",
      "Epoch [2/15], Batch [1201/2673], Loss: 5.5940, correct :34603, total: 153728, Batch Accuracy: 22.51%\n",
      "Epoch [2/15], Batch [1301/2673], Loss: 5.5597, correct :38115, total: 166528, Batch Accuracy: 22.89%\n",
      "Epoch [2/15], Batch [1401/2673], Loss: 5.5238, correct :41802, total: 179328, Batch Accuracy: 23.31%\n",
      "Epoch [2/15], Batch [1501/2673], Loss: 5.4886, correct :45646, total: 192128, Batch Accuracy: 23.76%\n",
      "Epoch [2/15], Batch [1601/2673], Loss: 5.4535, correct :49541, total: 204928, Batch Accuracy: 24.17%\n",
      "Epoch [2/15], Batch [1701/2673], Loss: 5.4235, correct :53441, total: 217728, Batch Accuracy: 24.54%\n",
      "Epoch [2/15], Batch [1801/2673], Loss: 5.3931, correct :57469, total: 230528, Batch Accuracy: 24.93%\n",
      "Epoch [2/15], Batch [1901/2673], Loss: 5.3638, correct :61532, total: 243328, Batch Accuracy: 25.29%\n",
      "Epoch [2/15], Batch [2001/2673], Loss: 5.3338, correct :65689, total: 256128, Batch Accuracy: 25.65%\n",
      "Epoch [2/15], Batch [2101/2673], Loss: 5.3036, correct :70026, total: 268928, Batch Accuracy: 26.04%\n",
      "Epoch [2/15], Batch [2201/2673], Loss: 5.2751, correct :74289, total: 281728, Batch Accuracy: 26.37%\n",
      "Epoch [2/15], Batch [2301/2673], Loss: 5.2452, correct :78790, total: 294528, Batch Accuracy: 26.75%\n",
      "Epoch [2/15], Batch [2401/2673], Loss: 5.2160, correct :83331, total: 307328, Batch Accuracy: 27.11%\n",
      "Epoch [2/15], Batch [2501/2673], Loss: 5.1858, correct :88088, total: 320128, Batch Accuracy: 27.52%\n",
      "Epoch [2/15], Batch [2601/2673], Loss: 5.1567, correct :92865, total: 332928, Batch Accuracy: 27.89%\n",
      "Epoch [2/15], Validation Loss: 0.0000, Validation Accuracy: 34.64%\n",
      "Epoch [3/15], Batch [1/2673], Loss: 4.1052, correct :54, total: 128, Batch Accuracy: 42.19%\n",
      "Epoch [3/15], Batch [101/2673], Loss: 4.3072, correct :4866, total: 12928, Batch Accuracy: 37.64%\n",
      "Epoch [3/15], Batch [201/2673], Loss: 4.3119, correct :9838, total: 25728, Batch Accuracy: 38.24%\n",
      "Epoch [3/15], Batch [301/2673], Loss: 4.2984, correct :14868, total: 38528, Batch Accuracy: 38.59%\n",
      "Epoch [3/15], Batch [401/2673], Loss: 4.2700, correct :20061, total: 51328, Batch Accuracy: 39.08%\n",
      "Epoch [3/15], Batch [501/2673], Loss: 4.2438, correct :25292, total: 64128, Batch Accuracy: 39.44%\n",
      "Epoch [3/15], Batch [601/2673], Loss: 4.2131, correct :30696, total: 76928, Batch Accuracy: 39.90%\n",
      "Epoch [3/15], Batch [701/2673], Loss: 4.1952, correct :36099, total: 89728, Batch Accuracy: 40.23%\n",
      "Epoch [3/15], Batch [801/2673], Loss: 4.1783, correct :41526, total: 102528, Batch Accuracy: 40.50%\n",
      "Epoch [3/15], Batch [901/2673], Loss: 4.1527, correct :47113, total: 115328, Batch Accuracy: 40.85%\n",
      "Epoch [3/15], Batch [1001/2673], Loss: 4.1355, correct :52670, total: 128128, Batch Accuracy: 41.11%\n",
      "Epoch [3/15], Batch [1101/2673], Loss: 4.1212, correct :58309, total: 140928, Batch Accuracy: 41.38%\n",
      "Epoch [3/15], Batch [1201/2673], Loss: 4.1041, correct :63986, total: 153728, Batch Accuracy: 41.62%\n",
      "Epoch [3/15], Batch [1301/2673], Loss: 4.0854, correct :69734, total: 166528, Batch Accuracy: 41.88%\n",
      "Epoch [3/15], Batch [1401/2673], Loss: 4.0655, correct :75595, total: 179328, Batch Accuracy: 42.15%\n",
      "Epoch [3/15], Batch [1501/2673], Loss: 4.0478, correct :81588, total: 192128, Batch Accuracy: 42.47%\n",
      "Epoch [3/15], Batch [1601/2673], Loss: 4.0285, correct :87610, total: 204928, Batch Accuracy: 42.75%\n",
      "Epoch [3/15], Batch [1701/2673], Loss: 4.0142, correct :93567, total: 217728, Batch Accuracy: 42.97%\n",
      "Epoch [3/15], Batch [1801/2673], Loss: 4.0006, correct :99581, total: 230528, Batch Accuracy: 43.20%\n",
      "Epoch [3/15], Batch [1901/2673], Loss: 3.9860, correct :105659, total: 243328, Batch Accuracy: 43.42%\n",
      "Epoch [3/15], Batch [2001/2673], Loss: 3.9710, correct :111785, total: 256128, Batch Accuracy: 43.64%\n",
      "Epoch [3/15], Batch [2101/2673], Loss: 3.9566, correct :117964, total: 268928, Batch Accuracy: 43.86%\n",
      "Epoch [3/15], Batch [2201/2673], Loss: 3.9416, correct :124176, total: 281728, Batch Accuracy: 44.08%\n",
      "Epoch [3/15], Batch [2301/2673], Loss: 3.9268, correct :130475, total: 294528, Batch Accuracy: 44.30%\n",
      "Epoch [3/15], Batch [2401/2673], Loss: 3.9110, correct :136901, total: 307328, Batch Accuracy: 44.55%\n",
      "Epoch [3/15], Batch [2501/2673], Loss: 3.8942, correct :143449, total: 320128, Batch Accuracy: 44.81%\n",
      "Epoch [3/15], Batch [2601/2673], Loss: 3.8784, correct :149972, total: 332928, Batch Accuracy: 45.05%\n",
      "Epoch [3/15], Validation Loss: 0.0000, Validation Accuracy: 44.81%\n",
      "Epoch [4/15], Batch [1/2673], Loss: 3.2425, correct :66, total: 128, Batch Accuracy: 51.56%\n",
      "Epoch [4/15], Batch [101/2673], Loss: 3.3946, correct :6683, total: 12928, Batch Accuracy: 51.69%\n",
      "Epoch [4/15], Batch [201/2673], Loss: 3.4219, correct :13270, total: 25728, Batch Accuracy: 51.58%\n",
      "Epoch [4/15], Batch [301/2673], Loss: 3.4184, correct :19951, total: 38528, Batch Accuracy: 51.78%\n",
      "Epoch [4/15], Batch [401/2673], Loss: 3.4023, correct :26752, total: 51328, Batch Accuracy: 52.12%\n",
      "Epoch [4/15], Batch [501/2673], Loss: 3.3872, correct :33603, total: 64128, Batch Accuracy: 52.40%\n",
      "Epoch [4/15], Batch [601/2673], Loss: 3.3658, correct :40554, total: 76928, Batch Accuracy: 52.72%\n",
      "Epoch [4/15], Batch [701/2673], Loss: 3.3565, correct :47496, total: 89728, Batch Accuracy: 52.93%\n",
      "Epoch [4/15], Batch [801/2673], Loss: 3.3484, correct :54395, total: 102528, Batch Accuracy: 53.05%\n",
      "Epoch [4/15], Batch [901/2673], Loss: 3.3310, correct :61529, total: 115328, Batch Accuracy: 53.35%\n",
      "Epoch [4/15], Batch [1001/2673], Loss: 3.3225, correct :68540, total: 128128, Batch Accuracy: 53.49%\n",
      "Epoch [4/15], Batch [1101/2673], Loss: 3.3159, correct :75562, total: 140928, Batch Accuracy: 53.62%\n",
      "Epoch [4/15], Batch [1201/2673], Loss: 3.3069, correct :82684, total: 153728, Batch Accuracy: 53.79%\n",
      "Epoch [4/15], Batch [1301/2673], Loss: 3.2955, correct :89822, total: 166528, Batch Accuracy: 53.94%\n",
      "Epoch [4/15], Batch [1401/2673], Loss: 3.2835, correct :97014, total: 179328, Batch Accuracy: 54.10%\n",
      "Epoch [4/15], Batch [1501/2673], Loss: 3.2735, correct :104313, total: 192128, Batch Accuracy: 54.29%\n",
      "Epoch [4/15], Batch [1601/2673], Loss: 3.2620, correct :111633, total: 204928, Batch Accuracy: 54.47%\n",
      "Epoch [4/15], Batch [1701/2673], Loss: 3.2542, correct :118880, total: 217728, Batch Accuracy: 54.60%\n",
      "Epoch [4/15], Batch [1801/2673], Loss: 3.2470, correct :126155, total: 230528, Batch Accuracy: 54.72%\n",
      "Epoch [4/15], Batch [1901/2673], Loss: 3.2387, correct :133508, total: 243328, Batch Accuracy: 54.87%\n",
      "Epoch [4/15], Batch [2001/2673], Loss: 3.2295, correct :140840, total: 256128, Batch Accuracy: 54.99%\n",
      "Epoch [4/15], Batch [2101/2673], Loss: 3.2215, correct :148209, total: 268928, Batch Accuracy: 55.11%\n",
      "Epoch [4/15], Batch [2201/2673], Loss: 3.2133, correct :155634, total: 281728, Batch Accuracy: 55.24%\n",
      "Epoch [4/15], Batch [2301/2673], Loss: 3.2042, correct :163042, total: 294528, Batch Accuracy: 55.36%\n",
      "Epoch [4/15], Batch [2401/2673], Loss: 3.1941, correct :170602, total: 307328, Batch Accuracy: 55.51%\n",
      "Epoch [4/15], Batch [2501/2673], Loss: 3.1833, correct :178243, total: 320128, Batch Accuracy: 55.68%\n",
      "Epoch [4/15], Batch [2601/2673], Loss: 3.1733, correct :185896, total: 332928, Batch Accuracy: 55.84%\n",
      "Epoch [4/15], Validation Loss: 0.0000, Validation Accuracy: 51.21%\n",
      "Epoch [5/15], Batch [1/2673], Loss: 2.6879, correct :80, total: 128, Batch Accuracy: 62.50%\n",
      "Epoch [5/15], Batch [101/2673], Loss: 2.8659, correct :7797, total: 12928, Batch Accuracy: 60.31%\n",
      "Epoch [5/15], Batch [201/2673], Loss: 2.8956, correct :15438, total: 25728, Batch Accuracy: 60.00%\n",
      "Epoch [5/15], Batch [301/2673], Loss: 2.8991, correct :23105, total: 38528, Batch Accuracy: 59.97%\n",
      "Epoch [5/15], Batch [401/2673], Loss: 2.8875, correct :30921, total: 51328, Batch Accuracy: 60.24%\n",
      "Epoch [5/15], Batch [501/2673], Loss: 2.8767, correct :38840, total: 64128, Batch Accuracy: 60.57%\n",
      "Epoch [5/15], Batch [601/2673], Loss: 2.8581, correct :46813, total: 76928, Batch Accuracy: 60.85%\n",
      "Epoch [5/15], Batch [701/2673], Loss: 2.8506, correct :54722, total: 89728, Batch Accuracy: 60.99%\n",
      "Epoch [5/15], Batch [801/2673], Loss: 2.8454, correct :62568, total: 102528, Batch Accuracy: 61.03%\n",
      "Epoch [5/15], Batch [901/2673], Loss: 2.8331, correct :70603, total: 115328, Batch Accuracy: 61.22%\n",
      "Epoch [5/15], Batch [1001/2673], Loss: 2.8287, correct :78503, total: 128128, Batch Accuracy: 61.27%\n",
      "Epoch [5/15], Batch [1101/2673], Loss: 2.8265, correct :86420, total: 140928, Batch Accuracy: 61.32%\n",
      "Epoch [5/15], Batch [1201/2673], Loss: 2.8205, correct :94424, total: 153728, Batch Accuracy: 61.42%\n",
      "Epoch [5/15], Batch [1301/2673], Loss: 2.8130, correct :102430, total: 166528, Batch Accuracy: 61.51%\n",
      "Epoch [5/15], Batch [1401/2673], Loss: 2.8052, correct :110515, total: 179328, Batch Accuracy: 61.63%\n",
      "Epoch [5/15], Batch [1501/2673], Loss: 2.7994, correct :118662, total: 192128, Batch Accuracy: 61.76%\n",
      "Epoch [5/15], Batch [1601/2673], Loss: 2.7917, correct :126725, total: 204928, Batch Accuracy: 61.84%\n",
      "Epoch [5/15], Batch [1701/2673], Loss: 2.7869, correct :134774, total: 217728, Batch Accuracy: 61.90%\n",
      "Epoch [5/15], Batch [1801/2673], Loss: 2.7835, correct :142856, total: 230528, Batch Accuracy: 61.97%\n",
      "Epoch [5/15], Batch [1901/2673], Loss: 2.7788, correct :151005, total: 243328, Batch Accuracy: 62.06%\n",
      "Epoch [5/15], Batch [2001/2673], Loss: 2.7734, correct :159109, total: 256128, Batch Accuracy: 62.12%\n",
      "Epoch [5/15], Batch [2101/2673], Loss: 2.7683, correct :167293, total: 268928, Batch Accuracy: 62.21%\n",
      "Epoch [5/15], Batch [2201/2673], Loss: 2.7638, correct :175417, total: 281728, Batch Accuracy: 62.26%\n",
      "Epoch [5/15], Batch [2301/2673], Loss: 2.7590, correct :183568, total: 294528, Batch Accuracy: 62.33%\n",
      "Epoch [5/15], Batch [2401/2673], Loss: 2.7523, correct :191873, total: 307328, Batch Accuracy: 62.43%\n",
      "Epoch [5/15], Batch [2501/2673], Loss: 2.7457, correct :200219, total: 320128, Batch Accuracy: 62.54%\n",
      "Epoch [5/15], Batch [2601/2673], Loss: 2.7391, correct :208618, total: 332928, Batch Accuracy: 62.66%\n",
      "Epoch [5/15], Validation Loss: 0.0000, Validation Accuracy: 54.99%\n",
      "Epoch [6/15], Batch [1/2673], Loss: 2.3851, correct :90, total: 128, Batch Accuracy: 70.31%\n",
      "Epoch [6/15], Batch [101/2673], Loss: 2.5240, correct :8468, total: 12928, Batch Accuracy: 65.50%\n",
      "Epoch [6/15], Batch [201/2673], Loss: 2.5548, correct :16797, total: 25728, Batch Accuracy: 65.29%\n",
      "Epoch [6/15], Batch [301/2673], Loss: 2.5535, correct :25201, total: 38528, Batch Accuracy: 65.41%\n",
      "Epoch [6/15], Batch [401/2673], Loss: 2.5473, correct :33696, total: 51328, Batch Accuracy: 65.65%\n",
      "Epoch [6/15], Batch [501/2673], Loss: 2.5388, correct :42159, total: 64128, Batch Accuracy: 65.74%\n",
      "Epoch [6/15], Batch [601/2673], Loss: 2.5247, correct :50735, total: 76928, Batch Accuracy: 65.95%\n",
      "Epoch [6/15], Batch [701/2673], Loss: 2.5205, correct :59307, total: 89728, Batch Accuracy: 66.10%\n",
      "Epoch [6/15], Batch [801/2673], Loss: 2.5178, correct :67806, total: 102528, Batch Accuracy: 66.13%\n",
      "Epoch [6/15], Batch [901/2673], Loss: 2.5092, correct :76444, total: 115328, Batch Accuracy: 66.28%\n",
      "Epoch [6/15], Batch [1001/2673], Loss: 2.5075, correct :84931, total: 128128, Batch Accuracy: 66.29%\n",
      "Epoch [6/15], Batch [1101/2673], Loss: 2.5075, correct :93411, total: 140928, Batch Accuracy: 66.28%\n",
      "Epoch [6/15], Batch [1201/2673], Loss: 2.5035, correct :101960, total: 153728, Batch Accuracy: 66.32%\n",
      "Epoch [6/15], Batch [1301/2673], Loss: 2.4975, correct :110524, total: 166528, Batch Accuracy: 66.37%\n",
      "Epoch [6/15], Batch [1401/2673], Loss: 2.4919, correct :119168, total: 179328, Batch Accuracy: 66.45%\n",
      "Epoch [6/15], Batch [1501/2673], Loss: 2.4888, correct :127821, total: 192128, Batch Accuracy: 66.53%\n",
      "Epoch [6/15], Batch [1601/2673], Loss: 2.4833, correct :136539, total: 204928, Batch Accuracy: 66.63%\n",
      "Epoch [6/15], Batch [1701/2673], Loss: 2.4805, correct :145166, total: 217728, Batch Accuracy: 66.67%\n",
      "Epoch [6/15], Batch [1801/2673], Loss: 2.4794, correct :153775, total: 230528, Batch Accuracy: 66.71%\n",
      "Epoch [6/15], Batch [1901/2673], Loss: 2.4763, correct :162463, total: 243328, Batch Accuracy: 66.77%\n",
      "Epoch [6/15], Batch [2001/2673], Loss: 2.4722, correct :171141, total: 256128, Batch Accuracy: 66.82%\n",
      "Epoch [6/15], Batch [2101/2673], Loss: 2.4696, correct :179820, total: 268928, Batch Accuracy: 66.87%\n",
      "Epoch [6/15], Batch [2201/2673], Loss: 2.4665, correct :188535, total: 281728, Batch Accuracy: 66.92%\n",
      "Epoch [6/15], Batch [2301/2673], Loss: 2.4635, correct :197172, total: 294528, Batch Accuracy: 66.95%\n",
      "Epoch [6/15], Batch [2401/2673], Loss: 2.4590, correct :205970, total: 307328, Batch Accuracy: 67.02%\n",
      "Epoch [6/15], Batch [2501/2673], Loss: 2.4534, correct :214826, total: 320128, Batch Accuracy: 67.11%\n",
      "Epoch [6/15], Batch [2601/2673], Loss: 2.4484, correct :223667, total: 332928, Batch Accuracy: 67.18%\n",
      "Epoch [6/15], Validation Loss: 0.0000, Validation Accuracy: 57.70%\n",
      "Epoch [7/15], Batch [1/2673], Loss: 2.2645, correct :96, total: 128, Batch Accuracy: 75.00%\n",
      "Epoch [7/15], Batch [101/2673], Loss: 2.2823, correct :8955, total: 12928, Batch Accuracy: 69.27%\n",
      "Epoch [7/15], Batch [201/2673], Loss: 2.3216, correct :17700, total: 25728, Batch Accuracy: 68.80%\n",
      "Epoch [7/15], Batch [301/2673], Loss: 2.3193, correct :26517, total: 38528, Batch Accuracy: 68.83%\n",
      "Epoch [7/15], Batch [401/2673], Loss: 2.3121, correct :35487, total: 51328, Batch Accuracy: 69.14%\n",
      "Epoch [7/15], Batch [501/2673], Loss: 2.3063, correct :44447, total: 64128, Batch Accuracy: 69.31%\n",
      "Epoch [7/15], Batch [601/2673], Loss: 2.2935, correct :53501, total: 76928, Batch Accuracy: 69.55%\n",
      "Epoch [7/15], Batch [701/2673], Loss: 2.2912, correct :62462, total: 89728, Batch Accuracy: 69.61%\n",
      "Epoch [7/15], Batch [801/2673], Loss: 2.2892, correct :71407, total: 102528, Batch Accuracy: 69.65%\n",
      "Epoch [7/15], Batch [901/2673], Loss: 2.2819, correct :80460, total: 115328, Batch Accuracy: 69.77%\n",
      "Epoch [7/15], Batch [1001/2673], Loss: 2.2802, correct :89412, total: 128128, Batch Accuracy: 69.78%\n",
      "Epoch [7/15], Batch [1101/2673], Loss: 2.2802, correct :98362, total: 140928, Batch Accuracy: 69.80%\n",
      "Epoch [7/15], Batch [1201/2673], Loss: 2.2774, correct :107327, total: 153728, Batch Accuracy: 69.82%\n",
      "Epoch [7/15], Batch [1301/2673], Loss: 2.2727, correct :116322, total: 166528, Batch Accuracy: 69.85%\n",
      "Epoch [7/15], Batch [1401/2673], Loss: 2.2682, correct :125378, total: 179328, Batch Accuracy: 69.92%\n",
      "Epoch [7/15], Batch [1501/2673], Loss: 2.2662, correct :134412, total: 192128, Batch Accuracy: 69.96%\n",
      "Epoch [7/15], Batch [1601/2673], Loss: 2.2621, correct :143480, total: 204928, Batch Accuracy: 70.01%\n",
      "Epoch [7/15], Batch [1701/2673], Loss: 2.2606, correct :152504, total: 217728, Batch Accuracy: 70.04%\n",
      "Epoch [7/15], Batch [1801/2673], Loss: 2.2604, correct :161551, total: 230528, Batch Accuracy: 70.08%\n",
      "Epoch [7/15], Batch [1901/2673], Loss: 2.2582, correct :170610, total: 243328, Batch Accuracy: 70.12%\n",
      "Epoch [7/15], Batch [2001/2673], Loss: 2.2550, correct :179685, total: 256128, Batch Accuracy: 70.15%\n",
      "Epoch [7/15], Batch [2101/2673], Loss: 2.2536, correct :188726, total: 268928, Batch Accuracy: 70.18%\n",
      "Epoch [7/15], Batch [2201/2673], Loss: 2.2514, correct :197755, total: 281728, Batch Accuracy: 70.19%\n",
      "Epoch [7/15], Batch [2301/2673], Loss: 2.2485, correct :206823, total: 294528, Batch Accuracy: 70.22%\n",
      "Epoch [7/15], Batch [2401/2673], Loss: 2.2450, correct :216013, total: 307328, Batch Accuracy: 70.29%\n",
      "Epoch [7/15], Batch [2501/2673], Loss: 2.2406, correct :225210, total: 320128, Batch Accuracy: 70.35%\n",
      "Epoch [7/15], Batch [2601/2673], Loss: 2.2362, correct :234418, total: 332928, Batch Accuracy: 70.41%\n",
      "Epoch [7/15], Validation Loss: 0.0000, Validation Accuracy: 58.06%\n",
      "Epoch [8/15], Batch [1/2673], Loss: 2.0975, correct :93, total: 128, Batch Accuracy: 72.66%\n",
      "Epoch [8/15], Batch [101/2673], Loss: 2.0976, correct :9354, total: 12928, Batch Accuracy: 72.35%\n",
      "Epoch [8/15], Batch [201/2673], Loss: 2.1269, correct :18522, total: 25728, Batch Accuracy: 71.99%\n",
      "Epoch [8/15], Batch [301/2673], Loss: 2.1276, correct :27743, total: 38528, Batch Accuracy: 72.01%\n",
      "Epoch [8/15], Batch [401/2673], Loss: 2.1234, correct :37024, total: 51328, Batch Accuracy: 72.13%\n",
      "Epoch [8/15], Batch [501/2673], Loss: 2.1194, correct :46329, total: 64128, Batch Accuracy: 72.24%\n",
      "Epoch [8/15], Batch [601/2673], Loss: 2.1090, correct :55701, total: 76928, Batch Accuracy: 72.41%\n",
      "Epoch [8/15], Batch [701/2673], Loss: 2.1085, correct :64993, total: 89728, Batch Accuracy: 72.43%\n",
      "Epoch [8/15], Batch [801/2673], Loss: 2.1072, correct :74304, total: 102528, Batch Accuracy: 72.47%\n",
      "Epoch [8/15], Batch [901/2673], Loss: 2.1018, correct :83693, total: 115328, Batch Accuracy: 72.57%\n",
      "Epoch [8/15], Batch [1001/2673], Loss: 2.1011, correct :92963, total: 128128, Batch Accuracy: 72.55%\n",
      "Epoch [8/15], Batch [1101/2673], Loss: 2.1016, correct :102239, total: 140928, Batch Accuracy: 72.55%\n",
      "Epoch [8/15], Batch [1201/2673], Loss: 2.0991, correct :111593, total: 153728, Batch Accuracy: 72.59%\n",
      "Epoch [8/15], Batch [1301/2673], Loss: 2.0957, correct :120955, total: 166528, Batch Accuracy: 72.63%\n",
      "Epoch [8/15], Batch [1401/2673], Loss: 2.0922, correct :130356, total: 179328, Batch Accuracy: 72.69%\n",
      "Epoch [8/15], Batch [1501/2673], Loss: 2.0907, correct :139760, total: 192128, Batch Accuracy: 72.74%\n",
      "Epoch [8/15], Batch [1601/2673], Loss: 2.0856, correct :149227, total: 204928, Batch Accuracy: 72.82%\n",
      "Epoch [8/15], Batch [1701/2673], Loss: 2.0852, correct :158573, total: 217728, Batch Accuracy: 72.83%\n",
      "Epoch [8/15], Batch [1801/2673], Loss: 2.0862, correct :167930, total: 230528, Batch Accuracy: 72.85%\n",
      "Epoch [8/15], Batch [1901/2673], Loss: 2.0843, correct :177349, total: 243328, Batch Accuracy: 72.88%\n",
      "Epoch [8/15], Batch [2001/2673], Loss: 2.0817, correct :186740, total: 256128, Batch Accuracy: 72.91%\n",
      "Epoch [8/15], Batch [2101/2673], Loss: 2.0803, correct :196130, total: 268928, Batch Accuracy: 72.93%\n",
      "Epoch [8/15], Batch [2201/2673], Loss: 2.0784, correct :205558, total: 281728, Batch Accuracy: 72.96%\n",
      "Epoch [8/15], Batch [2301/2673], Loss: 2.0764, correct :214968, total: 294528, Batch Accuracy: 72.99%\n",
      "Epoch [8/15], Batch [2401/2673], Loss: 2.0738, correct :224422, total: 307328, Batch Accuracy: 73.02%\n",
      "Epoch [8/15], Batch [2501/2673], Loss: 2.0699, correct :233957, total: 320128, Batch Accuracy: 73.08%\n",
      "Epoch [8/15], Batch [2601/2673], Loss: 2.0660, correct :243522, total: 332928, Batch Accuracy: 73.15%\n",
      "Epoch [8/15], Validation Loss: 0.0000, Validation Accuracy: 61.31%\n",
      "Epoch [9/15], Batch [1/2673], Loss: 2.1293, correct :93, total: 128, Batch Accuracy: 72.66%\n",
      "Epoch [9/15], Batch [101/2673], Loss: 1.9595, correct :9645, total: 12928, Batch Accuracy: 74.61%\n",
      "Epoch [9/15], Batch [201/2673], Loss: 1.9846, correct :19130, total: 25728, Batch Accuracy: 74.35%\n",
      "Epoch [9/15], Batch [301/2673], Loss: 1.9819, correct :28617, total: 38528, Batch Accuracy: 74.28%\n",
      "Epoch [9/15], Batch [401/2673], Loss: 1.9739, correct :38272, total: 51328, Batch Accuracy: 74.56%\n",
      "Epoch [9/15], Batch [501/2673], Loss: 1.9687, correct :47931, total: 64128, Batch Accuracy: 74.74%\n",
      "Epoch [9/15], Batch [601/2673], Loss: 1.9585, correct :57577, total: 76928, Batch Accuracy: 74.85%\n",
      "Epoch [9/15], Batch [701/2673], Loss: 1.9593, correct :67177, total: 89728, Batch Accuracy: 74.87%\n",
      "Epoch [9/15], Batch [801/2673], Loss: 1.9580, correct :76775, total: 102528, Batch Accuracy: 74.88%\n",
      "Epoch [9/15], Batch [901/2673], Loss: 1.9515, correct :86469, total: 115328, Batch Accuracy: 74.98%\n",
      "Epoch [9/15], Batch [1001/2673], Loss: 1.9508, correct :96010, total: 128128, Batch Accuracy: 74.93%\n",
      "Epoch [9/15], Batch [1101/2673], Loss: 1.9507, correct :105643, total: 140928, Batch Accuracy: 74.96%\n",
      "Epoch [9/15], Batch [1201/2673], Loss: 1.9495, correct :115287, total: 153728, Batch Accuracy: 74.99%\n",
      "Epoch [9/15], Batch [1301/2673], Loss: 1.9458, correct :124977, total: 166528, Batch Accuracy: 75.05%\n",
      "Epoch [9/15], Batch [1401/2673], Loss: 1.9429, correct :134612, total: 179328, Batch Accuracy: 75.06%\n",
      "Epoch [9/15], Batch [1501/2673], Loss: 1.9408, correct :144323, total: 192128, Batch Accuracy: 75.12%\n",
      "Epoch [9/15], Batch [1601/2673], Loss: 1.9363, correct :154093, total: 204928, Batch Accuracy: 75.19%\n",
      "Epoch [9/15], Batch [1701/2673], Loss: 1.9357, correct :163749, total: 217728, Batch Accuracy: 75.21%\n",
      "Epoch [9/15], Batch [1801/2673], Loss: 1.9365, correct :173412, total: 230528, Batch Accuracy: 75.22%\n",
      "Epoch [9/15], Batch [1901/2673], Loss: 1.9350, correct :183119, total: 243328, Batch Accuracy: 75.26%\n",
      "Epoch [9/15], Batch [2001/2673], Loss: 1.9325, correct :192833, total: 256128, Batch Accuracy: 75.29%\n",
      "Epoch [9/15], Batch [2101/2673], Loss: 1.9311, correct :202572, total: 268928, Batch Accuracy: 75.33%\n",
      "Epoch [9/15], Batch [2201/2673], Loss: 1.9295, correct :212287, total: 281728, Batch Accuracy: 75.35%\n",
      "Epoch [9/15], Batch [2301/2673], Loss: 1.9274, correct :222018, total: 294528, Batch Accuracy: 75.38%\n",
      "Epoch [9/15], Batch [2401/2673], Loss: 1.9248, correct :231815, total: 307328, Batch Accuracy: 75.43%\n",
      "Epoch [9/15], Batch [2501/2673], Loss: 1.9212, correct :241653, total: 320128, Batch Accuracy: 75.49%\n",
      "Epoch [9/15], Batch [2601/2673], Loss: 1.9176, correct :251447, total: 332928, Batch Accuracy: 75.53%\n",
      "Epoch [9/15], Validation Loss: 0.0000, Validation Accuracy: 64.35%\n",
      "Epoch [10/15], Batch [1/2673], Loss: 1.9755, correct :95, total: 128, Batch Accuracy: 74.22%\n",
      "Epoch [10/15], Batch [101/2673], Loss: 1.8150, correct :9888, total: 12928, Batch Accuracy: 76.49%\n",
      "Epoch [10/15], Batch [201/2673], Loss: 1.8347, correct :19655, total: 25728, Batch Accuracy: 76.40%\n",
      "Epoch [10/15], Batch [301/2673], Loss: 1.8379, correct :29428, total: 38528, Batch Accuracy: 76.38%\n",
      "Epoch [10/15], Batch [401/2673], Loss: 1.8335, correct :39339, total: 51328, Batch Accuracy: 76.64%\n",
      "Epoch [10/15], Batch [501/2673], Loss: 1.8310, correct :49207, total: 64128, Batch Accuracy: 76.73%\n",
      "Epoch [10/15], Batch [601/2673], Loss: 1.8208, correct :59146, total: 76928, Batch Accuracy: 76.88%\n",
      "Epoch [10/15], Batch [701/2673], Loss: 1.8229, correct :69000, total: 89728, Batch Accuracy: 76.90%\n",
      "Epoch [10/15], Batch [801/2673], Loss: 1.8233, correct :78844, total: 102528, Batch Accuracy: 76.90%\n",
      "Epoch [10/15], Batch [901/2673], Loss: 1.8177, correct :88782, total: 115328, Batch Accuracy: 76.98%\n",
      "Epoch [10/15], Batch [1001/2673], Loss: 1.8187, correct :98581, total: 128128, Batch Accuracy: 76.94%\n",
      "Epoch [10/15], Batch [1101/2673], Loss: 1.8191, correct :108452, total: 140928, Batch Accuracy: 76.96%\n",
      "Epoch [10/15], Batch [1201/2673], Loss: 1.8188, correct :118335, total: 153728, Batch Accuracy: 76.98%\n",
      "Epoch [10/15], Batch [1301/2673], Loss: 1.8153, correct :128277, total: 166528, Batch Accuracy: 77.03%\n",
      "Epoch [10/15], Batch [1401/2673], Loss: 1.8130, correct :138147, total: 179328, Batch Accuracy: 77.04%\n",
      "Epoch [10/15], Batch [1501/2673], Loss: 1.8120, correct :148052, total: 192128, Batch Accuracy: 77.06%\n",
      "Epoch [10/15], Batch [1601/2673], Loss: 1.8077, correct :158069, total: 204928, Batch Accuracy: 77.13%\n",
      "Epoch [10/15], Batch [1701/2673], Loss: 1.8070, correct :167999, total: 217728, Batch Accuracy: 77.16%\n",
      "Epoch [10/15], Batch [1801/2673], Loss: 1.8077, correct :177916, total: 230528, Batch Accuracy: 77.18%\n",
      "Epoch [10/15], Batch [1901/2673], Loss: 1.8070, correct :187788, total: 243328, Batch Accuracy: 77.17%\n",
      "Epoch [10/15], Batch [2001/2673], Loss: 1.8047, correct :197778, total: 256128, Batch Accuracy: 77.22%\n",
      "Epoch [10/15], Batch [2101/2673], Loss: 1.8036, correct :207725, total: 268928, Batch Accuracy: 77.24%\n",
      "Epoch [10/15], Batch [2201/2673], Loss: 1.8023, correct :217671, total: 281728, Batch Accuracy: 77.26%\n",
      "Epoch [10/15], Batch [2301/2673], Loss: 1.8007, correct :227624, total: 294528, Batch Accuracy: 77.28%\n",
      "Epoch [10/15], Batch [2401/2673], Loss: 1.7985, correct :237578, total: 307328, Batch Accuracy: 77.30%\n",
      "Epoch [10/15], Batch [2501/2673], Loss: 1.7957, correct :247585, total: 320128, Batch Accuracy: 77.34%\n",
      "Epoch [10/15], Batch [2601/2673], Loss: 1.7924, correct :257632, total: 332928, Batch Accuracy: 77.38%\n",
      "Epoch [10/15], Validation Loss: 0.0000, Validation Accuracy: 64.40%\n",
      "Epoch [11/15], Batch [1/2673], Loss: 1.8795, correct :97, total: 128, Batch Accuracy: 75.78%\n",
      "Epoch [11/15], Batch [101/2673], Loss: 1.6969, correct :10181, total: 12928, Batch Accuracy: 78.75%\n",
      "Epoch [11/15], Batch [201/2673], Loss: 1.7210, correct :20133, total: 25728, Batch Accuracy: 78.25%\n",
      "Epoch [11/15], Batch [301/2673], Loss: 1.7227, correct :30127, total: 38528, Batch Accuracy: 78.20%\n",
      "Epoch [11/15], Batch [401/2673], Loss: 1.7203, correct :40220, total: 51328, Batch Accuracy: 78.36%\n",
      "Epoch [11/15], Batch [501/2673], Loss: 1.7158, correct :50303, total: 64128, Batch Accuracy: 78.44%\n",
      "Epoch [11/15], Batch [601/2673], Loss: 1.7075, correct :60491, total: 76928, Batch Accuracy: 78.63%\n",
      "Epoch [11/15], Batch [701/2673], Loss: 1.7109, correct :70555, total: 89728, Batch Accuracy: 78.63%\n",
      "Epoch [11/15], Batch [801/2673], Loss: 1.7111, correct :80667, total: 102528, Batch Accuracy: 78.68%\n",
      "Epoch [11/15], Batch [901/2673], Loss: 1.7055, correct :90843, total: 115328, Batch Accuracy: 78.77%\n",
      "Epoch [11/15], Batch [1001/2673], Loss: 1.7059, correct :100896, total: 128128, Batch Accuracy: 78.75%\n",
      "Epoch [11/15], Batch [1101/2673], Loss: 1.7063, correct :111007, total: 140928, Batch Accuracy: 78.77%\n",
      "Epoch [11/15], Batch [1201/2673], Loss: 1.7060, correct :121087, total: 153728, Batch Accuracy: 78.77%\n",
      "Epoch [11/15], Batch [1301/2673], Loss: 1.7034, correct :131250, total: 166528, Batch Accuracy: 78.82%\n",
      "Epoch [11/15], Batch [1401/2673], Loss: 1.7010, correct :141384, total: 179328, Batch Accuracy: 78.84%\n",
      "Epoch [11/15], Batch [1501/2673], Loss: 1.7000, correct :151508, total: 192128, Batch Accuracy: 78.86%\n",
      "Epoch [11/15], Batch [1601/2673], Loss: 1.6963, correct :161755, total: 204928, Batch Accuracy: 78.93%\n",
      "Epoch [11/15], Batch [1701/2673], Loss: 1.6963, correct :171865, total: 217728, Batch Accuracy: 78.94%\n",
      "Epoch [11/15], Batch [1801/2673], Loss: 1.6982, correct :181973, total: 230528, Batch Accuracy: 78.94%\n",
      "Epoch [11/15], Batch [1901/2673], Loss: 1.6981, correct :192065, total: 243328, Batch Accuracy: 78.93%\n",
      "Epoch [11/15], Batch [2001/2673], Loss: 1.6964, correct :202172, total: 256128, Batch Accuracy: 78.93%\n",
      "Epoch [11/15], Batch [2101/2673], Loss: 1.6957, correct :212328, total: 268928, Batch Accuracy: 78.95%\n",
      "Epoch [11/15], Batch [2201/2673], Loss: 1.6954, correct :222443, total: 281728, Batch Accuracy: 78.96%\n",
      "Epoch [11/15], Batch [2301/2673], Loss: 1.6941, correct :232558, total: 294528, Batch Accuracy: 78.96%\n",
      "Epoch [11/15], Batch [2401/2673], Loss: 1.6921, correct :242748, total: 307328, Batch Accuracy: 78.99%\n",
      "Epoch [11/15], Batch [2501/2673], Loss: 1.6893, correct :252977, total: 320128, Batch Accuracy: 79.02%\n",
      "Epoch [11/15], Batch [2601/2673], Loss: 1.6865, correct :263249, total: 332928, Batch Accuracy: 79.07%\n",
      "Epoch [11/15], Validation Loss: 0.0000, Validation Accuracy: 66.60%\n",
      "Epoch [12/15], Batch [1/2673], Loss: 1.6743, correct :103, total: 128, Batch Accuracy: 80.47%\n",
      "Epoch [12/15], Batch [101/2673], Loss: 1.5968, correct :10433, total: 12928, Batch Accuracy: 80.70%\n",
      "Epoch [12/15], Batch [201/2673], Loss: 1.6269, correct :20587, total: 25728, Batch Accuracy: 80.02%\n",
      "Epoch [12/15], Batch [301/2673], Loss: 1.6280, correct :30797, total: 38528, Batch Accuracy: 79.93%\n",
      "Epoch [12/15], Batch [401/2673], Loss: 1.6270, correct :41078, total: 51328, Batch Accuracy: 80.03%\n",
      "Epoch [12/15], Batch [501/2673], Loss: 1.6231, correct :51389, total: 64128, Batch Accuracy: 80.14%\n",
      "Epoch [12/15], Batch [601/2673], Loss: 1.6152, correct :61769, total: 76928, Batch Accuracy: 80.29%\n",
      "Epoch [12/15], Batch [701/2673], Loss: 1.6182, correct :72067, total: 89728, Batch Accuracy: 80.32%\n",
      "Epoch [12/15], Batch [801/2673], Loss: 1.6176, correct :82365, total: 102528, Batch Accuracy: 80.33%\n",
      "Epoch [12/15], Batch [901/2673], Loss: 1.6130, correct :92716, total: 115328, Batch Accuracy: 80.39%\n",
      "Epoch [12/15], Batch [1001/2673], Loss: 1.6127, correct :102989, total: 128128, Batch Accuracy: 80.38%\n",
      "Epoch [12/15], Batch [1101/2673], Loss: 1.6133, correct :113248, total: 140928, Batch Accuracy: 80.36%\n",
      "Epoch [12/15], Batch [1201/2673], Loss: 1.6134, correct :123564, total: 153728, Batch Accuracy: 80.38%\n",
      "Epoch [12/15], Batch [1301/2673], Loss: 1.6109, correct :133919, total: 166528, Batch Accuracy: 80.42%\n",
      "Epoch [12/15], Batch [1401/2673], Loss: 1.6091, correct :144211, total: 179328, Batch Accuracy: 80.42%\n",
      "Epoch [12/15], Batch [1501/2673], Loss: 1.6087, correct :154503, total: 192128, Batch Accuracy: 80.42%\n",
      "Epoch [12/15], Batch [1601/2673], Loss: 1.6060, correct :164789, total: 204928, Batch Accuracy: 80.41%\n",
      "Epoch [12/15], Batch [1701/2673], Loss: 1.6057, correct :175083, total: 217728, Batch Accuracy: 80.41%\n",
      "Epoch [12/15], Batch [1801/2673], Loss: 1.6074, correct :185328, total: 230528, Batch Accuracy: 80.39%\n",
      "Epoch [12/15], Batch [1901/2673], Loss: 1.6070, correct :195653, total: 243328, Batch Accuracy: 80.41%\n",
      "Epoch [12/15], Batch [2001/2673], Loss: 1.6052, correct :205991, total: 256128, Batch Accuracy: 80.43%\n",
      "Epoch [12/15], Batch [2101/2673], Loss: 1.6049, correct :216295, total: 268928, Batch Accuracy: 80.43%\n",
      "Epoch [12/15], Batch [2201/2673], Loss: 1.6041, correct :226606, total: 281728, Batch Accuracy: 80.43%\n",
      "Epoch [12/15], Batch [2301/2673], Loss: 1.6030, correct :236944, total: 294528, Batch Accuracy: 80.45%\n",
      "Epoch [12/15], Batch [2401/2673], Loss: 1.6013, correct :247314, total: 307328, Batch Accuracy: 80.47%\n",
      "Epoch [12/15], Batch [2501/2673], Loss: 1.5988, correct :257757, total: 320128, Batch Accuracy: 80.52%\n",
      "Epoch [12/15], Batch [2601/2673], Loss: 1.5957, correct :268225, total: 332928, Batch Accuracy: 80.57%\n",
      "Epoch [12/15], Validation Loss: 0.0000, Validation Accuracy: 67.62%\n",
      "Epoch [13/15], Batch [1/2673], Loss: 1.6108, correct :104, total: 128, Batch Accuracy: 81.25%\n",
      "Epoch [13/15], Batch [101/2673], Loss: 1.5204, correct :10597, total: 12928, Batch Accuracy: 81.97%\n",
      "Epoch [13/15], Batch [201/2673], Loss: 1.5340, correct :21004, total: 25728, Batch Accuracy: 81.64%\n",
      "Epoch [13/15], Batch [301/2673], Loss: 1.5400, correct :31390, total: 38528, Batch Accuracy: 81.47%\n",
      "Epoch [13/15], Batch [401/2673], Loss: 1.5410, correct :41843, total: 51328, Batch Accuracy: 81.52%\n",
      "Epoch [13/15], Batch [501/2673], Loss: 1.5384, correct :52322, total: 64128, Batch Accuracy: 81.59%\n",
      "Epoch [13/15], Batch [601/2673], Loss: 1.5305, correct :62884, total: 76928, Batch Accuracy: 81.74%\n",
      "Epoch [13/15], Batch [701/2673], Loss: 1.5324, correct :73319, total: 89728, Batch Accuracy: 81.71%\n",
      "Epoch [13/15], Batch [801/2673], Loss: 1.5311, correct :83770, total: 102528, Batch Accuracy: 81.70%\n",
      "Epoch [13/15], Batch [901/2673], Loss: 1.5271, correct :94279, total: 115328, Batch Accuracy: 81.75%\n",
      "Epoch [13/15], Batch [1001/2673], Loss: 1.5272, correct :104699, total: 128128, Batch Accuracy: 81.71%\n",
      "Epoch [13/15], Batch [1101/2673], Loss: 1.5284, correct :115123, total: 140928, Batch Accuracy: 81.69%\n",
      "Epoch [13/15], Batch [1201/2673], Loss: 1.5283, correct :125587, total: 153728, Batch Accuracy: 81.69%\n",
      "Epoch [13/15], Batch [1301/2673], Loss: 1.5264, correct :136105, total: 166528, Batch Accuracy: 81.73%\n",
      "Epoch [13/15], Batch [1401/2673], Loss: 1.5251, correct :146544, total: 179328, Batch Accuracy: 81.72%\n",
      "Epoch [13/15], Batch [1501/2673], Loss: 1.5247, correct :157041, total: 192128, Batch Accuracy: 81.74%\n",
      "Epoch [13/15], Batch [1601/2673], Loss: 1.5222, correct :167576, total: 204928, Batch Accuracy: 81.77%\n",
      "Epoch [13/15], Batch [1701/2673], Loss: 1.5219, correct :178054, total: 217728, Batch Accuracy: 81.78%\n",
      "Epoch [13/15], Batch [1801/2673], Loss: 1.5241, correct :188480, total: 230528, Batch Accuracy: 81.76%\n",
      "Epoch [13/15], Batch [1901/2673], Loss: 1.5241, correct :198993, total: 243328, Batch Accuracy: 81.78%\n",
      "Epoch [13/15], Batch [2001/2673], Loss: 1.5225, correct :209490, total: 256128, Batch Accuracy: 81.79%\n",
      "Epoch [13/15], Batch [2101/2673], Loss: 1.5219, correct :219982, total: 268928, Batch Accuracy: 81.80%\n",
      "Epoch [13/15], Batch [2201/2673], Loss: 1.5219, correct :230425, total: 281728, Batch Accuracy: 81.79%\n",
      "Epoch [13/15], Batch [2301/2673], Loss: 1.5208, correct :240957, total: 294528, Batch Accuracy: 81.81%\n",
      "Epoch [13/15], Batch [2401/2673], Loss: 1.5194, correct :251498, total: 307328, Batch Accuracy: 81.83%\n",
      "Epoch [13/15], Batch [2501/2673], Loss: 1.5167, correct :262095, total: 320128, Batch Accuracy: 81.87%\n",
      "Epoch [13/15], Batch [2601/2673], Loss: 1.5142, correct :272706, total: 332928, Batch Accuracy: 81.91%\n",
      "Epoch [13/15], Validation Loss: 0.0000, Validation Accuracy: 67.50%\n",
      "Epoch [14/15], Batch [1/2673], Loss: 1.5531, correct :105, total: 128, Batch Accuracy: 82.03%\n",
      "Epoch [14/15], Batch [101/2673], Loss: 1.4459, correct :10739, total: 12928, Batch Accuracy: 83.07%\n",
      "Epoch [14/15], Batch [201/2673], Loss: 1.4608, correct :21253, total: 25728, Batch Accuracy: 82.61%\n",
      "Epoch [14/15], Batch [301/2673], Loss: 1.4636, correct :31810, total: 38528, Batch Accuracy: 82.56%\n",
      "Epoch [14/15], Batch [401/2673], Loss: 1.4661, correct :42407, total: 51328, Batch Accuracy: 82.62%\n",
      "Epoch [14/15], Batch [501/2673], Loss: 1.4641, correct :53018, total: 64128, Batch Accuracy: 82.68%\n",
      "Epoch [14/15], Batch [601/2673], Loss: 1.4584, correct :63673, total: 76928, Batch Accuracy: 82.77%\n",
      "Epoch [14/15], Batch [701/2673], Loss: 1.4617, correct :74210, total: 89728, Batch Accuracy: 82.71%\n",
      "Epoch [14/15], Batch [801/2673], Loss: 1.4619, correct :84774, total: 102528, Batch Accuracy: 82.68%\n",
      "Epoch [14/15], Batch [901/2673], Loss: 1.4587, correct :95408, total: 115328, Batch Accuracy: 82.73%\n",
      "Epoch [14/15], Batch [1001/2673], Loss: 1.4589, correct :105964, total: 128128, Batch Accuracy: 82.70%\n",
      "Epoch [14/15], Batch [1101/2673], Loss: 1.4596, correct :116596, total: 140928, Batch Accuracy: 82.73%\n",
      "Epoch [14/15], Batch [1201/2673], Loss: 1.4597, correct :127184, total: 153728, Batch Accuracy: 82.73%\n",
      "Epoch [14/15], Batch [1301/2673], Loss: 1.4579, correct :137828, total: 166528, Batch Accuracy: 82.77%\n",
      "Epoch [14/15], Batch [1401/2673], Loss: 1.4564, correct :148462, total: 179328, Batch Accuracy: 82.79%\n",
      "Epoch [14/15], Batch [1501/2673], Loss: 1.4563, correct :159035, total: 192128, Batch Accuracy: 82.78%\n",
      "Epoch [14/15], Batch [1601/2673], Loss: 1.4538, correct :169723, total: 204928, Batch Accuracy: 82.82%\n",
      "Epoch [14/15], Batch [1701/2673], Loss: 1.4536, correct :180302, total: 217728, Batch Accuracy: 82.81%\n",
      "Epoch [14/15], Batch [1801/2673], Loss: 1.4550, correct :190908, total: 230528, Batch Accuracy: 82.81%\n",
      "Epoch [14/15], Batch [1901/2673], Loss: 1.4551, correct :201496, total: 243328, Batch Accuracy: 82.81%\n",
      "Epoch [14/15], Batch [2001/2673], Loss: 1.4534, correct :212144, total: 256128, Batch Accuracy: 82.83%\n",
      "Epoch [14/15], Batch [2101/2673], Loss: 1.4527, correct :222782, total: 268928, Batch Accuracy: 82.84%\n",
      "Epoch [14/15], Batch [2201/2673], Loss: 1.4522, correct :233404, total: 281728, Batch Accuracy: 82.85%\n",
      "Epoch [14/15], Batch [2301/2673], Loss: 1.4514, correct :244032, total: 294528, Batch Accuracy: 82.86%\n",
      "Epoch [14/15], Batch [2401/2673], Loss: 1.4499, correct :254730, total: 307328, Batch Accuracy: 82.89%\n",
      "Epoch [14/15], Batch [2501/2673], Loss: 1.4473, correct :265482, total: 320128, Batch Accuracy: 82.93%\n",
      "Epoch [14/15], Batch [2601/2673], Loss: 1.4446, correct :276231, total: 332928, Batch Accuracy: 82.97%\n",
      "Epoch [14/15], Validation Loss: 0.0000, Validation Accuracy: 68.66%\n",
      "Epoch [15/15], Batch [1/2673], Loss: 1.5424, correct :106, total: 128, Batch Accuracy: 82.81%\n",
      "Epoch [15/15], Batch [101/2673], Loss: 1.3884, correct :10861, total: 12928, Batch Accuracy: 84.01%\n",
      "Epoch [15/15], Batch [201/2673], Loss: 1.4020, correct :21525, total: 25728, Batch Accuracy: 83.66%\n",
      "Epoch [15/15], Batch [301/2673], Loss: 1.4062, correct :32202, total: 38528, Batch Accuracy: 83.58%\n",
      "Epoch [15/15], Batch [401/2673], Loss: 1.4067, correct :42900, total: 51328, Batch Accuracy: 83.58%\n",
      "Epoch [15/15], Batch [501/2673], Loss: 1.4041, correct :53637, total: 64128, Batch Accuracy: 83.64%\n",
      "Epoch [15/15], Batch [601/2673], Loss: 1.3981, correct :64421, total: 76928, Batch Accuracy: 83.74%\n",
      "Epoch [15/15], Batch [701/2673], Loss: 1.4004, correct :75132, total: 89728, Batch Accuracy: 83.73%\n",
      "Epoch [15/15], Batch [801/2673], Loss: 1.3987, correct :85837, total: 102528, Batch Accuracy: 83.72%\n",
      "Epoch [15/15], Batch [901/2673], Loss: 1.3956, correct :96608, total: 115328, Batch Accuracy: 83.77%\n",
      "Epoch [15/15], Batch [1001/2673], Loss: 1.3967, correct :107292, total: 128128, Batch Accuracy: 83.74%\n",
      "Epoch [15/15], Batch [1101/2673], Loss: 1.3976, correct :117994, total: 140928, Batch Accuracy: 83.73%\n",
      "Epoch [15/15], Batch [1201/2673], Loss: 1.3981, correct :128718, total: 153728, Batch Accuracy: 83.73%\n",
      "Epoch [15/15], Batch [1301/2673], Loss: 1.3960, correct :139516, total: 166528, Batch Accuracy: 83.78%\n",
      "Epoch [15/15], Batch [1401/2673], Loss: 1.3946, correct :150243, total: 179328, Batch Accuracy: 83.78%\n",
      "Epoch [15/15], Batch [1501/2673], Loss: 1.3944, correct :160987, total: 192128, Batch Accuracy: 83.79%\n",
      "Epoch [15/15], Batch [1601/2673], Loss: 1.3927, correct :171716, total: 204928, Batch Accuracy: 83.79%\n",
      "Epoch [15/15], Batch [1701/2673], Loss: 1.3925, correct :182473, total: 217728, Batch Accuracy: 83.81%\n",
      "Epoch [15/15], Batch [1801/2673], Loss: 1.3941, correct :193174, total: 230528, Batch Accuracy: 83.80%\n",
      "Epoch [15/15], Batch [1901/2673], Loss: 1.3944, correct :203904, total: 243328, Batch Accuracy: 83.80%\n",
      "Epoch [15/15], Batch [2001/2673], Loss: 1.3929, correct :214656, total: 256128, Batch Accuracy: 83.81%\n",
      "Epoch [15/15], Batch [2101/2673], Loss: 1.3919, correct :225432, total: 268928, Batch Accuracy: 83.83%\n",
      "Epoch [15/15], Batch [2201/2673], Loss: 1.3914, correct :236167, total: 281728, Batch Accuracy: 83.83%\n",
      "Epoch [15/15], Batch [2301/2673], Loss: 1.3907, correct :246887, total: 294528, Batch Accuracy: 83.82%\n",
      "Epoch [15/15], Batch [2401/2673], Loss: 1.3893, correct :257674, total: 307328, Batch Accuracy: 83.84%\n",
      "Epoch [15/15], Batch [2501/2673], Loss: 1.3871, correct :268504, total: 320128, Batch Accuracy: 83.87%\n",
      "Epoch [15/15], Batch [2601/2673], Loss: 1.3846, correct :279351, total: 332928, Batch Accuracy: 83.91%\n",
      "Epoch [15/15], Validation Loss: 0.0000, Validation Accuracy: 69.33%\n",
      "2024-03-21 10:14:52\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "formatted_time = datetime.datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define the temperature parameter for knowledge distillation\n",
    "temperature = 4.0  # You can adjust this value based on your needs\n",
    "# Define the loss function and optimizer for training the student model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "\n",
    "    #define running loss\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass for the teacher model (assuming it's already trained)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = teacher_model(inputs)\n",
    "\n",
    "        # Forward pass for the student model\n",
    "        optimizer_student.zero_grad()\n",
    "        outputs_student = student_model(inputs)\n",
    "\n",
    "        #Calculates the knowledge distillation loss using the Kullback-Leibler (KL) Divergence loss.It measures the difference between two probability distributions. In this case, it calculates the KL Divergence between the log-softmax predictions of the student model and the softmax predictions of the teacher model.\n",
    "\n",
    "        loss_distillation = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs_student / temperature, dim=1), #This part computes the logarithm of the softmax function applied to the output predictions of the student model divided by the temperature. The temperature is a hyperparameter that controls the smoothness of the probability distribution.\n",
    "                                           F.softmax(outputs_teacher / temperature, dim=1)) #Similarly, this part computes the softmax function applied to the output predictions of the teacher model divided by the temperature.\n",
    "\n",
    "        # Calculate the classification loss\n",
    "        loss_classification = criterion(outputs_student, labels)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_classification + loss_distillation\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs_student.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "        # Print batch statistics\n",
    "        if batch_idx % 100 == 0:  # Adjust the interval for printing\n",
    "            batch_accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / (batch_idx + 1):.4f}, correct :{correct}, total: {total}, Batch Accuracy: {batch_accuracy:.2f}%')\n",
    "\n",
    "    # Validation phase\n",
    "    student_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for val_batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "            # Forward pass for the teacher model\n",
    "            with torch.no_grad():\n",
    "                val_outputs_teacher = teacher_model(val_inputs)\n",
    "\n",
    "            # Forward pass for the student model\n",
    "            val_outputs_student = student_model(val_inputs)\n",
    "\n",
    "            _, val_predicted = val_outputs_student.max(1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += val_predicted.eq(val_labels).sum().item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Print validation statistics\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, '\n",
    "            f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'student_model_state_dict': student_model.state_dict(),\n",
    "        'optimizer_student_state_dict': optimizer_student.state_dict(),\n",
    "        'val_accuracy': val_accuracy,\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pt')\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "formatted_time = datetime.datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(formatted_time)\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "with open(\"execution_time_kd.txt\", \"w\") as file:\n",
    "    file.write(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model, 'KD_full_mobiFace_like_v1_4.pth') \n",
    "torch.save(student_model.state_dict(), 'KD_dict_mobiFace_live_v1_4.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
