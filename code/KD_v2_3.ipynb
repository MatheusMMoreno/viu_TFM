{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobiFace(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bottleneck_block1): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block1): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block1_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block2): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2_3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block3): BottleneckBlock(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_4): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_5): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3_6): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): PReLU(num_parameters=1)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "\n",
    "#import models\n",
    "from mobiface_like_v2 import MobiFace\n",
    "from backbone import get_model\n",
    "import model\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, also set the seed for GPU\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10575\n",
    "student = MobiFace()\n",
    "student.fc = nn.Linear(in_features=512, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobiFace                                      [1, 10575]                --\n",
       "├─Conv2d: 1-1                                 [1, 64, 56, 56]           1,728\n",
       "├─BatchNorm2d: 1-2                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-3                                  [1, 64, 56, 56]           1\n",
       "├─DepthwiseSeparableConv2d: 1-4               [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 56, 56]           576\n",
       "│    └─Conv2d: 2-2                            [1, 64, 56, 56]           4,096\n",
       "│    └─BatchNorm2d: 2-3                       [1, 64, 56, 56]           128\n",
       "│    └─PReLU: 2-4                             [1, 64, 56, 56]           1\n",
       "├─BatchNorm2d: 1-5                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-6                                  [1, 64, 56, 56]           (recursive)\n",
       "├─BottleneckBlock: 1-7                        [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-5                            [1, 32, 56, 56]           2,048\n",
       "│    └─BatchNorm2d: 2-6                       [1, 32, 56, 56]           64\n",
       "│    └─PReLU: 2-7                             [1, 32, 56, 56]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-8          [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                       [1, 32, 28, 28]           288\n",
       "│    │    └─Conv2d: 3-2                       [1, 32, 28, 28]           1,024\n",
       "│    │    └─BatchNorm2d: 3-3                  [1, 32, 28, 28]           64\n",
       "│    │    └─PReLU: 3-4                        [1, 32, 28, 28]           1\n",
       "│    └─BatchNorm2d: 2-9                       [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-10                            [1, 32, 28, 28]           (recursive)\n",
       "│    └─Conv2d: 2-11                           [1, 64, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-12                      [1, 64, 28, 28]           128\n",
       "├─InvertedResidualBlock: 1-8                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-13                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-14                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-15                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-16         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-5                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-6                       [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-8                        [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-17                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-18                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-19                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-20                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-21                       [1, 64, 28, 28]           --\n",
       "├─InvertedResidualBlock: 1-9                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-22                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-23                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-24                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-25         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-9                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-10                      [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-11                 [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-12                       [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-26                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-27                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-28                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-29                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-30                       [1, 64, 28, 28]           --\n",
       "├─BottleneckBlock: 1-10                       [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-31                           [1, 32, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-32                      [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-33                            [1, 32, 28, 28]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-34         [1, 32, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-13                      [1, 32, 14, 14]           288\n",
       "│    │    └─Conv2d: 3-14                      [1, 32, 14, 14]           1,024\n",
       "│    │    └─BatchNorm2d: 3-15                 [1, 32, 14, 14]           64\n",
       "│    │    └─PReLU: 3-16                       [1, 32, 14, 14]           1\n",
       "│    └─BatchNorm2d: 2-35                      [1, 32, 14, 14]           64\n",
       "│    └─PReLU: 2-36                            [1, 32, 14, 14]           (recursive)\n",
       "│    └─Conv2d: 2-37                           [1, 128, 14, 14]          4,096\n",
       "│    └─BatchNorm2d: 2-38                      [1, 128, 14, 14]          256\n",
       "├─InvertedResidualBlock: 1-11                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-39                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-40                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-41                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-42         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-17                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-18                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-19                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-20                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-43                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-44                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-45                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-46                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-47                       [1, 128, 14, 14]          --\n",
       "├─InvertedResidualBlock: 1-12                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-48                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-49                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-50                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-51         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-21                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-22                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-23                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-24                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-52                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-53                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-54                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-55                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-56                       [1, 128, 14, 14]          --\n",
       "├─InvertedResidualBlock: 1-13                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-57                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-58                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-59                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-60         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-25                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-26                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-27                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-28                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-61                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-62                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-63                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-64                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-65                       [1, 128, 14, 14]          --\n",
       "├─BottleneckBlock: 1-14                       [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-66                           [1, 64, 14, 14]           8,192\n",
       "│    └─BatchNorm2d: 2-67                      [1, 64, 14, 14]           128\n",
       "│    └─PReLU: 2-68                            [1, 64, 14, 14]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-69         [1, 64, 7, 7]             --\n",
       "│    │    └─Conv2d: 3-29                      [1, 64, 7, 7]             576\n",
       "│    │    └─Conv2d: 3-30                      [1, 64, 7, 7]             4,096\n",
       "│    │    └─BatchNorm2d: 3-31                 [1, 64, 7, 7]             128\n",
       "│    │    └─PReLU: 3-32                       [1, 64, 7, 7]             1\n",
       "│    └─BatchNorm2d: 2-70                      [1, 64, 7, 7]             128\n",
       "│    └─PReLU: 2-71                            [1, 64, 7, 7]             (recursive)\n",
       "│    └─Conv2d: 2-72                           [1, 256, 7, 7]            16,384\n",
       "│    └─BatchNorm2d: 2-73                      [1, 256, 7, 7]            512\n",
       "├─InvertedResidualBlock: 1-15                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-74                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-75                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-76                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-77         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-33                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-34                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-35                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-36                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-78                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-79                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-80                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-81                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-82                       [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-16                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-83                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-84                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-85                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-86         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-37                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-38                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-39                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-40                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-87                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-88                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-89                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-90                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-91                       [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-17                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-92                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-93                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-94                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-95         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-41                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-42                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-43                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-44                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-96                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-97                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-98                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-99                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-100                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-18                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-101                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-102                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-103                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-104        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-45                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-46                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-47                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-48                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-105                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-106                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-107                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-108                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-109                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-19                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-110                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-111                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-112                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-113        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-49                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-50                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-51                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-52                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-114                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-115                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-116                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-117                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-118                      [1, 256, 7, 7]            --\n",
       "├─InvertedResidualBlock: 1-20                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-119                          [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-120                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-121                           [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-122        [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-53                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-54                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-55                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-56                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-123                     [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-124                           [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-125                          [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-126                     [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-127                      [1, 256, 7, 7]            --\n",
       "├─Conv2d: 1-21                                [1, 512, 7, 7]            131,072\n",
       "├─BatchNorm2d: 1-22                           [1, 512, 7, 7]            1,024\n",
       "├─Linear: 1-23                                [1, 10575]                5,424,975\n",
       "===============================================================================================\n",
       "Total params: 9,277,677\n",
       "Trainable params: 9,277,677\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 333.42\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 61.45\n",
       "Params size (MB): 37.11\n",
       "Estimated Total Size (MB): 98.71\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(student, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher =  torch.load(\"full_webcassia_finetuned_v2.pth\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionResnetV1(\n",
       "  (conv2d_1a): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2a): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2b): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_3b): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4a): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4b): BasicConv2d(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (repeat_1): Sequential(\n",
       "    (0): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_6a): Mixed_6a(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_2): Sequential(\n",
       "    (0): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_7a): Mixed_7a(\n",
       "    (branch0): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_3): Sequential(\n",
       "    (0): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (block8): Block8(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "InceptionResnetV1                             [1, 10575]                --\n",
       "├─BasicConv2d: 1-1                            [1, 32, 55, 55]           --\n",
       "│    └─Conv2d: 2-1                            [1, 32, 55, 55]           (864)\n",
       "│    └─BatchNorm2d: 2-2                       [1, 32, 55, 55]           (64)\n",
       "│    └─ReLU: 2-3                              [1, 32, 55, 55]           --\n",
       "├─BasicConv2d: 1-2                            [1, 32, 53, 53]           --\n",
       "│    └─Conv2d: 2-4                            [1, 32, 53, 53]           (9,216)\n",
       "│    └─BatchNorm2d: 2-5                       [1, 32, 53, 53]           (64)\n",
       "│    └─ReLU: 2-6                              [1, 32, 53, 53]           --\n",
       "├─BasicConv2d: 1-3                            [1, 64, 53, 53]           --\n",
       "│    └─Conv2d: 2-7                            [1, 64, 53, 53]           (18,432)\n",
       "│    └─BatchNorm2d: 2-8                       [1, 64, 53, 53]           (128)\n",
       "│    └─ReLU: 2-9                              [1, 64, 53, 53]           --\n",
       "├─MaxPool2d: 1-4                              [1, 64, 26, 26]           --\n",
       "├─BasicConv2d: 1-5                            [1, 80, 26, 26]           --\n",
       "│    └─Conv2d: 2-10                           [1, 80, 26, 26]           (5,120)\n",
       "│    └─BatchNorm2d: 2-11                      [1, 80, 26, 26]           (160)\n",
       "│    └─ReLU: 2-12                             [1, 80, 26, 26]           --\n",
       "├─BasicConv2d: 1-6                            [1, 192, 24, 24]          --\n",
       "│    └─Conv2d: 2-13                           [1, 192, 24, 24]          (138,240)\n",
       "│    └─BatchNorm2d: 2-14                      [1, 192, 24, 24]          (384)\n",
       "│    └─ReLU: 2-15                             [1, 192, 24, 24]          --\n",
       "├─BasicConv2d: 1-7                            [1, 256, 11, 11]          --\n",
       "│    └─Conv2d: 2-16                           [1, 256, 11, 11]          (442,368)\n",
       "│    └─BatchNorm2d: 2-17                      [1, 256, 11, 11]          (512)\n",
       "│    └─ReLU: 2-18                             [1, 256, 11, 11]          --\n",
       "├─Sequential: 1-8                             [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-19                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-1                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-2                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-3                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-4                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-5                         [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-20                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-6                  [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-7                   [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-8                   [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-9                       [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-10                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-21                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-11                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-12                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-13                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-14                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-15                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-22                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-16                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-17                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-18                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-19                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-20                        [1, 256, 11, 11]          --\n",
       "│    └─Block35: 2-23                          [1, 256, 11, 11]          --\n",
       "│    │    └─BasicConv2d: 3-21                 [1, 32, 11, 11]           (8,256)\n",
       "│    │    └─Sequential: 3-22                  [1, 32, 11, 11]           (17,536)\n",
       "│    │    └─Sequential: 3-23                  [1, 32, 11, 11]           (26,816)\n",
       "│    │    └─Conv2d: 3-24                      [1, 256, 11, 11]          (24,832)\n",
       "│    │    └─ReLU: 3-25                        [1, 256, 11, 11]          --\n",
       "├─Mixed_6a: 1-9                               [1, 896, 5, 5]            --\n",
       "│    └─BasicConv2d: 2-24                      [1, 384, 5, 5]            --\n",
       "│    │    └─Conv2d: 3-26                      [1, 384, 5, 5]            (884,736)\n",
       "│    │    └─BatchNorm2d: 3-27                 [1, 384, 5, 5]            (768)\n",
       "│    │    └─ReLU: 3-28                        [1, 384, 5, 5]            --\n",
       "│    └─Sequential: 2-25                       [1, 256, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-29                 [1, 192, 11, 11]          (49,536)\n",
       "│    │    └─BasicConv2d: 3-30                 [1, 192, 11, 11]          (332,160)\n",
       "│    │    └─BasicConv2d: 3-31                 [1, 256, 5, 5]            (442,880)\n",
       "│    └─MaxPool2d: 2-26                        [1, 256, 5, 5]            --\n",
       "├─Sequential: 1-10                            [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-27                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-32                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-33                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-34                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-35                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-28                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-36                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-37                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-38                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-39                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-29                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-40                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-41                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-42                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-43                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-30                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-44                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-45                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-46                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-47                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-31                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-48                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-49                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-50                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-51                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-32                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-52                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-53                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-54                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-55                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-33                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-56                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-57                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-58                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-59                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-34                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-60                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-61                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-62                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-63                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-35                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-64                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-65                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-66                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-67                        [1, 896, 5, 5]            --\n",
       "│    └─Block17: 2-36                          [1, 896, 5, 5]            --\n",
       "│    │    └─BasicConv2d: 3-68                 [1, 128, 5, 5]            (114,944)\n",
       "│    │    └─Sequential: 3-69                  [1, 128, 5, 5]            (344,832)\n",
       "│    │    └─Conv2d: 3-70                      [1, 896, 5, 5]            (230,272)\n",
       "│    │    └─ReLU: 3-71                        [1, 896, 5, 5]            --\n",
       "├─Mixed_7a: 1-11                              [1, 1792, 2, 2]           --\n",
       "│    └─Sequential: 2-37                       [1, 384, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-72                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-73                 [1, 384, 2, 2]            (885,504)\n",
       "│    └─Sequential: 2-38                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-74                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-75                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─Sequential: 2-39                       [1, 256, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-76                 [1, 256, 5, 5]            (229,888)\n",
       "│    │    └─BasicConv2d: 3-77                 [1, 256, 5, 5]            (590,336)\n",
       "│    │    └─BasicConv2d: 3-78                 [1, 256, 2, 2]            (590,336)\n",
       "│    └─MaxPool2d: 2-40                        [1, 896, 2, 2]            --\n",
       "├─Sequential: 1-12                            [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-41                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-79                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-80                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-81                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-82                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-42                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-83                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-84                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-85                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-86                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-43                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-87                 [1, 192, 2, 2]            344,448\n",
       "│    │    └─Sequential: 3-88                  [1, 192, 2, 2]            566,400\n",
       "│    │    └─Conv2d: 3-89                      [1, 1792, 2, 2]           689,920\n",
       "│    │    └─ReLU: 3-90                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-44                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-91                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-92                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-93                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-94                        [1, 1792, 2, 2]           --\n",
       "│    └─Block8: 2-45                           [1, 1792, 2, 2]           --\n",
       "│    │    └─BasicConv2d: 3-95                 [1, 192, 2, 2]            (344,448)\n",
       "│    │    └─Sequential: 3-96                  [1, 192, 2, 2]            (566,400)\n",
       "│    │    └─Conv2d: 3-97                      [1, 1792, 2, 2]           (689,920)\n",
       "│    │    └─ReLU: 3-98                        [1, 1792, 2, 2]           --\n",
       "├─Block8: 1-13                                [1, 1792, 2, 2]           --\n",
       "│    └─BasicConv2d: 2-46                      [1, 192, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-99                      [1, 192, 2, 2]            344,064\n",
       "│    │    └─BatchNorm2d: 3-100                [1, 192, 2, 2]            384\n",
       "│    │    └─ReLU: 3-101                       [1, 192, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       [1, 192, 2, 2]            --\n",
       "│    │    └─BasicConv2d: 3-102                [1, 192, 2, 2]            344,448\n",
       "│    │    └─BasicConv2d: 3-103                [1, 192, 2, 2]            110,976\n",
       "│    │    └─BasicConv2d: 3-104                [1, 192, 2, 2]            110,976\n",
       "│    └─Conv2d: 2-48                           [1, 1792, 2, 2]           689,920\n",
       "├─AdaptiveAvgPool2d: 1-14                     [1, 1792, 1, 1]           --\n",
       "├─Dropout: 1-15                               [1, 1792, 1, 1]           --\n",
       "├─Linear: 1-16                                [1, 512]                  917,504\n",
       "├─BatchNorm1d: 1-17                           [1, 512]                  1,024\n",
       "├─Linear: 1-18                                [1, 10575]                5,424,975\n",
       "===============================================================================================\n",
       "Total params: 28,907,599\n",
       "Trainable params: 9,545,039\n",
       "Non-trainable params: 19,362,560\n",
       "Total mult-adds (M): 600.00\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 18.13\n",
       "Params size (MB): 115.63\n",
       "Estimated Total Size (MB): 133.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(teacher, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KD Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for test\n",
    "#root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\small_sample\"\n",
    "root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\images\"\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Create ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# Number of images for testing\n",
    "num_test_images = 2000\n",
    "\n",
    "# Total number of images\n",
    "total_images = len(dataset)\n",
    "\n",
    "# Indices of images for testing\n",
    "test_indices = random.sample(range(total_images), num_test_images)\n",
    "\n",
    "# Remaining indices for validation and training\n",
    "remaining_indices = set(range(total_images)) - set(test_indices)\n",
    "\n",
    "\n",
    "# Split remaining indices into validation and training sets\n",
    "remaining_indices = list(remaining_indices)\n",
    "random.shuffle(remaining_indices)\n",
    "\n",
    "\n",
    "# Define the sizes of validation and training sets\n",
    "val_size = int(0.30 * len(remaining_indices))\n",
    "train_size = len(remaining_indices) - val_size\n",
    "\n",
    "# Indices for validation and training sets\n",
    "val_indices = remaining_indices[:val_size]\n",
    "train_indices = remaining_indices[val_size:]\n",
    "\n",
    "\n",
    "# Create Subset datasets\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiFace(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bottleneck_block1): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block2): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block3): BottleneckBlock(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_4): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_5): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3_6): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): PReLU(num_parameters=1)\n",
       "  (fc): Linear(in_features=512, out_features=10575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = student\n",
    "teacher_model = teacher\n",
    "\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [1/2673], Loss: 10.2471, correct :0, total: 128, Batch Accuracy: 0.00%\n",
      "Epoch [1/15], Batch [101/2673], Loss: 10.0705, correct :19, total: 12928, Batch Accuracy: 0.15%\n",
      "Epoch [1/15], Batch [201/2673], Loss: 9.9320, correct :58, total: 25728, Batch Accuracy: 0.23%\n",
      "Epoch [1/15], Batch [301/2673], Loss: 9.8176, correct :114, total: 38528, Batch Accuracy: 0.30%\n",
      "Epoch [1/15], Batch [401/2673], Loss: 9.7114, correct :194, total: 51328, Batch Accuracy: 0.38%\n",
      "Epoch [1/15], Batch [501/2673], Loss: 9.6043, correct :300, total: 64128, Batch Accuracy: 0.47%\n",
      "Epoch [1/15], Batch [601/2673], Loss: 9.5028, correct :435, total: 76928, Batch Accuracy: 0.57%\n",
      "Epoch [1/15], Batch [701/2673], Loss: 9.4096, correct :604, total: 89728, Batch Accuracy: 0.67%\n",
      "Epoch [1/15], Batch [801/2673], Loss: 9.3211, correct :820, total: 102528, Batch Accuracy: 0.80%\n",
      "Epoch [1/15], Batch [901/2673], Loss: 9.2346, correct :1063, total: 115328, Batch Accuracy: 0.92%\n",
      "Epoch [1/15], Batch [1001/2673], Loss: 9.1513, correct :1378, total: 128128, Batch Accuracy: 1.08%\n",
      "Epoch [1/15], Batch [1101/2673], Loss: 9.0740, correct :1687, total: 140928, Batch Accuracy: 1.20%\n",
      "Epoch [1/15], Batch [1201/2673], Loss: 9.0009, correct :2063, total: 153728, Batch Accuracy: 1.34%\n",
      "Epoch [1/15], Batch [1301/2673], Loss: 8.9309, correct :2484, total: 166528, Batch Accuracy: 1.49%\n",
      "Epoch [1/15], Batch [1401/2673], Loss: 8.8655, correct :2902, total: 179328, Batch Accuracy: 1.62%\n",
      "Epoch [1/15], Batch [1501/2673], Loss: 8.8019, correct :3391, total: 192128, Batch Accuracy: 1.76%\n",
      "Epoch [1/15], Batch [1601/2673], Loss: 8.7412, correct :3929, total: 204928, Batch Accuracy: 1.92%\n",
      "Epoch [1/15], Batch [1701/2673], Loss: 8.6795, correct :4540, total: 217728, Batch Accuracy: 2.09%\n",
      "Epoch [1/15], Batch [1801/2673], Loss: 8.6189, correct :5231, total: 230528, Batch Accuracy: 2.27%\n",
      "Epoch [1/15], Batch [1901/2673], Loss: 8.5614, correct :5957, total: 243328, Batch Accuracy: 2.45%\n",
      "Epoch [1/15], Batch [2001/2673], Loss: 8.5032, correct :6796, total: 256128, Batch Accuracy: 2.65%\n",
      "Epoch [1/15], Batch [2101/2673], Loss: 8.4446, correct :7745, total: 268928, Batch Accuracy: 2.88%\n",
      "Epoch [1/15], Batch [2201/2673], Loss: 8.3861, correct :8779, total: 281728, Batch Accuracy: 3.12%\n",
      "Epoch [1/15], Batch [2301/2673], Loss: 8.3273, correct :9971, total: 294528, Batch Accuracy: 3.39%\n",
      "Epoch [1/15], Batch [2401/2673], Loss: 8.2691, correct :11126, total: 307328, Batch Accuracy: 3.62%\n",
      "Epoch [1/15], Batch [2501/2673], Loss: 8.2115, correct :12439, total: 320128, Batch Accuracy: 3.89%\n",
      "Epoch [1/15], Batch [2601/2673], Loss: 8.1540, correct :13851, total: 332928, Batch Accuracy: 4.16%\n",
      "Epoch [1/15], Validation Loss: 0.0000, Validation Accuracy: 11.24%\n",
      "Epoch [2/15], Batch [1/2673], Loss: 6.7861, correct :14, total: 128, Batch Accuracy: 10.94%\n",
      "Epoch [2/15], Batch [101/2673], Loss: 6.4976, correct :1608, total: 12928, Batch Accuracy: 12.44%\n",
      "Epoch [2/15], Batch [201/2673], Loss: 6.4847, correct :3228, total: 25728, Batch Accuracy: 12.55%\n",
      "Epoch [2/15], Batch [301/2673], Loss: 6.4320, correct :4992, total: 38528, Batch Accuracy: 12.96%\n",
      "Epoch [2/15], Batch [401/2673], Loss: 6.3941, correct :6820, total: 51328, Batch Accuracy: 13.29%\n",
      "Epoch [2/15], Batch [501/2673], Loss: 6.3437, correct :8792, total: 64128, Batch Accuracy: 13.71%\n",
      "Epoch [2/15], Batch [601/2673], Loss: 6.2921, correct :10924, total: 76928, Batch Accuracy: 14.20%\n",
      "Epoch [2/15], Batch [701/2673], Loss: 6.2556, correct :13018, total: 89728, Batch Accuracy: 14.51%\n",
      "Epoch [2/15], Batch [801/2673], Loss: 6.2144, correct :15354, total: 102528, Batch Accuracy: 14.98%\n",
      "Epoch [2/15], Batch [901/2673], Loss: 6.1739, correct :17700, total: 115328, Batch Accuracy: 15.35%\n",
      "Epoch [2/15], Batch [1001/2673], Loss: 6.1358, correct :20191, total: 128128, Batch Accuracy: 15.76%\n",
      "Epoch [2/15], Batch [1101/2673], Loss: 6.0978, correct :22752, total: 140928, Batch Accuracy: 16.14%\n",
      "Epoch [2/15], Batch [1201/2673], Loss: 6.0603, correct :25380, total: 153728, Batch Accuracy: 16.51%\n",
      "Epoch [2/15], Batch [1301/2673], Loss: 6.0223, correct :28110, total: 166528, Batch Accuracy: 16.88%\n",
      "Epoch [2/15], Batch [1401/2673], Loss: 5.9867, correct :30876, total: 179328, Batch Accuracy: 17.22%\n",
      "Epoch [2/15], Batch [1501/2673], Loss: 5.9513, correct :33756, total: 192128, Batch Accuracy: 17.57%\n",
      "Epoch [2/15], Batch [1601/2673], Loss: 5.9173, correct :36728, total: 204928, Batch Accuracy: 17.92%\n",
      "Epoch [2/15], Batch [1701/2673], Loss: 5.8802, correct :39871, total: 217728, Batch Accuracy: 18.31%\n",
      "Epoch [2/15], Batch [1801/2673], Loss: 5.8451, correct :43050, total: 230528, Batch Accuracy: 18.67%\n",
      "Epoch [2/15], Batch [1901/2673], Loss: 5.8118, correct :46399, total: 243328, Batch Accuracy: 19.07%\n",
      "Epoch [2/15], Batch [2001/2673], Loss: 5.7776, correct :49795, total: 256128, Batch Accuracy: 19.44%\n",
      "Epoch [2/15], Batch [2101/2673], Loss: 5.7425, correct :53364, total: 268928, Batch Accuracy: 19.84%\n",
      "Epoch [2/15], Batch [2201/2673], Loss: 5.7096, correct :57014, total: 281728, Batch Accuracy: 20.24%\n",
      "Epoch [2/15], Batch [2301/2673], Loss: 5.6759, correct :60743, total: 294528, Batch Accuracy: 20.62%\n",
      "Epoch [2/15], Batch [2401/2673], Loss: 5.6427, correct :64507, total: 307328, Batch Accuracy: 20.99%\n",
      "Epoch [2/15], Batch [2501/2673], Loss: 5.6123, correct :68346, total: 320128, Batch Accuracy: 21.35%\n",
      "Epoch [2/15], Batch [2601/2673], Loss: 5.5813, correct :72298, total: 332928, Batch Accuracy: 21.72%\n",
      "Epoch [2/15], Validation Loss: 0.0000, Validation Accuracy: 28.40%\n",
      "Epoch [3/15], Batch [1/2673], Loss: 4.6849, correct :40, total: 128, Batch Accuracy: 31.25%\n",
      "Epoch [3/15], Batch [101/2673], Loss: 4.6817, correct :4032, total: 12928, Batch Accuracy: 31.19%\n",
      "Epoch [3/15], Batch [201/2673], Loss: 4.6966, correct :8185, total: 25728, Batch Accuracy: 31.81%\n",
      "Epoch [3/15], Batch [301/2673], Loss: 4.6617, correct :12507, total: 38528, Batch Accuracy: 32.46%\n",
      "Epoch [3/15], Batch [401/2673], Loss: 4.6467, correct :16768, total: 51328, Batch Accuracy: 32.67%\n",
      "Epoch [3/15], Batch [501/2673], Loss: 4.6251, correct :21149, total: 64128, Batch Accuracy: 32.98%\n",
      "Epoch [3/15], Batch [601/2673], Loss: 4.5935, correct :25737, total: 76928, Batch Accuracy: 33.46%\n",
      "Epoch [3/15], Batch [701/2673], Loss: 4.5749, correct :30307, total: 89728, Batch Accuracy: 33.78%\n",
      "Epoch [3/15], Batch [801/2673], Loss: 4.5513, correct :34963, total: 102528, Batch Accuracy: 34.10%\n",
      "Epoch [3/15], Batch [901/2673], Loss: 4.5284, correct :39769, total: 115328, Batch Accuracy: 34.48%\n",
      "Epoch [3/15], Batch [1001/2673], Loss: 4.5077, correct :44570, total: 128128, Batch Accuracy: 34.79%\n",
      "Epoch [3/15], Batch [1101/2673], Loss: 4.4854, correct :49483, total: 140928, Batch Accuracy: 35.11%\n",
      "Epoch [3/15], Batch [1201/2673], Loss: 4.4634, correct :54526, total: 153728, Batch Accuracy: 35.47%\n",
      "Epoch [3/15], Batch [1301/2673], Loss: 4.4413, correct :59589, total: 166528, Batch Accuracy: 35.78%\n",
      "Epoch [3/15], Batch [1401/2673], Loss: 4.4191, correct :64759, total: 179328, Batch Accuracy: 36.11%\n",
      "Epoch [3/15], Batch [1501/2673], Loss: 4.3984, correct :69990, total: 192128, Batch Accuracy: 36.43%\n",
      "Epoch [3/15], Batch [1601/2673], Loss: 4.3772, correct :75250, total: 204928, Batch Accuracy: 36.72%\n",
      "Epoch [3/15], Batch [1701/2673], Loss: 4.3526, correct :80712, total: 217728, Batch Accuracy: 37.07%\n",
      "Epoch [3/15], Batch [1801/2673], Loss: 4.3303, correct :86213, total: 230528, Batch Accuracy: 37.40%\n",
      "Epoch [3/15], Batch [1901/2673], Loss: 4.3077, correct :91808, total: 243328, Batch Accuracy: 37.73%\n",
      "Epoch [3/15], Batch [2001/2673], Loss: 4.2846, correct :97519, total: 256128, Batch Accuracy: 38.07%\n",
      "Epoch [3/15], Batch [2101/2673], Loss: 4.2607, correct :103315, total: 268928, Batch Accuracy: 38.42%\n",
      "Epoch [3/15], Batch [2201/2673], Loss: 4.2395, correct :109147, total: 281728, Batch Accuracy: 38.74%\n",
      "Epoch [3/15], Batch [2301/2673], Loss: 4.2168, correct :115066, total: 294528, Batch Accuracy: 39.07%\n",
      "Epoch [3/15], Batch [2401/2673], Loss: 4.1938, correct :121039, total: 307328, Batch Accuracy: 39.38%\n",
      "Epoch [3/15], Batch [2501/2673], Loss: 4.1741, correct :127041, total: 320128, Batch Accuracy: 39.68%\n",
      "Epoch [3/15], Batch [2601/2673], Loss: 4.1537, correct :133154, total: 332928, Batch Accuracy: 39.99%\n",
      "Epoch [3/15], Validation Loss: 0.0000, Validation Accuracy: 44.61%\n",
      "Epoch [4/15], Batch [1/2673], Loss: 3.6413, correct :64, total: 128, Batch Accuracy: 50.00%\n",
      "Epoch [4/15], Batch [101/2673], Loss: 3.5226, correct :6334, total: 12928, Batch Accuracy: 48.99%\n",
      "Epoch [4/15], Batch [201/2673], Loss: 3.5494, correct :12534, total: 25728, Batch Accuracy: 48.72%\n",
      "Epoch [4/15], Batch [301/2673], Loss: 3.5305, correct :18933, total: 38528, Batch Accuracy: 49.14%\n",
      "Epoch [4/15], Batch [401/2673], Loss: 3.5234, correct :25328, total: 51328, Batch Accuracy: 49.35%\n",
      "Epoch [4/15], Batch [501/2673], Loss: 3.5148, correct :31803, total: 64128, Batch Accuracy: 49.59%\n",
      "Epoch [4/15], Batch [601/2673], Loss: 3.4964, correct :38368, total: 76928, Batch Accuracy: 49.88%\n",
      "Epoch [4/15], Batch [701/2673], Loss: 3.4813, correct :44996, total: 89728, Batch Accuracy: 50.15%\n",
      "Epoch [4/15], Batch [801/2673], Loss: 3.4681, correct :51631, total: 102528, Batch Accuracy: 50.36%\n",
      "Epoch [4/15], Batch [901/2673], Loss: 3.4555, correct :58332, total: 115328, Batch Accuracy: 50.58%\n",
      "Epoch [4/15], Batch [1001/2673], Loss: 3.4422, correct :65171, total: 128128, Batch Accuracy: 50.86%\n",
      "Epoch [4/15], Batch [1101/2673], Loss: 3.4287, correct :71969, total: 140928, Batch Accuracy: 51.07%\n",
      "Epoch [4/15], Batch [1201/2673], Loss: 3.4163, correct :78804, total: 153728, Batch Accuracy: 51.26%\n",
      "Epoch [4/15], Batch [1301/2673], Loss: 3.4044, correct :85758, total: 166528, Batch Accuracy: 51.50%\n",
      "Epoch [4/15], Batch [1401/2673], Loss: 3.3916, correct :92723, total: 179328, Batch Accuracy: 51.71%\n",
      "Epoch [4/15], Batch [1501/2673], Loss: 3.3798, correct :99757, total: 192128, Batch Accuracy: 51.92%\n",
      "Epoch [4/15], Batch [1601/2673], Loss: 3.3694, correct :106716, total: 204928, Batch Accuracy: 52.07%\n",
      "Epoch [4/15], Batch [1701/2673], Loss: 3.3544, correct :113972, total: 217728, Batch Accuracy: 52.35%\n",
      "Epoch [4/15], Batch [1801/2673], Loss: 3.3412, correct :121161, total: 230528, Batch Accuracy: 52.56%\n",
      "Epoch [4/15], Batch [1901/2673], Loss: 3.3274, correct :128436, total: 243328, Batch Accuracy: 52.78%\n",
      "Epoch [4/15], Batch [2001/2673], Loss: 3.3145, correct :135690, total: 256128, Batch Accuracy: 52.98%\n",
      "Epoch [4/15], Batch [2101/2673], Loss: 3.3013, correct :143033, total: 268928, Batch Accuracy: 53.19%\n",
      "Epoch [4/15], Batch [2201/2673], Loss: 3.2894, correct :150361, total: 281728, Batch Accuracy: 53.37%\n",
      "Epoch [4/15], Batch [2301/2673], Loss: 3.2759, correct :157868, total: 294528, Batch Accuracy: 53.60%\n",
      "Epoch [4/15], Batch [2401/2673], Loss: 3.2621, correct :165320, total: 307328, Batch Accuracy: 53.79%\n",
      "Epoch [4/15], Batch [2501/2673], Loss: 3.2515, correct :172812, total: 320128, Batch Accuracy: 53.98%\n",
      "Epoch [4/15], Batch [2601/2673], Loss: 3.2404, correct :180369, total: 332928, Batch Accuracy: 54.18%\n",
      "Epoch [4/15], Validation Loss: 0.0000, Validation Accuracy: 53.54%\n",
      "Epoch [5/15], Batch [1/2673], Loss: 3.0237, correct :76, total: 128, Batch Accuracy: 59.38%\n",
      "Epoch [5/15], Batch [101/2673], Loss: 2.8749, correct :7746, total: 12928, Batch Accuracy: 59.92%\n",
      "Epoch [5/15], Batch [201/2673], Loss: 2.8977, correct :15331, total: 25728, Batch Accuracy: 59.59%\n",
      "Epoch [5/15], Batch [301/2673], Loss: 2.8919, correct :23028, total: 38528, Batch Accuracy: 59.77%\n",
      "Epoch [5/15], Batch [401/2673], Loss: 2.8864, correct :30684, total: 51328, Batch Accuracy: 59.78%\n",
      "Epoch [5/15], Batch [501/2673], Loss: 2.8804, correct :38371, total: 64128, Batch Accuracy: 59.84%\n",
      "Epoch [5/15], Batch [601/2673], Loss: 2.8690, correct :46188, total: 76928, Batch Accuracy: 60.04%\n",
      "Epoch [5/15], Batch [701/2673], Loss: 2.8623, correct :53986, total: 89728, Batch Accuracy: 60.17%\n",
      "Epoch [5/15], Batch [801/2673], Loss: 2.8526, correct :61846, total: 102528, Batch Accuracy: 60.32%\n",
      "Epoch [5/15], Batch [901/2673], Loss: 2.8442, correct :69733, total: 115328, Batch Accuracy: 60.46%\n",
      "Epoch [5/15], Batch [1001/2673], Loss: 2.8369, correct :77637, total: 128128, Batch Accuracy: 60.59%\n",
      "Epoch [5/15], Batch [1101/2673], Loss: 2.8290, correct :85532, total: 140928, Batch Accuracy: 60.69%\n",
      "Epoch [5/15], Batch [1201/2673], Loss: 2.8219, correct :93552, total: 153728, Batch Accuracy: 60.86%\n",
      "Epoch [5/15], Batch [1301/2673], Loss: 2.8151, correct :101609, total: 166528, Batch Accuracy: 61.02%\n",
      "Epoch [5/15], Batch [1401/2673], Loss: 2.8074, correct :109589, total: 179328, Batch Accuracy: 61.11%\n",
      "Epoch [5/15], Batch [1501/2673], Loss: 2.8008, correct :117675, total: 192128, Batch Accuracy: 61.25%\n",
      "Epoch [5/15], Batch [1601/2673], Loss: 2.7939, correct :125740, total: 204928, Batch Accuracy: 61.36%\n",
      "Epoch [5/15], Batch [1701/2673], Loss: 2.7848, correct :133921, total: 217728, Batch Accuracy: 61.51%\n",
      "Epoch [5/15], Batch [1801/2673], Loss: 2.7767, correct :142050, total: 230528, Batch Accuracy: 61.62%\n",
      "Epoch [5/15], Batch [1901/2673], Loss: 2.7679, correct :150268, total: 243328, Batch Accuracy: 61.76%\n",
      "Epoch [5/15], Batch [2001/2673], Loss: 2.7582, correct :158528, total: 256128, Batch Accuracy: 61.89%\n",
      "Epoch [5/15], Batch [2101/2673], Loss: 2.7493, correct :166834, total: 268928, Batch Accuracy: 62.04%\n",
      "Epoch [5/15], Batch [2201/2673], Loss: 2.7422, correct :175143, total: 281728, Batch Accuracy: 62.17%\n",
      "Epoch [5/15], Batch [2301/2673], Loss: 2.7335, correct :183540, total: 294528, Batch Accuracy: 62.32%\n",
      "Epoch [5/15], Batch [2401/2673], Loss: 2.7240, correct :191897, total: 307328, Batch Accuracy: 62.44%\n",
      "Epoch [5/15], Batch [2501/2673], Loss: 2.7171, correct :200269, total: 320128, Batch Accuracy: 62.56%\n",
      "Epoch [5/15], Batch [2601/2673], Loss: 2.7098, correct :208698, total: 332928, Batch Accuracy: 62.69%\n",
      "Epoch [5/15], Validation Loss: 0.0000, Validation Accuracy: 59.72%\n",
      "Epoch [6/15], Batch [1/2673], Loss: 2.6230, correct :85, total: 128, Batch Accuracy: 66.41%\n",
      "Epoch [6/15], Batch [101/2673], Loss: 2.4468, correct :8624, total: 12928, Batch Accuracy: 66.71%\n",
      "Epoch [6/15], Batch [201/2673], Loss: 2.4750, correct :17054, total: 25728, Batch Accuracy: 66.29%\n",
      "Epoch [6/15], Batch [301/2673], Loss: 2.4751, correct :25578, total: 38528, Batch Accuracy: 66.39%\n",
      "Epoch [6/15], Batch [401/2673], Loss: 2.4718, correct :34096, total: 51328, Batch Accuracy: 66.43%\n",
      "Epoch [6/15], Batch [501/2673], Loss: 2.4719, correct :42621, total: 64128, Batch Accuracy: 66.46%\n",
      "Epoch [6/15], Batch [601/2673], Loss: 2.4632, correct :51236, total: 76928, Batch Accuracy: 66.60%\n",
      "Epoch [6/15], Batch [701/2673], Loss: 2.4578, correct :59818, total: 89728, Batch Accuracy: 66.67%\n",
      "Epoch [6/15], Batch [801/2673], Loss: 2.4515, correct :68477, total: 102528, Batch Accuracy: 66.79%\n",
      "Epoch [6/15], Batch [901/2673], Loss: 2.4445, correct :77184, total: 115328, Batch Accuracy: 66.93%\n",
      "Epoch [6/15], Batch [1001/2673], Loss: 2.4388, correct :85860, total: 128128, Batch Accuracy: 67.01%\n",
      "Epoch [6/15], Batch [1101/2673], Loss: 2.4324, correct :94560, total: 140928, Batch Accuracy: 67.10%\n",
      "Epoch [6/15], Batch [1201/2673], Loss: 2.4285, correct :103261, total: 153728, Batch Accuracy: 67.17%\n",
      "Epoch [6/15], Batch [1301/2673], Loss: 2.4239, correct :112051, total: 166528, Batch Accuracy: 67.29%\n",
      "Epoch [6/15], Batch [1401/2673], Loss: 2.4172, correct :120869, total: 179328, Batch Accuracy: 67.40%\n",
      "Epoch [6/15], Batch [1501/2673], Loss: 2.4122, correct :129654, total: 192128, Batch Accuracy: 67.48%\n",
      "Epoch [6/15], Batch [1601/2673], Loss: 2.4065, correct :138456, total: 204928, Batch Accuracy: 67.56%\n",
      "Epoch [6/15], Batch [1701/2673], Loss: 2.3997, correct :147351, total: 217728, Batch Accuracy: 67.68%\n",
      "Epoch [6/15], Batch [1801/2673], Loss: 2.3941, correct :156197, total: 230528, Batch Accuracy: 67.76%\n",
      "Epoch [6/15], Batch [1901/2673], Loss: 2.3877, correct :165086, total: 243328, Batch Accuracy: 67.85%\n",
      "Epoch [6/15], Batch [2001/2673], Loss: 2.3806, correct :174003, total: 256128, Batch Accuracy: 67.94%\n",
      "Epoch [6/15], Batch [2101/2673], Loss: 2.3738, correct :182953, total: 268928, Batch Accuracy: 68.03%\n",
      "Epoch [6/15], Batch [2201/2673], Loss: 2.3688, correct :191887, total: 281728, Batch Accuracy: 68.11%\n",
      "Epoch [6/15], Batch [2301/2673], Loss: 2.3627, correct :200942, total: 294528, Batch Accuracy: 68.23%\n",
      "Epoch [6/15], Batch [2401/2673], Loss: 2.3553, correct :209964, total: 307328, Batch Accuracy: 68.32%\n",
      "Epoch [6/15], Batch [2501/2673], Loss: 2.3513, correct :218913, total: 320128, Batch Accuracy: 68.38%\n",
      "Epoch [6/15], Batch [2601/2673], Loss: 2.3459, correct :228030, total: 332928, Batch Accuracy: 68.49%\n",
      "Epoch [6/15], Validation Loss: 0.0000, Validation Accuracy: 62.67%\n",
      "Epoch [7/15], Batch [1/2673], Loss: 2.3103, correct :89, total: 128, Batch Accuracy: 69.53%\n",
      "Epoch [7/15], Batch [101/2673], Loss: 2.1532, correct :9219, total: 12928, Batch Accuracy: 71.31%\n",
      "Epoch [7/15], Batch [201/2673], Loss: 2.1742, correct :18274, total: 25728, Batch Accuracy: 71.03%\n",
      "Epoch [7/15], Batch [301/2673], Loss: 2.1717, correct :27411, total: 38528, Batch Accuracy: 71.15%\n",
      "Epoch [7/15], Batch [401/2673], Loss: 2.1683, correct :36518, total: 51328, Batch Accuracy: 71.15%\n",
      "Epoch [7/15], Batch [501/2673], Loss: 2.1672, correct :45653, total: 64128, Batch Accuracy: 71.19%\n",
      "Epoch [7/15], Batch [601/2673], Loss: 2.1613, correct :54830, total: 76928, Batch Accuracy: 71.27%\n",
      "Epoch [7/15], Batch [701/2673], Loss: 2.1567, correct :64080, total: 89728, Batch Accuracy: 71.42%\n",
      "Epoch [7/15], Batch [801/2673], Loss: 2.1526, correct :73351, total: 102528, Batch Accuracy: 71.54%\n",
      "Epoch [7/15], Batch [901/2673], Loss: 2.1481, correct :82620, total: 115328, Batch Accuracy: 71.64%\n",
      "Epoch [7/15], Batch [1001/2673], Loss: 2.1441, correct :91887, total: 128128, Batch Accuracy: 71.72%\n",
      "Epoch [7/15], Batch [1101/2673], Loss: 2.1386, correct :101185, total: 140928, Batch Accuracy: 71.80%\n",
      "Epoch [7/15], Batch [1201/2673], Loss: 2.1363, correct :110459, total: 153728, Batch Accuracy: 71.85%\n",
      "Epoch [7/15], Batch [1301/2673], Loss: 2.1338, correct :119768, total: 166528, Batch Accuracy: 71.92%\n",
      "Epoch [7/15], Batch [1401/2673], Loss: 2.1297, correct :129097, total: 179328, Batch Accuracy: 71.99%\n",
      "Epoch [7/15], Batch [1501/2673], Loss: 2.1259, correct :138451, total: 192128, Batch Accuracy: 72.06%\n",
      "Epoch [7/15], Batch [1601/2673], Loss: 2.1223, correct :147710, total: 204928, Batch Accuracy: 72.08%\n",
      "Epoch [7/15], Batch [1701/2673], Loss: 2.1171, correct :157135, total: 217728, Batch Accuracy: 72.17%\n",
      "Epoch [7/15], Batch [1801/2673], Loss: 2.1135, correct :166464, total: 230528, Batch Accuracy: 72.21%\n",
      "Epoch [7/15], Batch [1901/2673], Loss: 2.1084, correct :175921, total: 243328, Batch Accuracy: 72.30%\n",
      "Epoch [7/15], Batch [2001/2673], Loss: 2.1026, correct :185363, total: 256128, Batch Accuracy: 72.37%\n",
      "Epoch [7/15], Batch [2101/2673], Loss: 2.0974, correct :194844, total: 268928, Batch Accuracy: 72.45%\n",
      "Epoch [7/15], Batch [2201/2673], Loss: 2.0936, correct :204318, total: 281728, Batch Accuracy: 72.52%\n",
      "Epoch [7/15], Batch [2301/2673], Loss: 2.0889, correct :213849, total: 294528, Batch Accuracy: 72.61%\n",
      "Epoch [7/15], Batch [2401/2673], Loss: 2.0829, correct :223385, total: 307328, Batch Accuracy: 72.69%\n",
      "Epoch [7/15], Batch [2501/2673], Loss: 2.0798, correct :232900, total: 320128, Batch Accuracy: 72.75%\n",
      "Epoch [7/15], Batch [2601/2673], Loss: 2.0763, correct :242452, total: 332928, Batch Accuracy: 72.82%\n",
      "Epoch [7/15], Validation Loss: 0.0000, Validation Accuracy: 64.44%\n",
      "Epoch [8/15], Batch [1/2673], Loss: 2.0850, correct :95, total: 128, Batch Accuracy: 74.22%\n",
      "Epoch [8/15], Batch [101/2673], Loss: 1.9213, correct :9770, total: 12928, Batch Accuracy: 75.57%\n",
      "Epoch [8/15], Batch [201/2673], Loss: 1.9441, correct :19303, total: 25728, Batch Accuracy: 75.03%\n",
      "Epoch [8/15], Batch [301/2673], Loss: 1.9462, correct :28924, total: 38528, Batch Accuracy: 75.07%\n",
      "Epoch [8/15], Batch [401/2673], Loss: 1.9445, correct :38485, total: 51328, Batch Accuracy: 74.98%\n",
      "Epoch [8/15], Batch [501/2673], Loss: 1.9444, correct :48084, total: 64128, Batch Accuracy: 74.98%\n",
      "Epoch [8/15], Batch [601/2673], Loss: 1.9392, correct :57772, total: 76928, Batch Accuracy: 75.10%\n",
      "Epoch [8/15], Batch [701/2673], Loss: 1.9371, correct :67384, total: 89728, Batch Accuracy: 75.10%\n",
      "Epoch [8/15], Batch [801/2673], Loss: 1.9337, correct :77095, total: 102528, Batch Accuracy: 75.19%\n",
      "Epoch [8/15], Batch [901/2673], Loss: 1.9311, correct :86789, total: 115328, Batch Accuracy: 75.25%\n",
      "Epoch [8/15], Batch [1001/2673], Loss: 1.9280, correct :96562, total: 128128, Batch Accuracy: 75.36%\n",
      "Epoch [8/15], Batch [1101/2673], Loss: 1.9227, correct :106293, total: 140928, Batch Accuracy: 75.42%\n",
      "Epoch [8/15], Batch [1201/2673], Loss: 1.9215, correct :116001, total: 153728, Batch Accuracy: 75.46%\n",
      "Epoch [8/15], Batch [1301/2673], Loss: 1.9205, correct :125688, total: 166528, Batch Accuracy: 75.48%\n",
      "Epoch [8/15], Batch [1401/2673], Loss: 1.9174, correct :135430, total: 179328, Batch Accuracy: 75.52%\n",
      "Epoch [8/15], Batch [1501/2673], Loss: 1.9144, correct :145158, total: 192128, Batch Accuracy: 75.55%\n",
      "Epoch [8/15], Batch [1601/2673], Loss: 1.9119, correct :154866, total: 204928, Batch Accuracy: 75.57%\n",
      "Epoch [8/15], Batch [1701/2673], Loss: 1.9069, correct :164748, total: 217728, Batch Accuracy: 75.67%\n",
      "Epoch [8/15], Batch [1801/2673], Loss: 1.9039, correct :174476, total: 230528, Batch Accuracy: 75.69%\n",
      "Epoch [8/15], Batch [1901/2673], Loss: 1.9001, correct :184287, total: 243328, Batch Accuracy: 75.74%\n",
      "Epoch [8/15], Batch [2001/2673], Loss: 1.8948, correct :194155, total: 256128, Batch Accuracy: 75.80%\n",
      "Epoch [8/15], Batch [2101/2673], Loss: 1.8903, correct :204008, total: 268928, Batch Accuracy: 75.86%\n",
      "Epoch [8/15], Batch [2201/2673], Loss: 1.8874, correct :213854, total: 281728, Batch Accuracy: 75.91%\n",
      "Epoch [8/15], Batch [2301/2673], Loss: 1.8831, correct :223772, total: 294528, Batch Accuracy: 75.98%\n",
      "Epoch [8/15], Batch [2401/2673], Loss: 1.8779, correct :233706, total: 307328, Batch Accuracy: 76.04%\n",
      "Epoch [8/15], Batch [2501/2673], Loss: 1.8752, correct :243636, total: 320128, Batch Accuracy: 76.11%\n",
      "Epoch [8/15], Batch [2601/2673], Loss: 1.8720, correct :253606, total: 332928, Batch Accuracy: 76.17%\n",
      "Epoch [8/15], Validation Loss: 0.0000, Validation Accuracy: 65.04%\n",
      "Epoch [9/15], Batch [1/2673], Loss: 1.8658, correct :97, total: 128, Batch Accuracy: 75.78%\n",
      "Epoch [9/15], Batch [101/2673], Loss: 1.7484, correct :10125, total: 12928, Batch Accuracy: 78.32%\n",
      "Epoch [9/15], Batch [201/2673], Loss: 1.7656, correct :20036, total: 25728, Batch Accuracy: 77.88%\n",
      "Epoch [9/15], Batch [301/2673], Loss: 1.7662, correct :29974, total: 38528, Batch Accuracy: 77.80%\n",
      "Epoch [9/15], Batch [401/2673], Loss: 1.7668, correct :39894, total: 51328, Batch Accuracy: 77.72%\n",
      "Epoch [9/15], Batch [501/2673], Loss: 1.7699, correct :49816, total: 64128, Batch Accuracy: 77.68%\n",
      "Epoch [9/15], Batch [601/2673], Loss: 1.7663, correct :59809, total: 76928, Batch Accuracy: 77.75%\n",
      "Epoch [9/15], Batch [701/2673], Loss: 1.7630, correct :69867, total: 89728, Batch Accuracy: 77.87%\n",
      "Epoch [9/15], Batch [801/2673], Loss: 1.7599, correct :79945, total: 102528, Batch Accuracy: 77.97%\n",
      "Epoch [9/15], Batch [901/2673], Loss: 1.7559, correct :90061, total: 115328, Batch Accuracy: 78.09%\n",
      "Epoch [9/15], Batch [1001/2673], Loss: 1.7553, correct :100116, total: 128128, Batch Accuracy: 78.14%\n",
      "Epoch [9/15], Batch [1101/2673], Loss: 1.7510, correct :110189, total: 140928, Batch Accuracy: 78.19%\n",
      "Epoch [9/15], Batch [1201/2673], Loss: 1.7490, correct :120242, total: 153728, Batch Accuracy: 78.22%\n",
      "Epoch [9/15], Batch [1301/2673], Loss: 1.7472, correct :130314, total: 166528, Batch Accuracy: 78.25%\n",
      "Epoch [9/15], Batch [1401/2673], Loss: 1.7449, correct :140351, total: 179328, Batch Accuracy: 78.26%\n",
      "Epoch [9/15], Batch [1501/2673], Loss: 1.7417, correct :150464, total: 192128, Batch Accuracy: 78.31%\n",
      "Epoch [9/15], Batch [1601/2673], Loss: 1.7398, correct :160525, total: 204928, Batch Accuracy: 78.33%\n",
      "Epoch [9/15], Batch [1701/2673], Loss: 1.7361, correct :170621, total: 217728, Batch Accuracy: 78.36%\n",
      "Epoch [9/15], Batch [1801/2673], Loss: 1.7339, correct :180712, total: 230528, Batch Accuracy: 78.39%\n",
      "Epoch [9/15], Batch [1901/2673], Loss: 1.7311, correct :190828, total: 243328, Batch Accuracy: 78.42%\n",
      "Epoch [9/15], Batch [2001/2673], Loss: 1.7265, correct :201035, total: 256128, Batch Accuracy: 78.49%\n",
      "Epoch [9/15], Batch [2101/2673], Loss: 1.7226, correct :211222, total: 268928, Batch Accuracy: 78.54%\n",
      "Epoch [9/15], Batch [2201/2673], Loss: 1.7201, correct :221428, total: 281728, Batch Accuracy: 78.60%\n",
      "Epoch [9/15], Batch [2301/2673], Loss: 1.7165, correct :231641, total: 294528, Batch Accuracy: 78.65%\n",
      "Epoch [9/15], Batch [2401/2673], Loss: 1.7120, correct :241886, total: 307328, Batch Accuracy: 78.71%\n",
      "Epoch [9/15], Batch [2501/2673], Loss: 1.7094, correct :252146, total: 320128, Batch Accuracy: 78.76%\n",
      "Epoch [9/15], Batch [2601/2673], Loss: 1.7071, correct :262377, total: 332928, Batch Accuracy: 78.81%\n",
      "Epoch [9/15], Validation Loss: 0.0000, Validation Accuracy: 67.59%\n",
      "Epoch [10/15], Batch [1/2673], Loss: 1.6870, correct :101, total: 128, Batch Accuracy: 78.91%\n",
      "Epoch [10/15], Batch [101/2673], Loss: 1.5928, correct :10418, total: 12928, Batch Accuracy: 80.58%\n",
      "Epoch [10/15], Batch [201/2673], Loss: 1.6097, correct :20662, total: 25728, Batch Accuracy: 80.31%\n",
      "Epoch [10/15], Batch [301/2673], Loss: 1.6165, correct :30881, total: 38528, Batch Accuracy: 80.15%\n",
      "Epoch [10/15], Batch [401/2673], Loss: 1.6135, correct :41137, total: 51328, Batch Accuracy: 80.15%\n",
      "Epoch [10/15], Batch [501/2673], Loss: 1.6164, correct :51368, total: 64128, Batch Accuracy: 80.10%\n",
      "Epoch [10/15], Batch [601/2673], Loss: 1.6159, correct :61657, total: 76928, Batch Accuracy: 80.15%\n",
      "Epoch [10/15], Batch [701/2673], Loss: 1.6136, correct :71963, total: 89728, Batch Accuracy: 80.20%\n",
      "Epoch [10/15], Batch [801/2673], Loss: 1.6121, correct :82270, total: 102528, Batch Accuracy: 80.24%\n",
      "Epoch [10/15], Batch [901/2673], Loss: 1.6096, correct :92637, total: 115328, Batch Accuracy: 80.32%\n",
      "Epoch [10/15], Batch [1001/2673], Loss: 1.6082, correct :102950, total: 128128, Batch Accuracy: 80.35%\n",
      "Epoch [10/15], Batch [1101/2673], Loss: 1.6038, correct :113350, total: 140928, Batch Accuracy: 80.43%\n",
      "Epoch [10/15], Batch [1201/2673], Loss: 1.6022, correct :123671, total: 153728, Batch Accuracy: 80.45%\n",
      "Epoch [10/15], Batch [1301/2673], Loss: 1.6017, correct :134007, total: 166528, Batch Accuracy: 80.47%\n",
      "Epoch [10/15], Batch [1401/2673], Loss: 1.5994, correct :144358, total: 179328, Batch Accuracy: 80.50%\n",
      "Epoch [10/15], Batch [1501/2673], Loss: 1.5968, correct :154758, total: 192128, Batch Accuracy: 80.55%\n",
      "Epoch [10/15], Batch [1601/2673], Loss: 1.5947, correct :165104, total: 204928, Batch Accuracy: 80.57%\n",
      "Epoch [10/15], Batch [1701/2673], Loss: 1.5911, correct :175556, total: 217728, Batch Accuracy: 80.63%\n",
      "Epoch [10/15], Batch [1801/2673], Loss: 1.5890, correct :185919, total: 230528, Batch Accuracy: 80.65%\n",
      "Epoch [10/15], Batch [1901/2673], Loss: 1.5873, correct :196286, total: 243328, Batch Accuracy: 80.67%\n",
      "Epoch [10/15], Batch [2001/2673], Loss: 1.5833, correct :206765, total: 256128, Batch Accuracy: 80.73%\n",
      "Epoch [10/15], Batch [2101/2673], Loss: 1.5804, correct :217228, total: 268928, Batch Accuracy: 80.78%\n",
      "Epoch [10/15], Batch [2201/2673], Loss: 1.5784, correct :227682, total: 281728, Batch Accuracy: 80.82%\n",
      "Epoch [10/15], Batch [2301/2673], Loss: 1.5752, correct :238191, total: 294528, Batch Accuracy: 80.87%\n",
      "Epoch [10/15], Batch [2401/2673], Loss: 1.5710, correct :248699, total: 307328, Batch Accuracy: 80.92%\n",
      "Epoch [10/15], Batch [2501/2673], Loss: 1.5692, correct :259203, total: 320128, Batch Accuracy: 80.97%\n",
      "Epoch [10/15], Batch [2601/2673], Loss: 1.5667, correct :269754, total: 332928, Batch Accuracy: 81.02%\n",
      "Epoch [10/15], Validation Loss: 0.0000, Validation Accuracy: 67.75%\n",
      "Epoch [11/15], Batch [1/2673], Loss: 1.5611, correct :107, total: 128, Batch Accuracy: 83.59%\n",
      "Epoch [11/15], Batch [101/2673], Loss: 1.4657, correct :10674, total: 12928, Batch Accuracy: 82.56%\n",
      "Epoch [11/15], Batch [201/2673], Loss: 1.4808, correct :21186, total: 25728, Batch Accuracy: 82.35%\n",
      "Epoch [11/15], Batch [301/2673], Loss: 1.4831, correct :31767, total: 38528, Batch Accuracy: 82.45%\n",
      "Epoch [11/15], Batch [401/2673], Loss: 1.4864, correct :42225, total: 51328, Batch Accuracy: 82.27%\n",
      "Epoch [11/15], Batch [501/2673], Loss: 1.4894, correct :52741, total: 64128, Batch Accuracy: 82.24%\n",
      "Epoch [11/15], Batch [601/2673], Loss: 1.4870, correct :63287, total: 76928, Batch Accuracy: 82.27%\n",
      "Epoch [11/15], Batch [701/2673], Loss: 1.4861, correct :73837, total: 89728, Batch Accuracy: 82.29%\n",
      "Epoch [11/15], Batch [801/2673], Loss: 1.4848, correct :84373, total: 102528, Batch Accuracy: 82.29%\n",
      "Epoch [11/15], Batch [901/2673], Loss: 1.4821, correct :95022, total: 115328, Batch Accuracy: 82.39%\n",
      "Epoch [11/15], Batch [1001/2673], Loss: 1.4823, correct :105568, total: 128128, Batch Accuracy: 82.39%\n",
      "Epoch [11/15], Batch [1101/2673], Loss: 1.4789, correct :116221, total: 140928, Batch Accuracy: 82.47%\n",
      "Epoch [11/15], Batch [1201/2673], Loss: 1.4776, correct :126785, total: 153728, Batch Accuracy: 82.47%\n",
      "Epoch [11/15], Batch [1301/2673], Loss: 1.4766, correct :137353, total: 166528, Batch Accuracy: 82.48%\n",
      "Epoch [11/15], Batch [1401/2673], Loss: 1.4745, correct :148005, total: 179328, Batch Accuracy: 82.53%\n",
      "Epoch [11/15], Batch [1501/2673], Loss: 1.4716, correct :158646, total: 192128, Batch Accuracy: 82.57%\n",
      "Epoch [11/15], Batch [1601/2673], Loss: 1.4702, correct :169257, total: 204928, Batch Accuracy: 82.59%\n",
      "Epoch [11/15], Batch [1701/2673], Loss: 1.4672, correct :179874, total: 217728, Batch Accuracy: 82.61%\n",
      "Epoch [11/15], Batch [1801/2673], Loss: 1.4652, correct :190517, total: 230528, Batch Accuracy: 82.64%\n",
      "Epoch [11/15], Batch [1901/2673], Loss: 1.4628, correct :201198, total: 243328, Batch Accuracy: 82.69%\n",
      "Epoch [11/15], Batch [2001/2673], Loss: 1.4589, correct :211914, total: 256128, Batch Accuracy: 82.74%\n",
      "Epoch [11/15], Batch [2101/2673], Loss: 1.4563, correct :222596, total: 268928, Batch Accuracy: 82.77%\n",
      "Epoch [11/15], Batch [2201/2673], Loss: 1.4549, correct :233246, total: 281728, Batch Accuracy: 82.79%\n",
      "Epoch [11/15], Batch [2301/2673], Loss: 1.4522, correct :243985, total: 294528, Batch Accuracy: 82.84%\n",
      "Epoch [11/15], Batch [2401/2673], Loss: 1.4480, correct :254733, total: 307328, Batch Accuracy: 82.89%\n",
      "Epoch [11/15], Batch [2501/2673], Loss: 1.4463, correct :265468, total: 320128, Batch Accuracy: 82.93%\n",
      "Epoch [11/15], Batch [2601/2673], Loss: 1.4444, correct :276215, total: 332928, Batch Accuracy: 82.97%\n",
      "Epoch [11/15], Validation Loss: 0.0000, Validation Accuracy: 69.29%\n",
      "Epoch [12/15], Batch [1/2673], Loss: 1.4229, correct :110, total: 128, Batch Accuracy: 85.94%\n",
      "Epoch [12/15], Batch [101/2673], Loss: 1.3661, correct :10891, total: 12928, Batch Accuracy: 84.24%\n",
      "Epoch [12/15], Batch [201/2673], Loss: 1.3845, correct :21543, total: 25728, Batch Accuracy: 83.73%\n",
      "Epoch [12/15], Batch [301/2673], Loss: 1.3809, correct :32322, total: 38528, Batch Accuracy: 83.89%\n",
      "Epoch [12/15], Batch [401/2673], Loss: 1.3825, correct :43059, total: 51328, Batch Accuracy: 83.89%\n",
      "Epoch [12/15], Batch [501/2673], Loss: 1.3831, correct :53798, total: 64128, Batch Accuracy: 83.89%\n",
      "Epoch [12/15], Batch [601/2673], Loss: 1.3807, correct :64571, total: 76928, Batch Accuracy: 83.94%\n",
      "Epoch [12/15], Batch [701/2673], Loss: 1.3790, correct :75339, total: 89728, Batch Accuracy: 83.96%\n",
      "Epoch [12/15], Batch [801/2673], Loss: 1.3780, correct :86104, total: 102528, Batch Accuracy: 83.98%\n",
      "Epoch [12/15], Batch [901/2673], Loss: 1.3748, correct :96921, total: 115328, Batch Accuracy: 84.04%\n",
      "Epoch [12/15], Batch [1001/2673], Loss: 1.3751, correct :107677, total: 128128, Batch Accuracy: 84.04%\n",
      "Epoch [12/15], Batch [1101/2673], Loss: 1.3713, correct :118558, total: 140928, Batch Accuracy: 84.13%\n",
      "Epoch [12/15], Batch [1201/2673], Loss: 1.3707, correct :129369, total: 153728, Batch Accuracy: 84.15%\n",
      "Epoch [12/15], Batch [1301/2673], Loss: 1.3690, correct :140211, total: 166528, Batch Accuracy: 84.20%\n",
      "Epoch [12/15], Batch [1401/2673], Loss: 1.3664, correct :151037, total: 179328, Batch Accuracy: 84.22%\n",
      "Epoch [12/15], Batch [1501/2673], Loss: 1.3648, correct :161888, total: 192128, Batch Accuracy: 84.26%\n",
      "Epoch [12/15], Batch [1601/2673], Loss: 1.3628, correct :172715, total: 204928, Batch Accuracy: 84.28%\n",
      "Epoch [12/15], Batch [1701/2673], Loss: 1.3592, correct :183613, total: 217728, Batch Accuracy: 84.33%\n",
      "Epoch [12/15], Batch [1801/2673], Loss: 1.3578, correct :194432, total: 230528, Batch Accuracy: 84.34%\n",
      "Epoch [12/15], Batch [1901/2673], Loss: 1.3564, correct :205284, total: 243328, Batch Accuracy: 84.37%\n",
      "Epoch [12/15], Batch [2001/2673], Loss: 1.3528, correct :216203, total: 256128, Batch Accuracy: 84.41%\n",
      "Epoch [12/15], Batch [2101/2673], Loss: 1.3507, correct :227087, total: 268928, Batch Accuracy: 84.44%\n",
      "Epoch [12/15], Batch [2201/2673], Loss: 1.3492, correct :238004, total: 281728, Batch Accuracy: 84.48%\n",
      "Epoch [12/15], Batch [2301/2673], Loss: 1.3474, correct :248864, total: 294528, Batch Accuracy: 84.50%\n",
      "Epoch [12/15], Batch [2401/2673], Loss: 1.3436, correct :259828, total: 307328, Batch Accuracy: 84.54%\n",
      "Epoch [12/15], Batch [2501/2673], Loss: 1.3425, correct :270714, total: 320128, Batch Accuracy: 84.56%\n",
      "Epoch [12/15], Batch [2601/2673], Loss: 1.3408, correct :281617, total: 332928, Batch Accuracy: 84.59%\n",
      "Epoch [12/15], Validation Loss: 0.0000, Validation Accuracy: 69.62%\n",
      "Epoch [13/15], Batch [1/2673], Loss: 1.4133, correct :110, total: 128, Batch Accuracy: 85.94%\n",
      "Epoch [13/15], Batch [101/2673], Loss: 1.2803, correct :11042, total: 12928, Batch Accuracy: 85.41%\n",
      "Epoch [13/15], Batch [201/2673], Loss: 1.2852, correct :21940, total: 25728, Batch Accuracy: 85.28%\n",
      "Epoch [13/15], Batch [301/2673], Loss: 1.2864, correct :32835, total: 38528, Batch Accuracy: 85.22%\n",
      "Epoch [13/15], Batch [401/2673], Loss: 1.2858, correct :43744, total: 51328, Batch Accuracy: 85.22%\n",
      "Epoch [13/15], Batch [501/2673], Loss: 1.2885, correct :54614, total: 64128, Batch Accuracy: 85.16%\n",
      "Epoch [13/15], Batch [601/2673], Loss: 1.2849, correct :65553, total: 76928, Batch Accuracy: 85.21%\n",
      "Epoch [13/15], Batch [701/2673], Loss: 1.2831, correct :76486, total: 89728, Batch Accuracy: 85.24%\n",
      "Epoch [13/15], Batch [801/2673], Loss: 1.2834, correct :87416, total: 102528, Batch Accuracy: 85.26%\n",
      "Epoch [13/15], Batch [901/2673], Loss: 1.2801, correct :98411, total: 115328, Batch Accuracy: 85.33%\n",
      "Epoch [13/15], Batch [1001/2673], Loss: 1.2796, correct :109406, total: 128128, Batch Accuracy: 85.39%\n",
      "Epoch [13/15], Batch [1101/2673], Loss: 1.2767, correct :120406, total: 140928, Batch Accuracy: 85.44%\n",
      "Epoch [13/15], Batch [1201/2673], Loss: 1.2753, correct :131432, total: 153728, Batch Accuracy: 85.50%\n",
      "Epoch [13/15], Batch [1301/2673], Loss: 1.2742, correct :142414, total: 166528, Batch Accuracy: 85.52%\n",
      "Epoch [13/15], Batch [1401/2673], Loss: 1.2723, correct :153438, total: 179328, Batch Accuracy: 85.56%\n",
      "Epoch [13/15], Batch [1501/2673], Loss: 1.2705, correct :164450, total: 192128, Batch Accuracy: 85.59%\n",
      "Epoch [13/15], Batch [1601/2673], Loss: 1.2694, correct :175435, total: 204928, Batch Accuracy: 85.61%\n",
      "Epoch [13/15], Batch [1701/2673], Loss: 1.2665, correct :186527, total: 217728, Batch Accuracy: 85.67%\n",
      "Epoch [13/15], Batch [1801/2673], Loss: 1.2646, correct :197562, total: 230528, Batch Accuracy: 85.70%\n",
      "Epoch [13/15], Batch [1901/2673], Loss: 1.2633, correct :208579, total: 243328, Batch Accuracy: 85.72%\n",
      "Epoch [13/15], Batch [2001/2673], Loss: 1.2602, correct :219648, total: 256128, Batch Accuracy: 85.76%\n",
      "Epoch [13/15], Batch [2101/2673], Loss: 1.2583, correct :230734, total: 268928, Batch Accuracy: 85.80%\n",
      "Epoch [13/15], Batch [2201/2673], Loss: 1.2570, correct :241800, total: 281728, Batch Accuracy: 85.83%\n",
      "Epoch [13/15], Batch [2301/2673], Loss: 1.2545, correct :252871, total: 294528, Batch Accuracy: 85.86%\n",
      "Epoch [13/15], Batch [2401/2673], Loss: 1.2505, correct :264071, total: 307328, Batch Accuracy: 85.92%\n",
      "Epoch [13/15], Batch [2501/2673], Loss: 1.2490, correct :275174, total: 320128, Batch Accuracy: 85.96%\n",
      "Epoch [13/15], Batch [2601/2673], Loss: 1.2475, correct :286299, total: 332928, Batch Accuracy: 85.99%\n",
      "Epoch [13/15], Validation Loss: 0.0000, Validation Accuracy: 69.71%\n",
      "Epoch [14/15], Batch [1/2673], Loss: 1.2722, correct :110, total: 128, Batch Accuracy: 85.94%\n",
      "Epoch [14/15], Batch [101/2673], Loss: 1.1886, correct :11263, total: 12928, Batch Accuracy: 87.12%\n",
      "Epoch [14/15], Batch [201/2673], Loss: 1.1982, correct :22360, total: 25728, Batch Accuracy: 86.91%\n",
      "Epoch [14/15], Batch [301/2673], Loss: 1.1975, correct :33480, total: 38528, Batch Accuracy: 86.90%\n",
      "Epoch [14/15], Batch [401/2673], Loss: 1.1970, correct :44601, total: 51328, Batch Accuracy: 86.89%\n",
      "Epoch [14/15], Batch [501/2673], Loss: 1.1976, correct :55724, total: 64128, Batch Accuracy: 86.89%\n",
      "Epoch [14/15], Batch [601/2673], Loss: 1.1947, correct :66870, total: 76928, Batch Accuracy: 86.93%\n",
      "Epoch [14/15], Batch [701/2673], Loss: 1.1923, correct :77984, total: 89728, Batch Accuracy: 86.91%\n",
      "Epoch [14/15], Batch [801/2673], Loss: 1.1925, correct :89108, total: 102528, Batch Accuracy: 86.91%\n",
      "Epoch [14/15], Batch [901/2673], Loss: 1.1907, correct :100262, total: 115328, Batch Accuracy: 86.94%\n",
      "Epoch [14/15], Batch [1001/2673], Loss: 1.1915, correct :111435, total: 128128, Batch Accuracy: 86.97%\n",
      "Epoch [14/15], Batch [1101/2673], Loss: 1.1890, correct :122655, total: 140928, Batch Accuracy: 87.03%\n",
      "Epoch [14/15], Batch [1201/2673], Loss: 1.1885, correct :133800, total: 153728, Batch Accuracy: 87.04%\n",
      "Epoch [14/15], Batch [1301/2673], Loss: 1.1872, correct :144988, total: 166528, Batch Accuracy: 87.07%\n",
      "Epoch [14/15], Batch [1401/2673], Loss: 1.1851, correct :156179, total: 179328, Batch Accuracy: 87.09%\n",
      "Epoch [14/15], Batch [1501/2673], Loss: 1.1839, correct :167373, total: 192128, Batch Accuracy: 87.12%\n",
      "Epoch [14/15], Batch [1601/2673], Loss: 1.1825, correct :178563, total: 204928, Batch Accuracy: 87.13%\n",
      "Epoch [14/15], Batch [1701/2673], Loss: 1.1806, correct :189747, total: 217728, Batch Accuracy: 87.15%\n",
      "Epoch [14/15], Batch [1801/2673], Loss: 1.1791, correct :200905, total: 230528, Batch Accuracy: 87.15%\n",
      "Epoch [14/15], Batch [1901/2673], Loss: 1.1778, correct :212121, total: 243328, Batch Accuracy: 87.17%\n",
      "Epoch [14/15], Batch [2001/2673], Loss: 1.1749, correct :223373, total: 256128, Batch Accuracy: 87.21%\n",
      "Epoch [14/15], Batch [2101/2673], Loss: 1.1736, correct :234563, total: 268928, Batch Accuracy: 87.22%\n",
      "Epoch [14/15], Batch [2201/2673], Loss: 1.1723, correct :245789, total: 281728, Batch Accuracy: 87.24%\n",
      "Epoch [14/15], Batch [2301/2673], Loss: 1.1703, correct :257032, total: 294528, Batch Accuracy: 87.27%\n",
      "Epoch [14/15], Batch [2401/2673], Loss: 1.1668, correct :268339, total: 307328, Batch Accuracy: 87.31%\n",
      "Epoch [14/15], Batch [2501/2673], Loss: 1.1659, correct :279560, total: 320128, Batch Accuracy: 87.33%\n",
      "Epoch [14/15], Batch [2601/2673], Loss: 1.1648, correct :290764, total: 332928, Batch Accuracy: 87.34%\n",
      "Epoch [14/15], Validation Loss: 0.0000, Validation Accuracy: 71.19%\n",
      "Epoch [15/15], Batch [1/2673], Loss: 1.1020, correct :112, total: 128, Batch Accuracy: 87.50%\n",
      "Epoch [15/15], Batch [101/2673], Loss: 1.1064, correct :11449, total: 12928, Batch Accuracy: 88.56%\n",
      "Epoch [15/15], Batch [201/2673], Loss: 1.1151, correct :22690, total: 25728, Batch Accuracy: 88.19%\n",
      "Epoch [15/15], Batch [301/2673], Loss: 1.1175, correct :33970, total: 38528, Batch Accuracy: 88.17%\n",
      "Epoch [15/15], Batch [401/2673], Loss: 1.1152, correct :45267, total: 51328, Batch Accuracy: 88.19%\n",
      "Epoch [15/15], Batch [501/2673], Loss: 1.1164, correct :56476, total: 64128, Batch Accuracy: 88.07%\n",
      "Epoch [15/15], Batch [601/2673], Loss: 1.1155, correct :67742, total: 76928, Batch Accuracy: 88.06%\n",
      "Epoch [15/15], Batch [701/2673], Loss: 1.1143, correct :79013, total: 89728, Batch Accuracy: 88.06%\n",
      "Epoch [15/15], Batch [801/2673], Loss: 1.1135, correct :90295, total: 102528, Batch Accuracy: 88.07%\n",
      "Epoch [15/15], Batch [901/2673], Loss: 1.1123, correct :101592, total: 115328, Batch Accuracy: 88.09%\n",
      "Epoch [15/15], Batch [1001/2673], Loss: 1.1150, correct :112817, total: 128128, Batch Accuracy: 88.05%\n",
      "Epoch [15/15], Batch [1101/2673], Loss: 1.1135, correct :124143, total: 140928, Batch Accuracy: 88.09%\n",
      "Epoch [15/15], Batch [1201/2673], Loss: 1.1139, correct :135414, total: 153728, Batch Accuracy: 88.09%\n",
      "Epoch [15/15], Batch [1301/2673], Loss: 1.1132, correct :146742, total: 166528, Batch Accuracy: 88.12%\n",
      "Epoch [15/15], Batch [1401/2673], Loss: 1.1107, correct :158123, total: 179328, Batch Accuracy: 88.18%\n",
      "Epoch [15/15], Batch [1501/2673], Loss: 1.1090, correct :169448, total: 192128, Batch Accuracy: 88.20%\n",
      "Epoch [15/15], Batch [1601/2673], Loss: 1.1074, correct :180823, total: 204928, Batch Accuracy: 88.24%\n",
      "Epoch [15/15], Batch [1701/2673], Loss: 1.1052, correct :192192, total: 217728, Batch Accuracy: 88.27%\n",
      "Epoch [15/15], Batch [1801/2673], Loss: 1.1040, correct :203512, total: 230528, Batch Accuracy: 88.28%\n",
      "Epoch [15/15], Batch [1901/2673], Loss: 1.1035, correct :214828, total: 243328, Batch Accuracy: 88.29%\n",
      "Epoch [15/15], Batch [2001/2673], Loss: 1.1013, correct :226209, total: 256128, Batch Accuracy: 88.32%\n",
      "Epoch [15/15], Batch [2101/2673], Loss: 1.1002, correct :237539, total: 268928, Batch Accuracy: 88.33%\n",
      "Epoch [15/15], Batch [2201/2673], Loss: 1.0989, correct :248911, total: 281728, Batch Accuracy: 88.35%\n",
      "Epoch [15/15], Batch [2301/2673], Loss: 1.0970, correct :260323, total: 294528, Batch Accuracy: 88.39%\n",
      "Epoch [15/15], Batch [2401/2673], Loss: 1.0936, correct :271805, total: 307328, Batch Accuracy: 88.44%\n",
      "Epoch [15/15], Batch [2501/2673], Loss: 1.0921, correct :283177, total: 320128, Batch Accuracy: 88.46%\n",
      "Epoch [15/15], Batch [2601/2673], Loss: 1.0907, correct :294596, total: 332928, Batch Accuracy: 88.49%\n",
      "Epoch [15/15], Validation Loss: 0.0000, Validation Accuracy: 71.19%\n",
      "2024-03-22 09:55:40\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "formatted_time = datetime.datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define the temperature parameter for knowledge distillation\n",
    "temperature = 4.0  # You can adjust this value based on your needs\n",
    "# Define the loss function and optimizer for training the student model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "\n",
    "    #define running loss\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass for the teacher model (assuming it's already trained)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = teacher_model(inputs)\n",
    "\n",
    "        # Forward pass for the student model\n",
    "        optimizer_student.zero_grad()\n",
    "        outputs_student = student_model(inputs)\n",
    "\n",
    "        #Calculates the knowledge distillation loss using the Kullback-Leibler (KL) Divergence loss.It measures the difference between two probability distributions. In this case, it calculates the KL Divergence between the log-softmax predictions of the student model and the softmax predictions of the teacher model.\n",
    "\n",
    "        loss_distillation = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs_student / temperature, dim=1), #This part computes the logarithm of the softmax function applied to the output predictions of the student model divided by the temperature. The temperature is a hyperparameter that controls the smoothness of the probability distribution.\n",
    "                                           F.softmax(outputs_teacher / temperature, dim=1)) #Similarly, this part computes the softmax function applied to the output predictions of the teacher model divided by the temperature.\n",
    "\n",
    "        # Calculate the classification loss\n",
    "        loss_classification = criterion(outputs_student, labels)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_classification + loss_distillation\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs_student.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "        # Print batch statistics\n",
    "        if batch_idx % 100 == 0:  # Adjust the interval for printing\n",
    "            batch_accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / (batch_idx + 1):.4f}, correct :{correct}, total: {total}, Batch Accuracy: {batch_accuracy:.2f}%')\n",
    "\n",
    "    # Validation phase\n",
    "    student_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for val_batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "            # Forward pass for the teacher model\n",
    "            with torch.no_grad():\n",
    "                val_outputs_teacher = teacher_model(val_inputs)\n",
    "\n",
    "            # Forward pass for the student model\n",
    "            val_outputs_student = student_model(val_inputs)\n",
    "\n",
    "            _, val_predicted = val_outputs_student.max(1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += val_predicted.eq(val_labels).sum().item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Print validation statistics\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, '\n",
    "            f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'student_model_state_dict': student_model.state_dict(),\n",
    "        'optimizer_student_state_dict': optimizer_student.state_dict(),\n",
    "        'val_accuracy': val_accuracy,\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_kd_v2_{epoch}.pt')\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "formatted_time = datetime.datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(formatted_time)\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "with open(\"execution_time_kd_v2.txt\", \"w\") as file:\n",
    "    file.write(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model, 'KD_full_mobiFace_like_v2_4.pth') \n",
    "torch.save(student_model.state_dict(), 'KD_dict_mobiFace_live_v2_4.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
