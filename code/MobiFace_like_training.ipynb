{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, also set the seed for GPU\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # sets device for model and PyTorch tensors\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobiFace(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bottleneck_block1): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block1): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block2): BottleneckBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block2): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (bottleneck_block3): BottleneckBlock(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (residual_block3): InvertedResidualBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): PReLU(num_parameters=1)\n",
      "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
      "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (relu): PReLU(num_parameters=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DepthwiseSeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseSeparableConv2d, self).__init__()\n",
    "\n",
    "        # Depthwise convolution - The number of groups is equivalent to the number of channels which makes the convolution be performed to each channel independently.\n",
    "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=False)\n",
    "\n",
    "        # Pointwise convolution = i used a 1x1 kernel to combine  information accross channels and project the features to a new space.It transforms teh number of channesl from in_channel to out_channels \n",
    "        self.pointwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        #Input Channels: The number of input channels (in_channels) corresponds to the depth or the number of features at each spatial location.\n",
    "        #Output Channels: The number of output channels (out_channels) corresponds to the number of filters or features that the convolutional layer is going to produce.\n",
    "        # pointwise convolution (1x1) performs a linear combination of input channels at each spatial location, resulting in an output with a new set of channels. The weights for this linear combination are learned during the training process, providing the model with the flexibility to capture different relationships and patterns across channels\n",
    "\n",
    "\n",
    "        #Normalizes the output of the pointwise convolution. Batch normalization helps stabilize and accelerate the training process by normalizing the activations\n",
    "        self.bn = nn.BatchNorm2d(out_channels) #self.bn = nn.BatchNorm2d(out_channels)\n",
    "        #choice of applying the BatchNorm2d fter the pointwise conv and before the PReLu to stabilize te inputs of the activation function\n",
    "\n",
    "        #Applies the PReLU activation function to the batch-normalized output. PReLU introduces learnable parameters to the standard ReLU activation.\n",
    "        self.relu = nn.PReLU()\n",
    "        #PReLU introduces a learnable parameter, allowing the slope of the negative part of the activation to be adjusted during training.\n",
    "        #mathematically is it equivalento to:\n",
    "        #PReLU(x) -> x;x>=0\n",
    "        #PReLU(x) -> alpha . x;x<0\n",
    "\n",
    "    #defines the forward pass of the network, specifying how the input data is transformed through the layers of the network to produce the final output\n",
    "    def forward(self, x):\n",
    "        #Applies depthwise separable convolution operation, which consists of depthwise convolution, pointwise convolution, batch normalization, and activation. \n",
    "        out = self.relu(self.bn(self.pointwise_conv(self.depthwise_conv(x))))\n",
    "        return out\n",
    "\n",
    "#see InvertedResidualBlock , essentially the same explanations but without the connection to output\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion, stride=1):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        expanded_channels = in_channels * expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels //2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels //2)\n",
    "        self.relu = nn.PReLU()\n",
    "\n",
    "        #depthwise conv\n",
    "        self.depthwise_conv = DepthwiseSeparableConv2d(in_channels //2, in_channels //2, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels //2)\n",
    "\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels //2, expanded_channels , kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(expanded_channels )\n",
    "        \n",
    "\n",
    "        # Remove the shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.depthwise_conv(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    " \n",
    "        return out\n",
    "\n",
    " \n",
    "\n",
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion,stride=1):\n",
    "        #is calling the constructor of the parent class nn.Module \n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "\n",
    "        \n",
    "        ###### Bloque de Expansion: narrow to wide\n",
    "        # 1x1 convolution is applied to the input tensor, changing the number of channels.The key role of the 1x1 convolution with expansion is to change the number of channels. \n",
    "        # this convolution is used to expand the low-dimensional input feature map to a higher-dimensional space suited to non-linear activations\n",
    "        expanded_channels = in_channels * expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, expanded_channels, kernel_size=1, bias=False)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(expanded_channels)\n",
    "        #MobiFace uses PReLU for non linearity\n",
    "        #PReLU introduces a learnable parameter, allowing the slope of the negative part of the activation to be adjusted during training.\n",
    "        #mathematically is it equivalent to:\n",
    "        #PReLU(x) -> x;x>=0\n",
    "        #PReLU(x) -> alpha . x;x<0\n",
    "        self.relu = nn.PReLU()\n",
    "\n",
    "        ####### Wide to wide\n",
    "        #A depthwise separable convolution is applied to the result of the previous step to achieve spatial filtering of hight dimensional tensor\n",
    "        self.depthwise_conv = DepthwiseSeparableConv2d(expanded_channels, expanded_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(expanded_channels)\n",
    "\n",
    "\n",
    "        ###### wide to narrow\n",
    "        #pointwise convolution linear convolution\n",
    "        #spatially-filtered feature map is projected back to a low-dimensional subspace\n",
    "        self.conv3 = nn.Conv2d(expanded_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "\n",
    "        #he shortcut connection is a form of a residual connection/skip connection\n",
    "        #Its purpose is to enable the smooth flow of gradients during backpropagation, aiding in the training of deep networks.\n",
    "        #The shortcut helps mitigate potential vanishing or exploding gradient problems by providing a direct path for information flow.\n",
    "        #shortcut is a sequential module that represents a shortcut connection.It is designed to connect the input directly to the output of the block, bypassing the internal transformations, if certain conditions are met.\n",
    "        self.shortcut = nn.Sequential()\n",
    "        #checks whether the number of input channels is not equal to the number of output channels after expansion. If this condition is true, it implies that there is a change in the number of channels, and a shortcut connection is needed to match dimensions.\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            print('shortcut')\n",
    "            self.shortcut = nn.Sequential(\n",
    "                #If the condition is met, a shortcut connection is created using a 1x1 convolution followed by batch normalization.The 1x1 convolution adjusts the number of channels, ensuring compatibility for element-wise addition with the output of the block.\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels ),\n",
    "                \n",
    "            )\n",
    "\n",
    "    #defines the forward pass of the network, specifying how the input data is transformed through the layers of the network to produce the final outpu\n",
    "    def forward(self, x):\n",
    "        #expansion\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        #depthwise conv\n",
    "        out = self.relu(self.bn2(self.depthwise_conv(out)))\n",
    "\n",
    "        #linear activation\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "\n",
    "        # Shortcut Connection -  the shortcut is applied during the forward pass - it is adding the original input tensor x to output tensor\n",
    "        # effectively acting as a residual connection, helping to create a shortcut path for information flow and facilitating gradient propagation during backpropagation.\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "class MobiFace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobiFace, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.depthwise_conv = DepthwiseSeparableConv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Bottleneck blocks followed by nverted Residual bottleneck blocks\n",
    "        self.bottleneck_block1 = BottleneckBlock(64, 64, expansion=1, stride=2)\n",
    "        self.residual_block1 = InvertedResidualBlock(64, 64, expansion=2)\n",
    "        \n",
    "        self.bottleneck_block2 = BottleneckBlock(64, 128, expansion=2, stride=2)\n",
    "        self.residual_block2 = InvertedResidualBlock(128, 128, expansion=2)\n",
    "        \n",
    "        self.bottleneck_block3 = BottleneckBlock(128, 256, expansion=2, stride=2)\n",
    "        self.residual_block3 = InvertedResidualBlock(256, 256, expansion=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "        self.fc = nn.Linear(512,512)\n",
    "        self.relu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #some print statements were added in case of checking the input shape transformation accross the network \n",
    "        \n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "\n",
    "        out = self.relu(self.bn2(self.depthwise_conv(out)))\n",
    "        \n",
    "        \n",
    "        # First bottleneck block followed by residual block\n",
    "        out = self.bottleneck_block1(out)\n",
    "        \n",
    "        out = self.residual_block1(out)\n",
    "        \n",
    "        \n",
    "        # Second bottleneck block followed by residual block\n",
    "        out = self.bottleneck_block2(out)\n",
    "        \n",
    "        out = self.residual_block2(out)\n",
    "        \n",
    "\n",
    "        # Third bottleneck block followed by residual block\n",
    "        out = self.bottleneck_block3(out)\n",
    "        \n",
    "        out = self.residual_block3(out)\n",
    "        \n",
    "        \n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = torch.mean(out, dim=[2, 3])  # Global Average Pooling\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Create an instance of the MobiFace model\n",
    "model = MobiFace()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.weight, Parameters: 1728\n",
      "total  1728\n",
      "Layer: bn1.weight, Parameters: 64\n",
      "total  1792\n",
      "Layer: bn1.bias, Parameters: 64\n",
      "total  1856\n",
      "Layer: depthwise_conv.depthwise_conv.weight, Parameters: 576\n",
      "total  2432\n",
      "Layer: depthwise_conv.pointwise_conv.weight, Parameters: 4096\n",
      "total  6528\n",
      "Layer: depthwise_conv.bn.weight, Parameters: 64\n",
      "total  6592\n",
      "Layer: depthwise_conv.bn.bias, Parameters: 64\n",
      "total  6656\n",
      "Layer: depthwise_conv.relu.weight, Parameters: 1\n",
      "total  6657\n",
      "Layer: bn2.weight, Parameters: 64\n",
      "total  6721\n",
      "Layer: bn2.bias, Parameters: 64\n",
      "total  6785\n",
      "Layer: bottleneck_block1.conv1.weight, Parameters: 2048\n",
      "total  8833\n",
      "Layer: bottleneck_block1.bn1.weight, Parameters: 32\n",
      "total  8865\n",
      "Layer: bottleneck_block1.bn1.bias, Parameters: 32\n",
      "total  8897\n",
      "Layer: bottleneck_block1.relu.weight, Parameters: 1\n",
      "total  8898\n",
      "Layer: bottleneck_block1.depthwise_conv.depthwise_conv.weight, Parameters: 288\n",
      "total  9186\n",
      "Layer: bottleneck_block1.depthwise_conv.pointwise_conv.weight, Parameters: 1024\n",
      "total  10210\n",
      "Layer: bottleneck_block1.depthwise_conv.bn.weight, Parameters: 32\n",
      "total  10242\n",
      "Layer: bottleneck_block1.depthwise_conv.bn.bias, Parameters: 32\n",
      "total  10274\n",
      "Layer: bottleneck_block1.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  10275\n",
      "Layer: bottleneck_block1.bn2.weight, Parameters: 32\n",
      "total  10307\n",
      "Layer: bottleneck_block1.bn2.bias, Parameters: 32\n",
      "total  10339\n",
      "Layer: bottleneck_block1.conv3.weight, Parameters: 2048\n",
      "total  12387\n",
      "Layer: bottleneck_block1.bn3.weight, Parameters: 64\n",
      "total  12451\n",
      "Layer: bottleneck_block1.bn3.bias, Parameters: 64\n",
      "total  12515\n",
      "Layer: residual_block1.conv1.weight, Parameters: 8192\n",
      "total  20707\n",
      "Layer: residual_block1.bn1.weight, Parameters: 128\n",
      "total  20835\n",
      "Layer: residual_block1.bn1.bias, Parameters: 128\n",
      "total  20963\n",
      "Layer: residual_block1.relu.weight, Parameters: 1\n",
      "total  20964\n",
      "Layer: residual_block1.depthwise_conv.depthwise_conv.weight, Parameters: 1152\n",
      "total  22116\n",
      "Layer: residual_block1.depthwise_conv.pointwise_conv.weight, Parameters: 16384\n",
      "total  38500\n",
      "Layer: residual_block1.depthwise_conv.bn.weight, Parameters: 128\n",
      "total  38628\n",
      "Layer: residual_block1.depthwise_conv.bn.bias, Parameters: 128\n",
      "total  38756\n",
      "Layer: residual_block1.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  38757\n",
      "Layer: residual_block1.bn2.weight, Parameters: 128\n",
      "total  38885\n",
      "Layer: residual_block1.bn2.bias, Parameters: 128\n",
      "total  39013\n",
      "Layer: residual_block1.conv3.weight, Parameters: 8192\n",
      "total  47205\n",
      "Layer: residual_block1.bn3.weight, Parameters: 64\n",
      "total  47269\n",
      "Layer: residual_block1.bn3.bias, Parameters: 64\n",
      "total  47333\n",
      "Layer: bottleneck_block2.conv1.weight, Parameters: 2048\n",
      "total  49381\n",
      "Layer: bottleneck_block2.bn1.weight, Parameters: 32\n",
      "total  49413\n",
      "Layer: bottleneck_block2.bn1.bias, Parameters: 32\n",
      "total  49445\n",
      "Layer: bottleneck_block2.relu.weight, Parameters: 1\n",
      "total  49446\n",
      "Layer: bottleneck_block2.depthwise_conv.depthwise_conv.weight, Parameters: 288\n",
      "total  49734\n",
      "Layer: bottleneck_block2.depthwise_conv.pointwise_conv.weight, Parameters: 1024\n",
      "total  50758\n",
      "Layer: bottleneck_block2.depthwise_conv.bn.weight, Parameters: 32\n",
      "total  50790\n",
      "Layer: bottleneck_block2.depthwise_conv.bn.bias, Parameters: 32\n",
      "total  50822\n",
      "Layer: bottleneck_block2.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  50823\n",
      "Layer: bottleneck_block2.bn2.weight, Parameters: 32\n",
      "total  50855\n",
      "Layer: bottleneck_block2.bn2.bias, Parameters: 32\n",
      "total  50887\n",
      "Layer: bottleneck_block2.conv3.weight, Parameters: 4096\n",
      "total  54983\n",
      "Layer: bottleneck_block2.bn3.weight, Parameters: 128\n",
      "total  55111\n",
      "Layer: bottleneck_block2.bn3.bias, Parameters: 128\n",
      "total  55239\n",
      "Layer: residual_block2.conv1.weight, Parameters: 32768\n",
      "total  88007\n",
      "Layer: residual_block2.bn1.weight, Parameters: 256\n",
      "total  88263\n",
      "Layer: residual_block2.bn1.bias, Parameters: 256\n",
      "total  88519\n",
      "Layer: residual_block2.relu.weight, Parameters: 1\n",
      "total  88520\n",
      "Layer: residual_block2.depthwise_conv.depthwise_conv.weight, Parameters: 2304\n",
      "total  90824\n",
      "Layer: residual_block2.depthwise_conv.pointwise_conv.weight, Parameters: 65536\n",
      "total  156360\n",
      "Layer: residual_block2.depthwise_conv.bn.weight, Parameters: 256\n",
      "total  156616\n",
      "Layer: residual_block2.depthwise_conv.bn.bias, Parameters: 256\n",
      "total  156872\n",
      "Layer: residual_block2.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  156873\n",
      "Layer: residual_block2.bn2.weight, Parameters: 256\n",
      "total  157129\n",
      "Layer: residual_block2.bn2.bias, Parameters: 256\n",
      "total  157385\n",
      "Layer: residual_block2.conv3.weight, Parameters: 32768\n",
      "total  190153\n",
      "Layer: residual_block2.bn3.weight, Parameters: 128\n",
      "total  190281\n",
      "Layer: residual_block2.bn3.bias, Parameters: 128\n",
      "total  190409\n",
      "Layer: bottleneck_block3.conv1.weight, Parameters: 8192\n",
      "total  198601\n",
      "Layer: bottleneck_block3.bn1.weight, Parameters: 64\n",
      "total  198665\n",
      "Layer: bottleneck_block3.bn1.bias, Parameters: 64\n",
      "total  198729\n",
      "Layer: bottleneck_block3.relu.weight, Parameters: 1\n",
      "total  198730\n",
      "Layer: bottleneck_block3.depthwise_conv.depthwise_conv.weight, Parameters: 576\n",
      "total  199306\n",
      "Layer: bottleneck_block3.depthwise_conv.pointwise_conv.weight, Parameters: 4096\n",
      "total  203402\n",
      "Layer: bottleneck_block3.depthwise_conv.bn.weight, Parameters: 64\n",
      "total  203466\n",
      "Layer: bottleneck_block3.depthwise_conv.bn.bias, Parameters: 64\n",
      "total  203530\n",
      "Layer: bottleneck_block3.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  203531\n",
      "Layer: bottleneck_block3.bn2.weight, Parameters: 64\n",
      "total  203595\n",
      "Layer: bottleneck_block3.bn2.bias, Parameters: 64\n",
      "total  203659\n",
      "Layer: bottleneck_block3.conv3.weight, Parameters: 16384\n",
      "total  220043\n",
      "Layer: bottleneck_block3.bn3.weight, Parameters: 256\n",
      "total  220299\n",
      "Layer: bottleneck_block3.bn3.bias, Parameters: 256\n",
      "total  220555\n",
      "Layer: residual_block3.conv1.weight, Parameters: 131072\n",
      "total  351627\n",
      "Layer: residual_block3.bn1.weight, Parameters: 512\n",
      "total  352139\n",
      "Layer: residual_block3.bn1.bias, Parameters: 512\n",
      "total  352651\n",
      "Layer: residual_block3.relu.weight, Parameters: 1\n",
      "total  352652\n",
      "Layer: residual_block3.depthwise_conv.depthwise_conv.weight, Parameters: 4608\n",
      "total  357260\n",
      "Layer: residual_block3.depthwise_conv.pointwise_conv.weight, Parameters: 262144\n",
      "total  619404\n",
      "Layer: residual_block3.depthwise_conv.bn.weight, Parameters: 512\n",
      "total  619916\n",
      "Layer: residual_block3.depthwise_conv.bn.bias, Parameters: 512\n",
      "total  620428\n",
      "Layer: residual_block3.depthwise_conv.relu.weight, Parameters: 1\n",
      "total  620429\n",
      "Layer: residual_block3.bn2.weight, Parameters: 512\n",
      "total  620941\n",
      "Layer: residual_block3.bn2.bias, Parameters: 512\n",
      "total  621453\n",
      "Layer: residual_block3.conv3.weight, Parameters: 131072\n",
      "total  752525\n",
      "Layer: residual_block3.bn3.weight, Parameters: 256\n",
      "total  752781\n",
      "Layer: residual_block3.bn3.bias, Parameters: 256\n",
      "total  753037\n",
      "Layer: conv3.weight, Parameters: 131072\n",
      "total  884109\n",
      "Layer: bn3.weight, Parameters: 512\n",
      "total  884621\n",
      "Layer: bn3.bias, Parameters: 512\n",
      "total  885133\n",
      "Layer: fc.weight, Parameters: 262144\n",
      "total  1147277\n",
      "Layer: fc.bias, Parameters: 512\n",
      "total  1147789\n",
      "Layer: relu.weight, Parameters: 1\n",
      "total  1147790\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total = 0\n",
    "# Count parameters per layer\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, Parameters: {param.numel()}\")\n",
    "    total+=param.numel()\n",
    "    print(\"total \",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Input Size: torch.Size([1, 3, 112, 112])\n",
      "Final Output Size: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 112, 112)\n",
    "\n",
    "\n",
    "# Print the initial input size\n",
    "print(f\"Initial Input Size: {dummy_input.shape}\")\n",
    "\n",
    "out = model(dummy_input)\n",
    "\n",
    "# Print the final output size\n",
    "print(f\"Final Output Size: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobiFace                                      [1, 512]                  --\n",
       "├─Conv2d: 1-1                                 [1, 64, 56, 56]           1,728\n",
       "├─BatchNorm2d: 1-2                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-3                                  [1, 64, 56, 56]           1\n",
       "├─DepthwiseSeparableConv2d: 1-4               [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 56, 56]           576\n",
       "│    └─Conv2d: 2-2                            [1, 64, 56, 56]           4,096\n",
       "│    └─BatchNorm2d: 2-3                       [1, 64, 56, 56]           128\n",
       "│    └─PReLU: 2-4                             [1, 64, 56, 56]           1\n",
       "├─BatchNorm2d: 1-5                            [1, 64, 56, 56]           128\n",
       "├─PReLU: 1-6                                  [1, 64, 56, 56]           (recursive)\n",
       "├─BottleneckBlock: 1-7                        [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-5                            [1, 32, 56, 56]           2,048\n",
       "│    └─BatchNorm2d: 2-6                       [1, 32, 56, 56]           64\n",
       "│    └─PReLU: 2-7                             [1, 32, 56, 56]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-8          [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                       [1, 32, 28, 28]           288\n",
       "│    │    └─Conv2d: 3-2                       [1, 32, 28, 28]           1,024\n",
       "│    │    └─BatchNorm2d: 3-3                  [1, 32, 28, 28]           64\n",
       "│    │    └─PReLU: 3-4                        [1, 32, 28, 28]           1\n",
       "│    └─BatchNorm2d: 2-9                       [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-10                            [1, 32, 28, 28]           (recursive)\n",
       "│    └─Conv2d: 2-11                           [1, 64, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-12                      [1, 64, 28, 28]           128\n",
       "├─InvertedResidualBlock: 1-8                  [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-13                           [1, 128, 28, 28]          8,192\n",
       "│    └─BatchNorm2d: 2-14                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-15                            [1, 128, 28, 28]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-16         [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-5                       [1, 128, 28, 28]          1,152\n",
       "│    │    └─Conv2d: 3-6                       [1, 128, 28, 28]          16,384\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 128, 28, 28]          256\n",
       "│    │    └─PReLU: 3-8                        [1, 128, 28, 28]          1\n",
       "│    └─BatchNorm2d: 2-17                      [1, 128, 28, 28]          256\n",
       "│    └─PReLU: 2-18                            [1, 128, 28, 28]          (recursive)\n",
       "│    └─Conv2d: 2-19                           [1, 64, 28, 28]           8,192\n",
       "│    └─BatchNorm2d: 2-20                      [1, 64, 28, 28]           128\n",
       "│    └─Sequential: 2-21                       [1, 64, 28, 28]           --\n",
       "├─BottleneckBlock: 1-9                        [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-22                           [1, 32, 28, 28]           2,048\n",
       "│    └─BatchNorm2d: 2-23                      [1, 32, 28, 28]           64\n",
       "│    └─PReLU: 2-24                            [1, 32, 28, 28]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-25         [1, 32, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-9                       [1, 32, 14, 14]           288\n",
       "│    │    └─Conv2d: 3-10                      [1, 32, 14, 14]           1,024\n",
       "│    │    └─BatchNorm2d: 3-11                 [1, 32, 14, 14]           64\n",
       "│    │    └─PReLU: 3-12                       [1, 32, 14, 14]           1\n",
       "│    └─BatchNorm2d: 2-26                      [1, 32, 14, 14]           64\n",
       "│    └─PReLU: 2-27                            [1, 32, 14, 14]           (recursive)\n",
       "│    └─Conv2d: 2-28                           [1, 128, 14, 14]          4,096\n",
       "│    └─BatchNorm2d: 2-29                      [1, 128, 14, 14]          256\n",
       "├─InvertedResidualBlock: 1-10                 [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-30                           [1, 256, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-31                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-32                            [1, 256, 14, 14]          1\n",
       "│    └─DepthwiseSeparableConv2d: 2-33         [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-13                      [1, 256, 14, 14]          2,304\n",
       "│    │    └─Conv2d: 3-14                      [1, 256, 14, 14]          65,536\n",
       "│    │    └─BatchNorm2d: 3-15                 [1, 256, 14, 14]          512\n",
       "│    │    └─PReLU: 3-16                       [1, 256, 14, 14]          1\n",
       "│    └─BatchNorm2d: 2-34                      [1, 256, 14, 14]          512\n",
       "│    └─PReLU: 2-35                            [1, 256, 14, 14]          (recursive)\n",
       "│    └─Conv2d: 2-36                           [1, 128, 14, 14]          32,768\n",
       "│    └─BatchNorm2d: 2-37                      [1, 128, 14, 14]          256\n",
       "│    └─Sequential: 2-38                       [1, 128, 14, 14]          --\n",
       "├─BottleneckBlock: 1-11                       [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-39                           [1, 64, 14, 14]           8,192\n",
       "│    └─BatchNorm2d: 2-40                      [1, 64, 14, 14]           128\n",
       "│    └─PReLU: 2-41                            [1, 64, 14, 14]           1\n",
       "│    └─DepthwiseSeparableConv2d: 2-42         [1, 64, 7, 7]             --\n",
       "│    │    └─Conv2d: 3-17                      [1, 64, 7, 7]             576\n",
       "│    │    └─Conv2d: 3-18                      [1, 64, 7, 7]             4,096\n",
       "│    │    └─BatchNorm2d: 3-19                 [1, 64, 7, 7]             128\n",
       "│    │    └─PReLU: 3-20                       [1, 64, 7, 7]             1\n",
       "│    └─BatchNorm2d: 2-43                      [1, 64, 7, 7]             128\n",
       "│    └─PReLU: 2-44                            [1, 64, 7, 7]             (recursive)\n",
       "│    └─Conv2d: 2-45                           [1, 256, 7, 7]            16,384\n",
       "│    └─BatchNorm2d: 2-46                      [1, 256, 7, 7]            512\n",
       "├─InvertedResidualBlock: 1-12                 [1, 256, 7, 7]            --\n",
       "│    └─Conv2d: 2-47                           [1, 512, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-48                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-49                            [1, 512, 7, 7]            1\n",
       "│    └─DepthwiseSeparableConv2d: 2-50         [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-21                      [1, 512, 7, 7]            4,608\n",
       "│    │    └─Conv2d: 3-22                      [1, 512, 7, 7]            262,144\n",
       "│    │    └─BatchNorm2d: 3-23                 [1, 512, 7, 7]            1,024\n",
       "│    │    └─PReLU: 3-24                       [1, 512, 7, 7]            1\n",
       "│    └─BatchNorm2d: 2-51                      [1, 512, 7, 7]            1,024\n",
       "│    └─PReLU: 2-52                            [1, 512, 7, 7]            (recursive)\n",
       "│    └─Conv2d: 2-53                           [1, 256, 7, 7]            131,072\n",
       "│    └─BatchNorm2d: 2-54                      [1, 256, 7, 7]            512\n",
       "│    └─Sequential: 2-55                       [1, 256, 7, 7]            --\n",
       "├─Conv2d: 1-13                                [1, 512, 7, 7]            131,072\n",
       "├─BatchNorm2d: 1-14                           [1, 512, 7, 7]            1,024\n",
       "├─Linear: 1-15                                [1, 512]                  262,656\n",
       "===============================================================================================\n",
       "Total params: 1,147,790\n",
       "Trainable params: 1,147,790\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 119.78\n",
       "===============================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 35.28\n",
       "Params size (MB): 4.59\n",
       "Estimated Total Size (MB): 40.02\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1,3,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset folder\n",
    "root_dir = \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\images\"\n",
    "\n",
    "# directory for test\n",
    "#root_dir= \"C:\\\\Users\\\\mathe\\\\OneDrive\\\\Área de Trabalho\\\\master\\\\TFM\\\\dataset\\\\faces_webface_112x112\\\\small_sample\"\n",
    "\n",
    "# Create ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "# Create DataLoader for training\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset)  - train_size -val_size\n",
    "train_dataset, val_dataset,test_dataset = random_split(dataset, [train_size, val_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 294373\n"
     ]
    }
   ],
   "source": [
    "print(\"train size\",len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_size, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the desired device\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiFace(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "    (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bottleneck_block1): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block1): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block2): BottleneckBlock(\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block2): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (bottleneck_block3): BottleneckBlock(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (residual_block3): InvertedResidualBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=1)\n",
       "    (depthwise_conv): DepthwiseSeparableConv2d(\n",
       "      (depthwise_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential()\n",
       "  )\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (relu): PReLU(num_parameters=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embedding_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_classes = 10572\n",
    "# Modify the number of classes in the last linear layer\n",
    "model.fc = nn.Linear(in_features=512, out_features=new_num_classes).to(device)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define loss function and optimizer after modifying the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        \n",
    "        # Move inputs and labels to the specified device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_dataloader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "\n",
    "            total_correct += (predicted == val_labels).sum().item()\n",
    "            total_samples += val_labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "torch.save(model, 'full_mobiFace_like_v1.pth') \n",
    "torch.save(model.state_dict(), 'dict_mobiFace_live_v1.pth') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
